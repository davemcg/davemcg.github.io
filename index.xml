<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>eye Bioinformatician on eye Bioinformatician</title>
    <link>/./</link>
    <description>Recent content in eye Bioinformatician on eye Bioinformatician</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 -0400</lastBuildDate>
    <atom:link href="//" rel="self" type="application/rss+xml" />
    
    <item>
      <title>#BoG18: Talk Notes</title>
      <link>/./post/bog18-notes/</link>
      <pubDate>Tue, 08 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/./post/bog18-notes/</guid>
      <description>&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#intro&#34;&gt;Intro&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#genome-engineering-and-genome-editing-tuesday-night&#34;&gt;Genome Engineering and Genome Editing (Tuesday Night)&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#jef-boeke&#34;&gt;Jef Boeke&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#writing-genomes&#34;&gt;Writing Genomes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#dark-matter&#34;&gt;“dark matter”&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#big-dna&#34;&gt;big dna&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#greg-findlay-jay-shendure&#34;&gt;Greg Findlay (Jay Shendure)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#stephen-levene-andrew-fire&#34;&gt;Stephen Levene (Andrew Fire)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#david-truong-jef-boeke&#34;&gt;David Truong (Jef Boeke)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#feng-zhang&#34;&gt;Feng Zhang&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#molly-gasperini-jay-shendure&#34;&gt;Molly Gasperini (Jay Shendure)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#eilon-sharon-hunter-fraser&#34;&gt;Eilon Sharon (Hunter Fraser)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#luca-pinello&#34;&gt;Luca Pinello&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#population-genomics-wednesday-morning&#34;&gt;Population Genomics (Wednesday morning)&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#mattias-joakobsson&#34;&gt;Mattias Joakobsson&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#jaemin-kim-elaine-ostrander&#34;&gt;Jaemin Kim (Elaine Ostrander)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#ipsita-agarwal-molly-przeworski&#34;&gt;Ipsita Agarwal (Molly Przeworski)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#amnon-koren&#34;&gt;Amnon Koren&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sarah-tishkoff&#34;&gt;Sarah Tishkoff&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#patrick-albers-gil-mcvean&#34;&gt;Patrick Albers (Gil McVean)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#laura-hayward-guy-sella&#34;&gt;Laura Hayward (Guy Sella)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#functional-genetics-and-epigenomics&#34;&gt;Functional Genetics and Epigenomics&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#job-dekker&#34;&gt;Job Dekker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#flora-vaccarino&#34;&gt;Flora Vaccarino&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#carninci&#34;&gt;Carninci&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#johnathan-griffiths-berthold-gottgens&#34;&gt;Johnathan Griffiths (Berthold Gottgens)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#emma-farley&#34;&gt;Emma Farley&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#jake-yeung-felix-naef&#34;&gt;Jake Yeung (Felix Naef)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#minal-caliskan-casey-brown&#34;&gt;Minal Caliskan (Casey Brown)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#parisa-razaz-talkwoski&#34;&gt;Parisa Razaz (Talkwoski)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#evolutionary-and-non-human-genomics&#34;&gt;Evolutionary and Non-human genomics&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#monica-justice&#34;&gt;Monica Justice&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#arang-rhie-erich-jarvis&#34;&gt;Arang Rhie (Erich Jarvis)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#olga-dudchenko-erez-lieberman-aiden&#34;&gt;Olga Dudchenko (Erez Lieberman Aiden)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#kasper-munch&#34;&gt;Kasper Munch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#gavin-sherlock&#34;&gt;Gavin Sherlock&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#anne-ruxandra-carvunis&#34;&gt;Anne Ruxandra Carvunis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#elaine-ostrander&#34;&gt;Elaine Ostrander&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#bobbie-cansdale-claire-wade&#34;&gt;Bobbie Cansdale (Claire Wade)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;intro&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Intro&lt;/h1&gt;
&lt;p&gt;Very sparse and poorly written notes covering &lt;a href=&#34;https://twitter.com/search?q=%23BoG18&amp;amp;src=tyah&#34;&gt;#BoG18&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Typos everywhere. Things may change dramatically over time as I scan back through notes.&lt;/p&gt;
&lt;p&gt;I’ve tried to respect #notwitter. Will be updated periodically.&lt;/p&gt;
&lt;p&gt;Speaker (Last Author)&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;genome-engineering-and-genome-editing-tuesday-night&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Genome Engineering and Genome Editing (Tuesday Night)&lt;/h1&gt;
&lt;div id=&#34;jef-boeke&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Jef Boeke&lt;/h2&gt;
&lt;div id=&#34;writing-genomes&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Writing Genomes&lt;/h3&gt;
&lt;p&gt;Building synthetic yeast genomes. Contig/chr one by one. All designed. &lt;em&gt;Sc2.0&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;80+% complete for each of the 16.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;dark-matter&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;“dark matter”&lt;/h3&gt;
&lt;p&gt;Can we use ‘big dna’ to functionally query mammalian genomes? ‘Synthetic haplotypes’&lt;/p&gt;
&lt;p&gt;Building dif combinations of haplotype blocks&lt;/p&gt;
&lt;p&gt;synthetic hypervariation:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;- query enhancers
- alt splicing&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;built 102kb locus (human) and put into yeast&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;- built in 3kb chunks and can assemble dif combiations&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;big-dna&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;big dna&lt;/h3&gt;
&lt;p&gt;Can build big dna pieces CEGS grant will build 3 100kb+ loci / year want community input&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;greg-findlay-jay-shendure&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Greg Findlay (Jay Shendure)&lt;/h2&gt;
&lt;p&gt;Accurate classficiation of thousands of BRCA1 variants with saturation genome editing&lt;/p&gt;
&lt;p&gt;vous a problem BRCA1:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;4243 clinvar snvs&lt;/li&gt;
&lt;li&gt;&lt;blockquote&gt;
&lt;p&gt;50% VOUS&lt;/p&gt;
&lt;/blockquote&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;How to functionally validate?&lt;/p&gt;
&lt;p&gt;Use Homology-direct repair (HDR). Can engineer precise edits.&lt;/p&gt;
&lt;p&gt;Use a library of SNVs for the HDR&lt;/p&gt;
&lt;p&gt;Over time selecdtion removes non functional edits&lt;/p&gt;
&lt;p&gt;Each experimente:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;millions of cells&lt;/li&gt;
&lt;li&gt;millions of sequencing reads to count SNVs&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Variable effects at splicing junctions&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;sometimes just 2-3 bp&lt;/li&gt;
&lt;li&gt;sometimes 9 base pairs&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;also have matched rna-seq data&lt;/p&gt;
&lt;p&gt;aberrant splicing causes RNA depletion&lt;/p&gt;
&lt;p&gt;matches up really well with clinvar designations&lt;/p&gt;
&lt;p&gt;question:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;hdr effeciency rate? 10-90% effectiveness&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;stephen-levene-andrew-fire&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Stephen Levene (Andrew Fire)&lt;/h2&gt;
&lt;p&gt;eccDNA is a possible mediator of chromosomal polymorphism at multple loci&lt;/p&gt;
&lt;p&gt;‘physical chemist by training’&lt;/p&gt;
&lt;ol start=&#34;5&#34; style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;coli genome: 1 femtoliter volume&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;100 fold compaction problem (DNA)&lt;/p&gt;
&lt;p&gt;~10k fold for mammalian&lt;/p&gt;
&lt;p&gt;Techniques for DNA/chromiatin flexibility:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Hi-C&lt;/li&gt;
&lt;li&gt;FISH&lt;/li&gt;
&lt;li&gt;SLICE (Beagrie et al Nature 2017)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;eccDNA (circular dna outside chromosome/nucleus(?))&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;unclear how it forms&lt;/li&gt;
&lt;li&gt;elevated levels associatd with genome instability&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;how to capture?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DNA -&amp;gt; SDS lysis -&amp;gt; isolate gDNA -&amp;gt; cscl gradient -&amp;gt; bottom bit&lt;/li&gt;
&lt;li&gt;or exoV treatment (leaves circular alone)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;take pictures of the loops with high resolution microscopy&lt;/p&gt;
&lt;p&gt;sequenced a few (&lt;strong&gt;unfortunately with short read illumina&lt;/strong&gt;)&lt;/p&gt;
&lt;p&gt;modeled with molecular dynamics&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;david-truong-jef-boeke&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;David Truong (Jef Boeke)&lt;/h2&gt;
&lt;p&gt;Resurrection of Histone H3k27 Me in brewer’s yeast by human prc2 and plant atxr6&lt;/p&gt;
&lt;p&gt;human pathway reconstruction in yeast&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;avoid pleiotropy (hopefully)&lt;/li&gt;
&lt;li&gt;more real than &lt;em&gt;in vitro&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Yeast (s. cerevisiae) lost histone mods&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Adding them back???&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;yes&lt;/p&gt;
&lt;p&gt;humanize yeast histones&lt;/p&gt;
&lt;p&gt;add synthetic human histones&lt;/p&gt;
&lt;p&gt;force out wt histones with +5FOA&lt;/p&gt;
&lt;p&gt;&lt;em&gt;20 days later&lt;/em&gt; ….. one colony&lt;/p&gt;
&lt;p&gt;Keep growing the colony out&lt;/p&gt;
&lt;p&gt;WGS: mutations in cell cycle regulation&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;bypassing histone cycle checks?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;brewer’s yeast does not have H3K27 methylation&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PRC2 complex (to methylate h3k27)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;add the stuffs - what happens?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;made artifical chr with PRC2 complex
&lt;ul&gt;
&lt;li&gt;and a slightly broken one&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;not much happens in WT yeast
&lt;ul&gt;
&lt;li&gt;no me changes&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;deleted H3k36me3 (might antagonize artificial chr)
&lt;ul&gt;
&lt;li&gt;nope&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;can you jump start with atxr6 (does mono me)?
&lt;ul&gt;
&lt;li&gt;yes (confirmed with mass spec)&lt;/li&gt;
&lt;li&gt;not super high levels (0.054% tri me)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;feng-zhang&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Feng Zhang&lt;/h2&gt;
&lt;p&gt;Advances in genome editing technologies&lt;/p&gt;
&lt;p&gt;two major classes of CRISPR&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;class 1 (multi subunut)&lt;/li&gt;
&lt;li&gt;class 2 (single subunit crRNA-effector)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;trying to find new class 2&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;bioinformatic screen with BLAST of cas1&lt;/li&gt;
&lt;li&gt;found a bunch (Shmakov collaboration)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;cas13&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;added into e. coli&lt;/li&gt;
&lt;li&gt;modify to only edit RNA?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;rna editing&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;reversible&lt;/li&gt;
&lt;li&gt;nuclease based editing inefficient in post mitotic cells&lt;/li&gt;
&lt;li&gt;dCas13 linked with &lt;a href=&#34;https://en.wikipedia.org/wiki/ADAR&#34;&gt;ADAR&lt;/a&gt; (adenosine to inosine) + guideRNA –&amp;gt; A to I conversion in RNA&lt;/li&gt;
&lt;li&gt;90+% conversion&lt;/li&gt;
&lt;li&gt;1732 off target incidents
&lt;ul&gt;
&lt;li&gt;925 off target with non-targeting guide!&lt;/li&gt;
&lt;li&gt;so protein itself is not ideal….&lt;/li&gt;
&lt;li&gt;identified non-binding residues of ADAR&lt;/li&gt;
&lt;li&gt;mutated them&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;v2 works better
&lt;ul&gt;
&lt;li&gt;18385 off target (v1) to 20 (v2)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;still developing&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;molly-gasperini-jay-shendure&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Molly Gasperini (Jay Shendure)&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;my fav of the night&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;crisprQTL mapping as a genome-wide association framework for cellular genetic screens&lt;/p&gt;
&lt;p&gt;lots of guideRNA to made mutations, check for dif in expression&lt;/p&gt;
&lt;p&gt;nuclease inactive cas9&lt;/p&gt;
&lt;p&gt;want to test all enhancers against all genes&lt;/p&gt;
&lt;p&gt;scRNA-seq + guideRNA (multiplex gRNA)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;thus multiple perturbations per ‘assay’&lt;/li&gt;
&lt;li&gt;15-30 / cell!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;targeted 1,119 candidate enhancers&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;15 guides / cell&lt;/li&gt;
&lt;li&gt;47k cells&lt;/li&gt;
&lt;li&gt;10X&lt;/li&gt;
&lt;li&gt;CROP-seq&lt;/li&gt;
&lt;li&gt;works really well&lt;/li&gt;
&lt;li&gt;crisprQTL usually targets closest gene
&lt;ul&gt;
&lt;li&gt;sometimes not….&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;matches up with histone chip-seq&lt;/li&gt;
&lt;li&gt;34.3kb average distance from enhancer &amp;lt;-&amp;gt; gene&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;** new data! ** 4,801 enhancers&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;built logistic regression model on pilot to pick new candidates&lt;/li&gt;
&lt;li&gt;30 guides / cell&lt;/li&gt;
&lt;li&gt;correlates with pilot&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;manolis kellis q:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;why doesn’t work so well? expected more&lt;/li&gt;
&lt;li&gt;what about multiple SNPS / block?&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;eilon-sharon-hunter-fraser&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Eilon Sharon (Hunter Fraser)&lt;/h2&gt;
&lt;p&gt;Testing genetic var effect on fitness using precise genome editing&lt;/p&gt;
&lt;p&gt;high throughput edigint&lt;/p&gt;
&lt;p&gt;crispey: cas9 retron precise parallel editing via homology&lt;/p&gt;
&lt;p&gt;use bacterial reverse transcriptase and RNA retron to covalently link ssDNA donor to guide-tracrRNA&lt;/p&gt;
&lt;p&gt;can insert long sequences&lt;/p&gt;
&lt;p&gt;(yeast)&lt;/p&gt;
&lt;p&gt;measure fitness of genetic variants (growth competition)&lt;/p&gt;
&lt;p&gt;sequence every 2-3 gens&lt;/p&gt;
&lt;p&gt;model at linear relative strain abundance / time (generation #)&lt;/p&gt;
&lt;p&gt;# missense var ~ # synonymous var for effecting fitness!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;luca-pinello&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Luca Pinello&lt;/h2&gt;
&lt;p&gt;CRISPR-SURF exploratory and interactive software for analyzing CRISPR-base tiling screens&lt;/p&gt;
&lt;p&gt;Uncover non-coding functional regions&lt;/p&gt;
&lt;p&gt;** Nice overview of CRISPR tiling strategy ** Mutate (tile across region) -&amp;gt; Measure pheno change (somehow) -&amp;gt; Assess (sequence gRNA)&lt;/p&gt;
&lt;p&gt;No unified framework to analyze these kind of assays&lt;/p&gt;
&lt;p&gt;many challenges&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;biological noise&lt;/li&gt;
&lt;li&gt;sgRNA efficiencies&lt;/li&gt;
&lt;li&gt;non-uniform spacing&lt;/li&gt;
&lt;li&gt;perturbation / assay differences&lt;/li&gt;
&lt;li&gt;epigenetic perturbation can be wide (changing 200bp or so)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;deconvolve with generalized lasso&lt;/p&gt;
&lt;p&gt;fastq -&amp;gt; score -&amp;gt; segmentation -&amp;gt; deconvolution -&amp;gt; region ID&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;population-genomics-wednesday-morning&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Population Genomics (Wednesday morning)&lt;/h1&gt;
&lt;div id=&#34;mattias-joakobsson&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Mattias Joakobsson&lt;/h2&gt;
&lt;p&gt;** out of my field here **&lt;/p&gt;
&lt;p&gt;Sequence based approaches utilizing complete modern and ancient genomes to investigate early human history&lt;/p&gt;
&lt;p&gt;Use full genomes on ancient pops&lt;/p&gt;
&lt;p&gt;Population divergence models&lt;/p&gt;
&lt;pre class=&#34;ascii&#34;&gt;&lt;code&gt;                      X
     +                X
     |                X
     |                X
     |                X
     |               XXXX
     |              XX  XXX
time |           XXX      XX
     |         XXX         XX
     |        XX            XX
     |
     |      A B              C
     |
     v&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Can model whether discordant or concordant (a,b,c) over time&lt;/p&gt;
&lt;p&gt;estimate pop divergence (time) in generations&lt;/p&gt;
&lt;p&gt;use genes from different populations to estimate divergence&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;‘tt method’&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;stone age humans from sourthern africa&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;13 genomes from 3 people&lt;/li&gt;
&lt;li&gt;a bit ‘right’ of yoruba&lt;/li&gt;
&lt;li&gt;admixture with east africa &lt;strong&gt;missed something&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;jaemin-kim-elaine-ostrander&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Jaemin Kim (Elaine Ostrander)&lt;/h2&gt;
&lt;p&gt;Genetic Selection of Athletic Success in Sport Hunting Dogs&lt;/p&gt;
&lt;p&gt;WGS of sport hunting (10 breeds), terrier (i breeds), and ‘village’ dogs (unselected - an outgroup)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;14 million SNPs&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;59 genes under strong selectdion in hunting dogs (compare to terrier and village)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;blood circulation GO terms&lt;/li&gt;
&lt;li&gt;and a bunch of ‘process’ GO terms&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ASIC3 - resistance to muscle fatigue?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;maybe?&lt;/li&gt;
&lt;li&gt;a guess based on known gene function (I think)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;dogs do agility performance competitions&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;made a metric to find breeds good at winning&lt;/li&gt;
&lt;li&gt;WGS of 92 breeds of 299 dogs&lt;/li&gt;
&lt;li&gt;ROBO1 significant 3e-4 (FDR corrected? Don’t know)
&lt;ul&gt;
&lt;li&gt;neuronal migration, axon guidance&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;1243 SNP chip
&lt;ul&gt;
&lt;li&gt;dogs classified by agility performance&lt;/li&gt;
&lt;li&gt;** do only pure breeds do agility? **&lt;/li&gt;
&lt;li&gt;ROBO1 SNP AF increases with more winning breeds&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;racing speeds (whippet)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;not ROBO1&lt;/li&gt;
&lt;li&gt;TRPM3 (1.6e-3)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;CDH23 - increased tolerance to loud noise and low startle reflex - &lt;strong&gt;do hunting dogs have poor hearing?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Useful stuff maybe for competitive dog breeders&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Q (Kellis?): polymorphic nature of traits across dogs. &lt;strong&gt;what’s the question?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A: complex traits, incomplete answers right now&lt;/p&gt;
&lt;p&gt;Q (Kellis?): enrollment bias for dogs that will win&lt;/p&gt;
&lt;p&gt;A: tried to control by grouping breeds&lt;/p&gt;
&lt;p&gt;Q: what kind of mutations?&lt;/p&gt;
&lt;p&gt;A: mostly noncoding (&lt;strong&gt;answer in LD I guess&lt;/strong&gt;)&lt;/p&gt;
&lt;p&gt;Q: project personality onto dog … look at dog behavior/traits relating to this?&lt;/p&gt;
&lt;p&gt;A: try to objectively test dogs (can’t trust owners….)&lt;/p&gt;
&lt;p&gt;Elaine: people developing stanrdard tests for dogs (yes, owners lie)&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ipsita-agarwal-molly-przeworski&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Ipsita Agarwal (Molly Przeworski)&lt;/h2&gt;
&lt;p&gt;Widespread differences in the mtation spectrum of X and autosomes&lt;/p&gt;
&lt;p&gt;Males contrigute more germline mutations than females&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;epigenetic differences for gamete development (methylation)&lt;/li&gt;
&lt;li&gt;sperm in mitosis all the time&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;ascii&#34;&gt;&lt;code&gt;+
|
|
|                         XX
|                       XXX
|                    XX
|                  X
|               XX
|             X
|       X XX
|   XXXX
|  XX
|                 XXXX
|   XXXX XXX  XXXXX
|
+------------------------+&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Mutation rates get wider as males age (top line male, bottom female)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;eyeball 3x worse?&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;GnomAD:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;120 million SNPs&lt;/li&gt;
&lt;li&gt;60% singleton (50%) and doubletons (10%) for variants&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Looked for X-autosome difs&lt;/p&gt;
&lt;p&gt;X/A diversity = (mutations(x) / all X) / (mutation(a) / all a) (a is autosome, x is chrX)&lt;/p&gt;
&lt;p&gt;Bootstrap test for mutation types to make null distribution&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;big shift in X (more than expected)&lt;/li&gt;
&lt;li&gt;T-&amp;gt;A and C-&amp;gt;A more common in X versus autosome&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Replication timing&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;inactive X has more mutations&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Enriched of C&amp;gt;G (meiotic recombination / DSB) mutations&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;amnon-koren&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Amnon Koren&lt;/h2&gt;
&lt;p&gt;Genetic architecture of human DNA replication origin activity&lt;/p&gt;
&lt;p&gt;We have extensive maps of human genomic / epigenomic&lt;/p&gt;
&lt;p&gt;But where are replication origins?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;yeah….good q&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;yeast have them
&lt;ul&gt;
&lt;li&gt;yeast have a DnaA/OriC signatures&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;how to find?
&lt;ul&gt;
&lt;li&gt;many techniques - don’t agree well (or at all)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;different parts of genomic replicate at different rates&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;can measure coverage across time, right&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;yes&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;sort G / S phase
&lt;ul&gt;
&lt;li&gt;check coverage&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Did in 2012 with human - but not precise enough (low resolution)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Is this a polymorphic trait?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;skipped cell sorting&lt;/li&gt;
&lt;li&gt;works well enough
&lt;ul&gt;
&lt;li&gt;and way faster to do&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;uh, wait, this has been done already (if cells are growing)&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;again, yes, LCL from 1000G&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;But still, did WGS &amp;gt;140 hESC lines&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;oooooo, reproduces REALLY well&lt;/li&gt;
&lt;li&gt;find ‘master’ ORI that are pretty much always present
&lt;ul&gt;
&lt;li&gt;crucial regions in replication?&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;GWAS of DNA replication timing&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;‘rtQTL’ (replication timing)&lt;/li&gt;
&lt;li&gt;big hit on chr7&lt;/li&gt;
&lt;li&gt;756 with FDR &amp;lt; 0.1&lt;/li&gt;
&lt;li&gt;most fall within replication origin
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;direct relationship, then, cool&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;getting causal SNPs with CAVIAR&lt;/li&gt;
&lt;li&gt;enriched with active chromatin states&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;perhaps some QTL stabilize TF binding motifs - stuff happening in motifs&lt;/p&gt;
&lt;p&gt;Q: look for associations with structural variation? (1000G data)&lt;/p&gt;
&lt;p&gt;A: looking at this now&lt;/p&gt;
&lt;p&gt;Q: cell type specific? (&lt;strong&gt;thank you&lt;/strong&gt;)&lt;/p&gt;
&lt;p&gt;A: 20-30% are dif across cell types (&lt;strong&gt;cool&lt;/strong&gt;)&lt;/p&gt;
&lt;p&gt;Q: is ORI piggybacking on enhancer / regulatory system? (&lt;strong&gt;or other way around??&lt;/strong&gt;)&lt;/p&gt;
&lt;p&gt;A: maybe (or other way around)&lt;/p&gt;
&lt;p&gt;Q: cis effects - did you find any trans or pleiotropy?&lt;/p&gt;
&lt;p&gt;A: nothing strong (spurious stuff maybe?)&lt;/p&gt;
&lt;p&gt;Q: HiC/3C data profiles comparisons?&lt;/p&gt;
&lt;p&gt;A: not &lt;em&gt;yet&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;sarah-tishkoff&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Sarah Tishkoff&lt;/h2&gt;
&lt;p&gt;Novel loci associated with skin pigmentation identified in African populations&lt;/p&gt;
&lt;p&gt;Integrative omics of copmlex traits&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;epigenomics&lt;/li&gt;
&lt;li&gt;transcriptomes&lt;/li&gt;
&lt;li&gt;microbiome&lt;/li&gt;
&lt;li&gt;metabolomics&lt;/li&gt;
&lt;li&gt;proteomics&lt;/li&gt;
&lt;li&gt;genomics&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;LOTS OF POSTERS&lt;/p&gt;
&lt;p&gt;200 WGS Aricans - 35 million SNPS - 20% novel&lt;/p&gt;
&lt;p&gt;81% GWAS european&lt;/p&gt;
&lt;p&gt;Skin color is adaptive trait - spectrophotometry of skin color - and take DNA - boom GWAS - 1600 people - found 8 regions&lt;/p&gt;
&lt;p&gt;SLC24A5&lt;/p&gt;
&lt;p&gt;MFSD12 - novel - transmembrane transporters - found enhnacer activity - functional work! - KO mRNA in melanocyptes - get more melanin - colocalizes with lysosome - ZF KO - yellow gone - mouse KO - diff colors - looks like gr/gr mouse - 9bp deletion in MFSD12!&lt;/p&gt;
&lt;p&gt;DDB1 - DNA repair in UV damage - pigmentation in tomatoes - fine mapping hits TMEM128 - luciferase assay with enhancer activity - huge haplotype blocks of low het in europeans/asians - selective sweep, near complete fixation&lt;/p&gt;
&lt;p&gt;OCA2/HERC2 - exon10 SNP alt splicing - rs1800404&lt;/p&gt;
&lt;p&gt;convergent evolution of very dark skin - african and south asia&lt;/p&gt;
&lt;p&gt;q: speculate about lysosome?&lt;/p&gt;
&lt;p&gt;a: pheomelanin made in lysosome (like) structure?&lt;/p&gt;
&lt;p&gt;q: surprised to not find var close to mcr1 a: no&lt;/p&gt;
&lt;p&gt;q: chimp with no hair has vitiligo?&lt;/p&gt;
&lt;p&gt;a: dont’ think so - have been assured chimps have light skin&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;patrick-albers-gil-mcvean&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Patrick Albers (Gil McVean)&lt;/h2&gt;
&lt;p&gt;Non-parametric estimation of allele age for variants in pop-scale seq data&lt;/p&gt;
&lt;p&gt;Want to know history of allele at single locus&lt;/p&gt;
&lt;p&gt;Genealogical approach (GEVA)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;look for coalescent events
&lt;ul&gt;
&lt;li&gt;concordant and discordance allele pairs&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;use HMM to detecdt haplotypes segments
&lt;ul&gt;
&lt;li&gt;non parametric&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;assess allele age…not sure how
&lt;ul&gt;
&lt;li&gt;incorporate time some how?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;model with real data to pick parameters??&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;model - simulation with simple pop, const size, fixed mut rate - compare estimate with actual - good cor (0.953)&lt;/p&gt;
&lt;p&gt;also tested in error-filled data - haplotypes, errors, phasing issues - still works, but overestimate young alleles (think they are older)&lt;/p&gt;
&lt;p&gt;ran in simons genetci diversity project and 1000G - oldest var ~37.5k years in AFR - SAS 12.5K - EAS 11K - AMR 7.5K - EUR 6K (why so young? - admixture)&lt;/p&gt;
&lt;p&gt;cumulative coalescent decoding (CCD) - what frac of your genome share with another genome back in time? - ran this pair-wise across 1000G dataset&lt;/p&gt;
&lt;p&gt;&lt;em&gt;will release a genome-wide atlas of allele age &amp;gt;16 million variants&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;laura-hayward-guy-sella&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Laura Hayward (Guy Sella)&lt;/h2&gt;
&lt;p&gt;Polygenic adaptation in response to sudden change in environment&lt;/p&gt;
&lt;p&gt;What time scale? Mentioned Human expansion out of Africa, which is ~100k years&lt;/p&gt;
&lt;p&gt;stabilizing selection reduces pheontypic variance (omega is width of trait distribution) - kingsolver et al. 2001&lt;/p&gt;
&lt;p&gt;model change of phenotpye in environment change&lt;/p&gt;
&lt;p&gt;OK…not following this talk well at all (pretty sure it’s me). Laura is copiously using cartoons, which is usually works for fools like me.&lt;/p&gt;
&lt;p&gt;not cetain whether this stuff is driven by theory or data or both - no, no data - equations from first princples&lt;/p&gt;
&lt;p&gt;conclusions: - polygenic adaption is rapid - short term: large effects drive change - long term: moderate effect alleles replace them&lt;/p&gt;
&lt;p&gt;topol Q: is this like dogs? big changes in short term&lt;/p&gt;
&lt;p&gt;a: no, not modeling dramatic changes like this&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;functional-genetics-and-epigenomics&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Functional Genetics and Epigenomics&lt;/h1&gt;
&lt;div id=&#34;job-dekker&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Job Dekker&lt;/h2&gt;
&lt;p&gt;Folding, unfolding, and refolding genomes&lt;/p&gt;
&lt;p&gt;How does the genome work? &lt;strong&gt;structured&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Dekker et al. 2002: 3C. &lt;strong&gt;I remember this paper. And totally failing at doing this tech myself&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A/B compartments….TAD…..enhancer - gene loops. One slide summarzing many publications and of cool work.&lt;/p&gt;
&lt;pre class=&#34;ascii&#34;&gt;&lt;code&gt;                                TAD
                                                loop (cohesin-mediated)
                 loop (cohesin-mediated)       XXXX 
                XXXX                         XX   XX
              XXX   XXX                     XX      XXX
            XX        XX                  XX           XX
          XX            XX              XXX              XX
        XX                X           XXX                  XXX
      XX                   XX        XX                      XX
    XXX                      XX    XXX                         XXX
  XX                          XXXXX                              XX
 XXXX                           X                XXXXXXXX       XXXX
    XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX       XXX X XX
ctcf                           ctcf                                 ctcf&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Interphase / metaphase - interphase has structure - metaphase erases structure (fat diagonal of 3c map)&lt;/p&gt;
&lt;p&gt;meiotic chr fold as helical nested loop arrays (helix with loops coming off) - Gibcus…Dekker Science 2018&lt;/p&gt;
&lt;p&gt;Using ATAC-seq, cut&amp;amp;ruhn to assay CTCF binding patterning in interphase / metaphase&lt;/p&gt;
&lt;p&gt;FRAP to measure stable CTCF binding in interphase / metaphase - unstable in metaphase&lt;/p&gt;
&lt;p&gt;Q: CTCF sites occupied in mitosis - why? Nucleosomes taking over?&lt;/p&gt;
&lt;p&gt;A: Good q, don’t know. Think nucleosomes ‘sliding in’&lt;/p&gt;
&lt;p&gt;Q: &lt;strong&gt;missed it&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A: protein levels of CTCF doesn’t change during what phase cell is in&lt;/p&gt;
&lt;p&gt;Q: what is keeping the promoters open during mitosis&lt;/p&gt;
&lt;p&gt;A: don’t think pol is bound….promoters more open to begin with….something bookmarking the site????&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;flora-vaccarino&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Flora Vaccarino&lt;/h2&gt;
&lt;p&gt;Integrative multi-omics analyses of iPSC-derived brain organioids&lt;/p&gt;
&lt;p&gt;#notwitter&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;carninci&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Carninci&lt;/h2&gt;
&lt;p&gt;RADICL-seq: novel tech for genome-wide mapping of RNA-chromatin interactions&lt;/p&gt;
&lt;p&gt;Many many (~20k) functiona lncRNA&lt;/p&gt;
&lt;p&gt;But what is role? Activate genes, promoter, enhancer? Repression of genes? Establish insulation?&lt;/p&gt;
&lt;p&gt;RADICL-seq - capture RNA-DNA interactions with crosslinking (formaldehyde, 1-2%)&lt;/p&gt;
&lt;p&gt;Where do they map?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Lots in the intron&lt;/li&gt;
&lt;li&gt;open chromatin&lt;/li&gt;
&lt;li&gt;380k RNA-DNA interactions&lt;/li&gt;
&lt;li&gt;enriched in TF family members&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;looks like lots of trans interactions&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;but way fewer than cis,as you would expect&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;some genes like MALAT1 interact with &lt;em&gt;entire&lt;/em&gt; genome&lt;/li&gt;
&lt;li&gt;compartments &lt;strong&gt;sort of&lt;/strong&gt; like TADS
&lt;ul&gt;
&lt;li&gt;weak cor with Hi-C (0.27)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;johnathan-griffiths-berthold-gottgens&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Johnathan Griffiths (Berthold Gottgens)&lt;/h2&gt;
&lt;p&gt;Charting the Diversification of Mammalian Cells at whole genome scale&lt;/p&gt;
&lt;p&gt;Gastrulation focus (mouse)&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;350 whole embryos&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Collected every 6 hours: e6.5 to e8.5&lt;/p&gt;
&lt;p&gt;10X chromium, 94k cells (post QC), 15,000 UMI (median), 3.5k detected genes (median)&lt;/p&gt;
&lt;p&gt;Big t-SNE plot&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;talk of ‘direction’ and ‘trajectory’ which I dislike for t-SNE…&lt;/li&gt;
&lt;li&gt;but can back up with time point data&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Clustered with association of cell types to each other&lt;/p&gt;
&lt;p&gt;Chimera embryos&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;KO gene, but only chimerically (inject KO mESC into blastocyst)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;whoah&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;can compare KO &lt;strong&gt;cells&lt;/strong&gt; vs not KO &lt;strong&gt;cells&lt;/strong&gt; within full atlas&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;damn&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;emma-farley&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Emma Farley&lt;/h2&gt;
&lt;p&gt;Regulatory principles governing enhancer specificity during development&lt;/p&gt;
&lt;p&gt;Otxa (neural enhancer)&lt;/p&gt;
&lt;p&gt;How do enhancers encode function?&lt;/p&gt;
&lt;p&gt;Need to test in embryos across time&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Ciona&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;have notochord, heart, nerver chord&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;enhnacer + prom + gfp -&amp;gt; electroporation == inside embryo&lt;/p&gt;
&lt;p&gt;made 2.5 million synthetic enhancers (barcoded)&lt;/p&gt;
&lt;p&gt;electroporate 100k eggs -&amp;gt; mRNA -&amp;gt; sequence (remember, we have barcodes) -&amp;gt; identify functional enhancers&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;pooling of embryos?&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;doesn’t seem like it…but seems like you have too for $&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Can we we make inert enhancers functional with small tweaks (change to optimal seq)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;lights up EVERYTHING&lt;/li&gt;
&lt;li&gt;&lt;em&gt;need mix of optimal and sub-optimal sites to maintain proper expression&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;spacing between enhancers also important&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;adding just a few bp between motifs &amp;gt;&amp;gt;&amp;gt; expression&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;interplay between spacing and motif ‘strength’ (canonical-ness)&lt;/p&gt;
&lt;p&gt;and &lt;em&gt;orientation&lt;/em&gt; (flipping motifs can break function)&lt;/p&gt;
&lt;p&gt;&lt;em&gt;suboptimization&lt;/em&gt; as design parameter hilarious and terrifying (great, let’s make things worse to control things more precisely)&lt;/p&gt;
&lt;p&gt;wut - SHH enhancer that causes polydactyly….points out that SNP makes binding site &lt;em&gt;better&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Deboever et al. Cell Stem Cell 2017 D’Antonion et al. Nature communication 2017&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;jake-yeung-felix-naef&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Jake Yeung (Felix Naef)&lt;/h2&gt;
&lt;p&gt;Clock dependent chromatin topology modulates circadian transcdription and behavior&lt;/p&gt;
&lt;p&gt;promoter - enhancer loops&lt;/p&gt;
&lt;p&gt;cry1 24 cycle in liver (high at night, low at day)&lt;/p&gt;
&lt;p&gt;how are enhancers used?&lt;/p&gt;
&lt;p&gt;4c-seq on mice collected every 4 hours for 24 hours&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;contacts change over time&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;h3k27ac changes also at same location&lt;/p&gt;
&lt;p&gt;removed that region in mouse: cry1deltaE mouse&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;clock runs faster (15 mins over 24 hours)&lt;/li&gt;
&lt;li&gt;corresponding mRNA difs in cry1&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;minal-caliskan-casey-brown&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Minal Caliskan (Casey Brown)&lt;/h2&gt;
&lt;p&gt;Genetic and epigenetic fine mapping of complex trait associated loci in the human liver&lt;/p&gt;
&lt;p&gt;Genotype &amp;lt;-&amp;gt; RNA-seq &amp;lt;-&amp;gt; H3K4me3 &amp;lt;-&amp;gt; H3K27ac 50 &amp;lt;-&amp;gt; 50 &amp;lt;-&amp;gt; 10 &amp;lt;-&amp;gt; 10 (people)&lt;/p&gt;
&lt;p&gt;Found eQTLs specific to liver (vs GTEX)&lt;/p&gt;
&lt;p&gt;Found hQTLS also (histone)&lt;/p&gt;
&lt;p&gt;eQTL + hQTL + RNA-seq to ‘fine map’ GWAS loci&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;blood pressure&lt;/li&gt;
&lt;li&gt;coronary artery disease&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;parisa-razaz-talkwoski&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Parisa Razaz (Talkwoski)&lt;/h2&gt;
&lt;p&gt;Tissue-specific molecular sigmnature of 16p11.2 reciprocal genomic disorder&lt;/p&gt;
&lt;p&gt;engineer rgd with CRISPR (make microdels and microdups)&lt;/p&gt;
&lt;p&gt;iPSCs models and mouse models with tx profiling (brain and not brain)&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;evolutionary-and-non-human-genomics&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Evolutionary and Non-human genomics&lt;/h1&gt;
&lt;div id=&#34;monica-justice&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Monica Justice&lt;/h2&gt;
&lt;/div&gt;
&lt;div id=&#34;arang-rhie-erich-jarvis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Arang Rhie (Erich Jarvis)&lt;/h2&gt;
&lt;/div&gt;
&lt;div id=&#34;olga-dudchenko-erez-lieberman-aiden&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Olga Dudchenko (Erez Lieberman Aiden)&lt;/h2&gt;
&lt;/div&gt;
&lt;div id=&#34;kasper-munch&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Kasper Munch&lt;/h2&gt;
&lt;/div&gt;
&lt;div id=&#34;gavin-sherlock&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Gavin Sherlock&lt;/h2&gt;
&lt;/div&gt;
&lt;div id=&#34;anne-ruxandra-carvunis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Anne Ruxandra Carvunis&lt;/h2&gt;
&lt;/div&gt;
&lt;div id=&#34;elaine-ostrander&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Elaine Ostrander&lt;/h2&gt;
&lt;/div&gt;
&lt;div id=&#34;bobbie-cansdale-claire-wade&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Bobbie Cansdale (Claire Wade)&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Let&#39;s Plot 6: Simple guide to heatmaps with ComplexHeatmaps</title>
      <link>/./post/simple-heatmaps-with-complexheatmaps/</link>
      <pubDate>Mon, 07 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/./post/simple-heatmaps-with-complexheatmaps/</guid>
      <description>&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#data-processing&#34;&gt;Data processing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#load-data&#34;&gt;Load data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#peek-at-expression&#34;&gt;Peek at expression&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#peek-at-metadata&#34;&gt;Peek at metadata&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#brief-outline-on-how-the-rna-seq-data-was-processed-before-we-see-it&#34;&gt;Brief outline on how the RNA-seq data was processed before we see it&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#load-libraries&#34;&gt;Load libraries&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#create-a-sample---sample-distance-heatmap&#34;&gt;Create a Sample - Sample distance heatmap&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#easy-heatmap-with-complexheatmap&#34;&gt;Easy heatmap with ComplexHeatmap&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#complex-heatmap&#34;&gt;Complex heatmap&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#finished-heatmap&#34;&gt;Finished heatmap&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#gene-heatmaps&#34;&gt;Gene Heatmaps&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#a-bit-simpler&#34;&gt;A bit simpler&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#session-info&#34;&gt;Session Info&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Heatmaps are a core competency for a bioinformatician. They are a compact way to visually demonstrate relationships and changes in values across conditions.&lt;/p&gt;
&lt;p&gt;We are going to use RNA-seq data to make two kinds of common heatmaps:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Sample - Sample relationships&lt;/li&gt;
&lt;li&gt;Gene expression changes across samples for a subset of genes&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;data-processing&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data processing&lt;/h2&gt;
&lt;p&gt;The two Rdata datasets we are going to use can be found here:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/davemcg/Let_us_plot/blob/master/006_heatmaps/expression.Rdata&#34;&gt;Expression data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/davemcg/Let_us_plot/blob/master/006_heatmaps/metadata.Rdata&#34;&gt;Metadata&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;load-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Load data&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;load(&amp;#39;~/git/Let_us_plot/006_heatmaps/expression.Rdata&amp;#39;)
load(&amp;#39;~/git/Let_us_plot/006_heatmaps/metadata.Rdata&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;peek-at-expression&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Peek at expression&lt;/h2&gt;
&lt;p&gt;Rows are genes, columns are samples. Notice how the &lt;em&gt;number&lt;/em&gt; sample names got X appended to the beginning. This is because R variable names cannot start with a number. Generally R will ‘fix’ your sample names during a &lt;em&gt;base&lt;/em&gt; R handling.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(expression)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     Gene       X10       X11       X16       X17       X18        X2
## 1  ABCA1 13.973778 12.244265 12.628729 13.182851 11.383009 12.333361
## 2 ABCA10 10.883834  8.813957 11.247787  9.870685  8.059123  9.346461
## 3 ABCA13  9.171412  7.629223  7.490137  8.134116  8.261363  6.430140
## 4  ABCA2 11.338420 14.976849 13.679589 12.014997 16.011478 13.439011
## 5  ABCA4  8.773803 11.641017 11.293125  8.072241 12.393982 10.126994
## 6  ABCA6  9.420007  6.285309  7.527962  8.659904  5.957441  6.535751
##          X3        X4        X9      var
## 1 13.483913 11.377315 10.976546 1.056482
## 2 11.245402  8.585732  9.479805 1.387638
## 3  9.955795  7.499681  7.084981 1.152503
## 4 12.259725 16.007328 15.390794 3.168466
## 5 10.126629 11.505725 11.344527 2.040986
## 6  9.950779  5.658777  6.439992 2.526444&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# check number of rows (genes) and column (samples)
dim(expression)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2191   11&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;peek-at-metadata&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Peek at metadata&lt;/h2&gt;
&lt;p&gt;Sample names with the serum conditions (Human Serum or Heat Inactivated HS) as well as the time the cells spend in the serum&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;metadata&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   sample serum treatment_hours
## 1      2    HS              24
## 2      3    HS              48
## 3      4  HIHS              48
## 4      9    HS              24
## 5     10    HS              48
## 6     11  HIHS              48
## 7     16    HS              24
## 8     17    HS              48
## 9     18  HIHS              48&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;brief-outline-on-how-the-rna-seq-data-was-processed-before-we-see-it&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Brief outline on how the RNA-seq data was processed before we see it&lt;/h2&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;a href=&#34;http://salmon.readthedocs.io&#34;&gt;Salmon&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://bioconductor.org/packages/release/bioc/html/tximport.html&#34;&gt;tximport&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://bioconductor.org/packages/release/bioc/html/DESeq2.html&#34;&gt;DESeq2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.bioconductor.org/packages//2.10/bioc/vignettes/DESeq/inst/doc/vst.pdf&#34;&gt;variance stabilizing transformation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Filter genes to only retain high variance genes (often not necessary, but used to reduce the amount of data I share)&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;load-libraries&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Load libraries&lt;/h2&gt;
&lt;p&gt;I’ve rapidly become a fan of &lt;a href=&#34;https://www.bioconductor.org/packages/release/bioc/html/ComplexHeatmap.html&#34;&gt;ComplexHeatmap&lt;/a&gt;. It is capaable of creating just about anything &lt;strong&gt;and&lt;/strong&gt; has excellent documentation and examples.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Attaching packages ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.2.1 ──&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✔ ggplot2 2.2.1     ✔ purrr   0.2.4
## ✔ tibble  1.4.2     ✔ dplyr   0.7.4
## ✔ tidyr   0.8.0     ✔ stringr 1.3.0
## ✔ readr   1.1.1     ✔ forcats 0.3.0&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Conflicts ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
## ✖ dplyr::filter() masks stats::filter()
## ✖ dplyr::lag()    masks stats::lag()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ComplexHeatmap)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: grid&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(viridis)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: viridisLite&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;create-a-sample---sample-distance-heatmap&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Create a Sample - Sample distance heatmap&lt;/h2&gt;
&lt;p&gt;An powerful way to see sample to sample relationships is to use the expression data to arrange the samples. The distance between each sample can be calculated by taking the &lt;a href=&#34;https://en.wikipedia.org/wiki/Euclidean_distance&#34;&gt;euclidean distance&lt;/a&gt; between each sample. This reduces the space from a n x m matrix of values to a single number for each sample pair.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;expression_dists &amp;lt;- expression %&amp;gt;% 
  # drop the Gene and variance column
  select(-Gene, -var) %&amp;gt;% 
  # flip axes as the dist() function does all of row-row relationships
  # we want samples as the rows....
  t() %&amp;gt;% 
  # this actually calculates the euclidean distance (other types of distance are possible - read the docs with ?dist)
  dist() %&amp;gt;% 
  # coerce to matrix, then data frame
  as.matrix() %&amp;gt;% data.frame() 

# now a 9 x 9 data frame
expression_dists %&amp;gt;% dim()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 9 9&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;easy-heatmap-with-complexheatmap&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Easy heatmap with ComplexHeatmap&lt;/h3&gt;
&lt;p&gt;I have a few problems with this plot:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Red / blue is more for distinguishing over / under in my opinion - we are talking about close to far&lt;/li&gt;
&lt;li&gt;Don’t really need to see key for the colors. Distance is unit-less.&lt;/li&gt;
&lt;li&gt;We can’t map between sample name and the metadata&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Heatmap(expression_dists)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-05-07-simple-heatmaps-with-complexheatmaps_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;complex-heatmap&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Complex heatmap&lt;/h3&gt;
&lt;p&gt;The metadata needs some extensive reworking to make it work with the sample distance data for the heatmap&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;code&gt;mutate&lt;/code&gt; the sample to add the ‘X’ to match the dist data column names&lt;/li&gt;
&lt;li&gt;&lt;code&gt;filter&lt;/code&gt; to only keep metadata samples that are in the distance data (very common to have metadata for &lt;em&gt;all&lt;/em&gt; samples)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;select&lt;/code&gt; to grab the relevant columns (also common to have many extra columns that aren’t used)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mutate&lt;/code&gt; again to coerce the sample order in the metadata to match the sample order in the distance data&lt;/li&gt;
&lt;li&gt;&lt;code&gt;arrange&lt;/code&gt; to use the order set above for the metadata (try erasing this and see what happens….)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;unique&lt;/code&gt; to remove duplicated rows&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;After that the HeatmapAnnotation take the &lt;code&gt;Time&lt;/code&gt; and &lt;code&gt;Serum&lt;/code&gt; as a data.frame and I am manually setting the colors by grabbing colors from the magma scheme from viridis.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;metadata_heatmap &amp;lt;- metadata  %&amp;gt;% 
  mutate(sample = paste0(&amp;#39;X&amp;#39;, sample)) %&amp;gt;% 
  filter(sample %in% colnames(expression_dists)) %&amp;gt;% 
  dplyr::select(sample, treatment_hours, serum) %&amp;gt;% 
  mutate(sample=factor(sample, levels=colnames(expression_dists))) %&amp;gt;% 
  arrange(sample) %&amp;gt;% 
  unique() 

ha_column = HeatmapAnnotation(df = data.frame(Time = metadata_heatmap$treatment_hours,
                                              Serum = metadata_heatmap$serum), 
                              col = list(Serum = c(&amp;quot;HS&amp;quot; =  magma(20)[5], &amp;quot;HIHS&amp;quot; = magma(20)[7]),
                                         Time = c(&amp;quot;24&amp;quot; = magma(20)[12], &amp;quot;48&amp;quot; = magma(20)[18])))


Heatmap(expression_dists, 
        col=viridis(100),
        name = &amp;#39;Sample\nDistances&amp;#39;,
        top_annotation = ha_column)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-05-07-simple-heatmaps-with-complexheatmaps_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;finished-heatmap&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Finished heatmap&lt;/h3&gt;
&lt;p&gt;Now I am going to drop the ‘X’ from the sample names and remove the Sample Distances key&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# substitute &amp;#39;&amp;#39; (nothing) for &amp;#39;X&amp;#39; for the column and row names
colnames(expression_dists) &amp;lt;- gsub(&amp;#39;X&amp;#39;,&amp;#39;&amp;#39;,colnames(expression_dists))
rownames(expression_dists) &amp;lt;- gsub(&amp;#39;X&amp;#39;,&amp;#39;&amp;#39;,rownames(expression_dists))
Heatmap(expression_dists, 
        col=viridis(100),
        show_heatmap_legend = F,
        top_annotation = ha_column)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-05-07-simple-heatmaps-with-complexheatmaps_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;gene-heatmaps&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Gene Heatmaps&lt;/h2&gt;
&lt;p&gt;The next common type of heatmap is to show how a set of genes changes expression between conditions&lt;/p&gt;
&lt;p&gt;We will look at a small set of genes and see how their expression changes when put in Heat Inactivated Human Serum (HIHS) or Human Serum (HS), only at the 48 hour time point.&lt;/p&gt;
&lt;p&gt;First, make gene_set, HS, and HIHS sample vectors&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gene_set &amp;lt;- c(&amp;#39;EP300&amp;#39;,&amp;#39;ABCA4&amp;#39;,&amp;#39;CLCN6&amp;#39;,&amp;#39;CRX&amp;#39;,&amp;#39;HIST1H1T&amp;#39;,&amp;#39;IGSF9&amp;#39;,&amp;#39;SLC16A7&amp;#39;,&amp;#39;MYO5C&amp;#39;,&amp;#39;NEURL3&amp;#39;)

HS_samples &amp;lt;- metadata %&amp;gt;% filter(serum==&amp;#39;HS&amp;#39;, treatment_hours==48) %&amp;gt;% pull(sample) %&amp;gt;% unique() %&amp;gt;% paste0(&amp;#39;X&amp;#39;,.)
HIHS_samples &amp;lt;- metadata %&amp;gt;% filter(serum==&amp;#39;HIHS&amp;#39;, treatment_hours==48) %&amp;gt;% pull(sample) %&amp;gt;% unique() %&amp;gt;% paste0(&amp;#39;X&amp;#39;,.)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now calculate the change in expression across the HIHS &amp;lt;-&amp;gt; HS comparison and prep the metadata&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gene_set = expression %&amp;gt;% filter(Gene %in% gene_set) %&amp;gt;% select(-var)

# HIHS is the &amp;#39;reference&amp;#39;
# we&amp;#39;ll look at how expression changes with you use HS
row_mean_HIHS = gene_set[,HIHS_samples] %&amp;gt;% rowMeans()

# now subtract the mean HIHS expression from each row,
# and only keep HS samples for the plot
heatmap_expression = gene_set[,HS_samples] - row_mean_HIHS
# add Gene back as rownames
row.names(heatmap_expression) &amp;lt;- gene_set$Gene
# prep metadata as above
metadata_heatmap &amp;lt;- metadata  %&amp;gt;% 
  mutate(sample = paste0(&amp;#39;X&amp;#39;, sample)) %&amp;gt;% 
  filter(sample %in% colnames(heatmap_expression)) %&amp;gt;% 
  dplyr::select(sample, treatment_hours, serum) %&amp;gt;% 
  mutate(sample=factor(sample, levels=colnames(heatmap_expression))) %&amp;gt;% 
  arrange(sample) %&amp;gt;% 
  unique() &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The clustering of the rows is &lt;em&gt;really&lt;/em&gt; useful to quickly see what sets of genes are moving in the same direction&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ha_column = HeatmapAnnotation(df = data.frame(Time = metadata_heatmap$treatment_hours,
                                              Serum = metadata_heatmap$serum), 
                              col = list(Serum = c(&amp;quot;HS&amp;quot; =  magma(20)[5], &amp;quot;HIHS&amp;quot; = magma(20)[7]),
                                         Time = c(&amp;quot;24&amp;quot; = magma(20)[12], &amp;quot;48&amp;quot; = magma(20)[18])))

# Drop the X in sample names
colnames(heatmap_expression) &amp;lt;- gsub(&amp;#39;X&amp;#39;,&amp;#39;&amp;#39;,colnames(heatmap_expression))
Heatmap(heatmap_expression, 
        cluster_columns = FALSE,
        name = &amp;#39;log2(Fold\nChange)&amp;#39;, 
        top_annotation = ha_column)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-05-07-simple-heatmaps-with-complexheatmaps_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;a-bit-simpler&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;A bit simpler&lt;/h3&gt;
&lt;p&gt;You may think the annotations are superfluous, as they are all the same. If you are making just one, I would agree. Usually I am making a bunch of plots and I’d rather keep the annotations attached so I don’t get confused later.&lt;/p&gt;
&lt;p&gt;It is easy enough to drop them.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Heatmap(heatmap_expression, 
        cluster_columns = FALSE,
        name = &amp;#39;log2(Fold\nChange)&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-05-07-simple-heatmaps-with-complexheatmaps_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;session-info&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Session Info&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::session_info()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Session info -------------------------------------------------------------&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  setting  value                       
##  version  R version 3.4.0 (2017-04-21)
##  system   x86_64, darwin15.6.0        
##  ui       X11                         
##  language (EN)                        
##  collate  en_US.UTF-8                 
##  tz       America/New_York            
##  date     2018-05-07&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Packages -----------------------------------------------------------------&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  package        * version    date       source                        
##  assertthat       0.2.0      2017-04-11 CRAN (R 3.4.0)                
##  backports        1.1.2      2017-12-13 CRAN (R 3.4.3)                
##  base           * 3.4.0      2017-04-21 local                         
##  bindr            0.1.1      2018-03-13 CRAN (R 3.4.4)                
##  bindrcpp       * 0.2        2017-06-17 CRAN (R 3.4.0)                
##  blogdown         0.5        2018-01-24 CRAN (R 3.4.3)                
##  bookdown         0.7        2018-02-18 CRAN (R 3.4.3)                
##  broom            0.4.3      2017-11-20 CRAN (R 3.4.0)                
##  cellranger       1.1.0      2016-07-27 CRAN (R 3.4.0)                
##  circlize         0.4.3      2017-12-20 CRAN (R 3.4.3)                
##  class            7.3-14     2015-08-30 CRAN (R 3.4.0)                
##  cli              1.0.0      2017-11-05 CRAN (R 3.4.2)                
##  cluster          2.0.6      2017-03-10 CRAN (R 3.4.0)                
##  colorspace       1.3-2      2016-12-14 CRAN (R 3.4.0)                
##  compiler         3.4.0      2017-04-21 local                         
##  ComplexHeatmap * 1.14.0     2017-02-15 Bioconductor (R 3.4.0)        
##  crayon           1.3.4      2017-09-16 CRAN (R 3.4.1)                
##  datasets       * 3.4.0      2017-04-21 local                         
##  dendextend       1.7.0      2018-02-11 CRAN (R 3.4.3)                
##  DEoptimR         1.0-8      2016-11-19 CRAN (R 3.4.0)                
##  devtools         1.13.5     2018-02-18 CRAN (R 3.4.3)                
##  digest           0.6.15     2018-01-28 CRAN (R 3.4.3)                
##  diptest          0.75-7     2016-12-05 CRAN (R 3.4.0)                
##  dplyr          * 0.7.4      2017-09-28 CRAN (R 3.4.2)                
##  evaluate         0.10.1     2017-06-24 CRAN (R 3.4.1)                
##  flexmix          2.3-14     2017-04-28 CRAN (R 3.4.0)                
##  forcats        * 0.3.0      2018-02-19 CRAN (R 3.4.3)                
##  foreign          0.8-69     2017-06-22 CRAN (R 3.4.1)                
##  fpc              2.1-11     2018-01-13 CRAN (R 3.4.3)                
##  GetoptLong       0.1.6      2017-03-07 CRAN (R 3.4.0)                
##  ggplot2        * 2.2.1      2016-12-30 CRAN (R 3.4.0)                
##  GlobalOptions    0.0.13     2018-03-15 CRAN (R 3.4.4)                
##  glue             1.2.0      2017-10-29 CRAN (R 3.4.2)                
##  graphics       * 3.4.0      2017-04-21 local                         
##  grDevices      * 3.4.0      2017-04-21 local                         
##  grid           * 3.4.0      2017-04-21 local                         
##  gridExtra        2.3        2017-09-09 CRAN (R 3.4.1)                
##  gtable           0.2.0      2016-02-26 CRAN (R 3.4.0)                
##  haven            1.1.1      2018-01-18 CRAN (R 3.4.3)                
##  hms              0.4.2      2018-03-10 CRAN (R 3.4.4)                
##  htmltools        0.3.6      2017-04-28 CRAN (R 3.4.0)                
##  httr             1.3.1      2017-08-20 CRAN (R 3.4.1)                
##  jsonlite         1.5        2017-06-01 CRAN (R 3.4.0)                
##  kernlab          0.9-25     2016-10-03 CRAN (R 3.4.0)                
##  knitr            1.20       2018-02-20 CRAN (R 3.4.3)                
##  lattice          0.20-35    2017-03-25 CRAN (R 3.4.0)                
##  lazyeval         0.2.1      2017-10-29 CRAN (R 3.4.2)                
##  lubridate        1.7.3      2018-02-27 CRAN (R 3.4.3)                
##  magrittr         1.5        2014-11-22 CRAN (R 3.4.0)                
##  MASS             7.3-49     2018-02-23 CRAN (R 3.4.3)                
##  mclust           5.4        2017-11-22 CRAN (R 3.4.3)                
##  memoise          1.1.0      2017-04-21 CRAN (R 3.4.0)                
##  methods        * 3.4.0      2017-04-21 local                         
##  mnormt           1.5-5      2016-10-15 CRAN (R 3.4.0)                
##  modelr           0.1.1      2017-07-24 CRAN (R 3.4.1)                
##  modeltools       0.2-21     2013-09-02 CRAN (R 3.4.0)                
##  munsell          0.4.3      2016-02-13 CRAN (R 3.4.0)                
##  mvtnorm          1.0-7      2018-01-25 CRAN (R 3.4.3)                
##  nlme             3.1-131.1  2018-02-16 CRAN (R 3.4.3)                
##  nnet             7.3-12     2016-02-02 CRAN (R 3.4.0)                
##  parallel         3.4.0      2017-04-21 local                         
##  pillar           1.2.1      2018-02-27 CRAN (R 3.4.3)                
##  pkgconfig        2.0.1      2017-03-21 CRAN (R 3.4.0)                
##  plyr             1.8.4      2016-06-08 CRAN (R 3.4.0)                
##  prabclus         2.2-6      2015-01-14 CRAN (R 3.4.0)                
##  psych            1.7.8      2017-09-09 CRAN (R 3.4.0)                
##  purrr          * 0.2.4      2017-10-18 CRAN (R 3.4.2)                
##  R6               2.2.2      2017-06-17 CRAN (R 3.4.0)                
##  RColorBrewer     1.1-2      2014-12-07 CRAN (R 3.4.0)                
##  Rcpp             0.12.16    2018-03-13 CRAN (R 3.4.4)                
##  readr          * 1.1.1      2017-05-16 CRAN (R 3.4.0)                
##  readxl           1.0.0      2017-04-18 CRAN (R 3.4.0)                
##  reshape2         1.4.3      2017-12-11 CRAN (R 3.4.3)                
##  rjson            0.2.15     2014-11-03 CRAN (R 3.4.0)                
##  rlang            0.2.0      2018-02-20 CRAN (R 3.4.3)                
##  rmarkdown        1.9        2018-03-01 CRAN (R 3.4.3)                
##  robustbase       0.92-8     2017-11-01 CRAN (R 3.4.2)                
##  rprojroot        1.3-2      2018-01-03 CRAN (R 3.4.3)                
##  rstudioapi       0.7        2017-09-07 CRAN (R 3.4.1)                
##  rvest            0.3.2      2016-06-17 CRAN (R 3.4.0)                
##  scales           0.5.0.9000 2017-09-20 Github (hadley/scales@d767915)
##  shape            1.4.4      2018-02-07 CRAN (R 3.4.3)                
##  stats          * 3.4.0      2017-04-21 local                         
##  stats4           3.4.0      2017-04-21 local                         
##  stringi          1.1.7      2018-03-12 CRAN (R 3.4.4)                
##  stringr        * 1.3.0      2018-02-19 CRAN (R 3.4.3)                
##  tibble         * 1.4.2      2018-01-22 cran (@1.4.2)                 
##  tidyr          * 0.8.0      2018-01-29 CRAN (R 3.4.3)                
##  tidyverse      * 1.2.1      2017-11-14 CRAN (R 3.4.2)                
##  tools            3.4.0      2017-04-21 local                         
##  trimcluster      0.1-2      2012-10-29 CRAN (R 3.4.0)                
##  utils          * 3.4.0      2017-04-21 local                         
##  viridis        * 0.5.0      2018-02-02 CRAN (R 3.4.3)                
##  viridisLite    * 0.3.0      2018-02-01 CRAN (R 3.4.3)                
##  whisker          0.3-2      2013-04-28 CRAN (R 3.4.0)                
##  withr            2.1.2      2018-03-15 CRAN (R 3.4.4)                
##  xfun             0.1        2018-01-22 CRAN (R 3.4.3)                
##  xml2             1.2.0      2018-01-24 CRAN (R 3.4.3)                
##  yaml             2.1.18     2018-03-08 CRAN (R 3.4.4)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Template for rmarkdown reports</title>
      <link>/./post/template-for-rmarkdown-reports/</link>
      <pubDate>Fri, 04 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/./post/template-for-rmarkdown-reports/</guid>
      <description>&lt;div id=&#34;what-is-this&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;What is this?&lt;/h1&gt;
&lt;p&gt;Since I keep opening up random recent Rmarkdown documents to copy the header to paste into my next document, I figure it would be more efficient to just make a post I could reach from anywhere (with an internet connection).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;copy-paste&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Copy / paste:&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt;---
title: THE TITLE
author: David McGaughey
date: &amp;#39;`r format(Sys.Date(), &amp;quot;%Y-%m-%d&amp;quot;)`&amp;#39;
output: 
  html_notebook:
    theme: flatly
    toc: true
    code_folding: hide
---&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;```{r, message=F, warning=F, include=F}
# Load Libraries without printing any warnings or messages
library(tidyverse)
```&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;# Session Info&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```{r}
devtools::session_info()
```&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Easy bam downsampling</title>
      <link>/./post/easy-bam-downsampling/</link>
      <pubDate>Fri, 20 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/./post/easy-bam-downsampling/</guid>
      <description>&lt;p&gt;When you have a set of ChIP-seq (like) files, it is sometimes useful to downsample the larger samples to more closely match most of the samples. Tommy Tang goes into more detail in his &lt;a href=&#34;http://crazyhottommy.blogspot.com/2016/05/downsampling-for-bam-files-to-certain.html&#34;&gt;blog post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Unfortunately the tool suites I use most for bam files (samtools and picard) only downsample to a &lt;em&gt;percentage&lt;/em&gt;. Which isn’t ideal when you want your files to be no more than &lt;code&gt;n&lt;/code&gt; reads.&lt;/p&gt;
&lt;p&gt;This post is just a slight one-upping of Tommy Tang’s &lt;a href=&#34;http://crazyhottommy.blogspot.com/2016/05/downsampling-for-bam-files-to-certain.html&#34;&gt;process&lt;/a&gt; to easily downsample a bam. If you do some googling you’ll find lots of &lt;em&gt;boutique&lt;/em&gt; tools to downsample. Which I tend to avoid because I don’t want to have to sift through the source to make sure what they are doing looks reasonable and often-times there are dependencies to worry about. For something this simple, there &lt;em&gt;should&lt;/em&gt; be a way to pipe together a few commands to get what we want. Which Tommy &lt;em&gt;almost&lt;/em&gt; does.&lt;/p&gt;
&lt;p&gt;His little code snippet is &lt;code&gt;samtools idxstats example.bam | cut -f3 | awk &#39;BEGIN {total=0} {total += $1} END {print total}&#39;&lt;/code&gt;. It sums up the reads present in each chromosome/contig that the bam index holds. It is robust and will work unless the output format &lt;code&gt;idxstats&lt;/code&gt; sub-program is altered. Which I think is unlikely.&lt;/p&gt;
&lt;p&gt;The problem is that you have to do a &lt;em&gt;little&lt;/em&gt; more work to get the percentage to feed &lt;code&gt;samtools view -s&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;So here’s my extension, using &lt;code&gt;awk&lt;/code&gt; to calculate the percentage of the bam file to sample if you want to get to &lt;code&gt;n&lt;/code&gt; reads. It also will return &lt;code&gt;1&lt;/code&gt; if your bam file has fewer reads than your target.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;frac=$( samtools idxstats  input.bam | cut -f3 | awk &#39;BEGIN {total=0} {total += $1} END {frac=15000000/total; if (frac &amp;gt; 1) {print 1} else {print frac}}&#39; )&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;If you &lt;code&gt;echo $frac&lt;/code&gt; you get the downsample percentage: &lt;code&gt;0.334801&lt;/code&gt; for one of my bam files. You replace the 15000000 (15 million) with whatever you want to the the maximum number of reads.&lt;/p&gt;
&lt;p&gt;If your bam has fewer than &lt;code&gt;n&lt;/code&gt; reads you’ll get back &lt;code&gt;1&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;You can then just feed this into &lt;code&gt;samtools view&lt;/code&gt; like so: &lt;code&gt;samtools view -bs $frac input.bam &amp;gt; subsample.bam&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Putting it all together we have a nice two step process which fits nicely into an automated pipeline / workflow:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;frac=$( samtools idxstats  input.bam | cut -f3 | awk &#39;BEGIN {total=0} {total += $1} END {frac=15000000/total; if (frac &amp;gt; 1) {print 1} else {print frac}}&#39; )&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;samtools view -bs $frac input.bam &amp;gt; subsample.bam&lt;/code&gt;&lt;/p&gt;
&lt;div id=&#34;update&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;UPDATE&lt;/h1&gt;
&lt;p&gt;Tommy pointed out that you should run this &lt;strong&gt;after&lt;/strong&gt; you have removed reads that are duplicated, singletons, and low quality. It is not unusual to see bam files with &amp;gt;50% duplicate reads.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Let’s Plot 5: ridgeline density plots</title>
      <link>/./post/let-s-plot-5-ridgeline-density-plots/</link>
      <pubDate>Thu, 12 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/./post/let-s-plot-5-ridgeline-density-plots/</guid>
      <description>&lt;div id=&#34;intro&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Intro&lt;/h1&gt;
&lt;p&gt;For this installment of Let’s Plot (where anyone can make a figure!), we’ll be making the hottest visualization of 2017 - the &lt;em&gt;joy plot&lt;/em&gt; or &lt;em&gt;ridgeline plot&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Joy plots are partially overlapping density line plots. They are useful for densely showing changes in many distributions over time / condition / etc.&lt;/p&gt;
&lt;p&gt;This type of visualization was inspired by the &lt;a href=&#34;https://en.wikipedia.org/wiki/Unknown_Pleasures&#34;&gt;cover art&lt;/a&gt; from Joy Division’s album Unknown Pleasures and implemented in the R package &lt;a href=&#34;http://cran.r-project.org/web/packages/ggridges&#34;&gt;ggridges&lt;/a&gt; by Claus Wilke.
&lt;img src=&#34;/./img/lets_plot_5_cover.jpg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;While the original term for this plot took off as &lt;em&gt;joy plot&lt;/em&gt; it has since been changed to a &lt;em&gt;ridgeline plot&lt;/em&gt; or &lt;em&gt;ridges plots&lt;/em&gt;, as discussed at length &lt;a href=&#34;http://serialmentor.com/blog/2017/9/15/goodbye-joyplots&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Anyways, Claus has a &lt;em&gt;beautiful&lt;/em&gt; intro to his package &lt;a href=&#34;https://cran.r-project.org/web/packages/ggridges/vignettes/gallery.html&#34;&gt;here&lt;/a&gt;. I will not reproduce any of his plots, as I want you to click the link. Plus they are way cooler looking than what we will be making. Which is real(ish) data from people in my division.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;load-davide-merged-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Load Davide merged data&lt;/h1&gt;
&lt;p&gt;This is a highly cut down version of his original data - which is a 160mb csv file. The csv for this exercise can be found &lt;a href=&#34;https://github.com/davemcg/Let_us_plot/blob/master/005_ggridges/davide_cell_size_data.csv&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It contains cell area size for thousands of cells which have had a drug perturbation, split by wells in a dish. One drug per well.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(ggridges)
merged.df &amp;lt;- read_csv(&amp;#39;~/git/Let_us_plot/005_ggridges/davide_cell_size_data.csv&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;what-does-the-data-look-like&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;What does the data look like?&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(merged.df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 3
##   Well.names  Area Drug 
##   &amp;lt;chr&amp;gt;      &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;
## 1 D07          643 20(S 
## 2 D07          388 20(S 
## 3 D09          290 20(S 
## 4 D08         1174 20(S 
## 5 D09          186 20(S 
## 6 D09         7062 20(S&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;first-we-create-a-fake-dmso-to-match-each-drug-so-we-can-see-the-null-distribution-matched-with-each-drug-in-the-visualization-below&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;First we create a fake DMSO to match each drug so we can see the ‘null’ distribution matched with each drug in the visualization below&lt;/h1&gt;
&lt;p&gt;I know &lt;code&gt;for&lt;/code&gt; loops are out of trend, but I find them easier to write &lt;em&gt;and&lt;/em&gt; read compared to &lt;code&gt;purrr&lt;/code&gt;. A lot less compact, I concede.&lt;/p&gt;
&lt;p&gt;This is a bit hacky, but I want to duplicate the DMSO data and assign it to each drug. Later we’ll be splitting the plot by drug, so we can see both the drug data &lt;em&gt;and&lt;/em&gt; the DMSO data in the section.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# for background DMSO plot
fake_DMSO_drug &amp;lt;- data.frame()
for (i in (merged.df$Drug %&amp;gt;% unique())){
  print(i)
  fake_DMSO_drug &amp;lt;- rbind(fake_DMSO_drug, merged.df %&amp;gt;% filter(Drug==&amp;#39;DMSO&amp;#39;) %&amp;gt;% mutate(Drug = i, Well.names=paste0(&amp;#39;0DMSO_&amp;#39;, i), DMSO=&amp;#39;Yes&amp;#39;))
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;20(S&amp;quot;
## [1] &amp;quot;3-Am&amp;quot;
## [1] &amp;quot;Brom&amp;quot;
## [1] &amp;quot;Cili&amp;quot;
## [1] &amp;quot;Ctrl&amp;quot;
## [1] &amp;quot;DMSO&amp;quot;
## [1] &amp;quot;ETP&amp;quot;
## [1] &amp;quot;G-Pr&amp;quot;
## [1] &amp;quot;GANT&amp;quot;
## [1] &amp;quot;HA 1&amp;quot;
## [1] &amp;quot;IMR-&amp;quot;
## [1] &amp;quot;IWP-&amp;quot;
## [1] &amp;quot;IWR-&amp;quot;
## [1] &amp;quot;LGK-&amp;quot;
## [1] &amp;quot;LY41&amp;quot;
## [1] &amp;quot;Metf&amp;quot;
## [1] &amp;quot;PJ 3&amp;quot;
## [1] &amp;quot;SANT&amp;quot;
## [1] &amp;quot;Sodi&amp;quot;
## [1] &amp;quot;Tori&amp;quot;
## [1] &amp;quot;UNC&amp;quot;
## [1] &amp;quot;Valp&amp;quot;
## [1] &amp;quot;Wnt-&amp;quot;
## [1] &amp;quot;WYE&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# order drugs by median area
drug_order &amp;lt;- merged.df %&amp;gt;% group_by(Drug) %&amp;gt;% summarise(MedianArea=median(Area)) %&amp;gt;% arrange(MedianArea) %&amp;gt;% pull(Drug)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;ridgeline-plot-showing-each-well-separately&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;ridgeline plot, showing each well separately&lt;/h1&gt;
&lt;p&gt;Several wells got the same drugs. So there are multiple plots per drug.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bind_rows(merged.df %&amp;gt;% mutate(DMSO=&amp;#39;No&amp;#39;),fake_DMSO_drug) %&amp;gt;% 
  filter(Drug!=&amp;#39;DMSO&amp;#39;, Drug!=&amp;#39;Pyr&amp;#39;) %&amp;gt;% # don&amp;#39;t need DMSO plot now and Pyr is empty
  mutate(Drug=factor(Drug, levels=drug_order)) %&amp;gt;% # reorder drugs by drug_order above 
  ggplot(aes(y = Drug, x=log2(Area), group=Well.names, fill=DMSO)) +
  geom_density_ridges(alpha=0.6) + 
  theme_ridges() + 
  scale_fill_brewer(palette = &amp;#39;Set1&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Picking joint bandwidth of 0.258&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-04-12-let-s-plot-5-ridgeline-density-plots_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;same-but-merging-all-wells-together&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Same, but merging all wells together&lt;/h1&gt;
&lt;p&gt;Now merge all the wells together. Notice how the group is now &lt;code&gt;Well.names2&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bind_rows(merged.df %&amp;gt;% 
            mutate(DMSO=&amp;#39;No&amp;#39;, Well.names2=paste0(&amp;#39;Orig&amp;#39;, Drug)),
          fake_DMSO_drug %&amp;gt;% 
            mutate(Well.names2 = Well.names)) %&amp;gt;% 
  filter(Drug!=&amp;#39;DMSO&amp;#39;, Drug!=&amp;#39;Pyro&amp;#39;) %&amp;gt;% # dont&amp;#39; need DMSO plot now and Pyroxamine is empty
  mutate(Drug=factor(Drug, levels=drug_order)) %&amp;gt;% # reorder drugs by drug_order above 
  ggplot(aes(y = Drug, x = log2(Area), group=Well.names2, fill=DMSO)) +
  geom_density_ridges(alpha=0.6) + 
  theme_ridges() + 
  scale_fill_brewer(palette = &amp;#39;Set1&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Picking joint bandwidth of 0.204&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-04-12-let-s-plot-5-ridgeline-density-plots_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;theres-a-large-variation-in-the-number-of-counts&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;There’s a large variation in the number of counts&lt;/h1&gt;
&lt;p&gt;How did I know? Because a bunch of the density plots were super wavy - which means (almost always) that the number of counts in that sample is very low. Low numbers = high variance.&lt;/p&gt;
&lt;p&gt;So IMR, IMP, Tori, and WYE are &lt;em&gt;problem&lt;/em&gt; tests. Perhaps they are just killing the cells? Something for Davide to examine.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cell_area_counts_by_drug &amp;lt;- merged.df %&amp;gt;% 
  group_by(Drug) %&amp;gt;% 
  summarise(Count=n())

cell_area_counts_by_drug  %&amp;gt;% 
  ggplot(aes(x=Drug, y=Count)) +
  geom_bar(stat=&amp;#39;identity&amp;#39;) + 
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-04-12-let-s-plot-5-ridgeline-density-plots_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Are you in genomics and building models? Stop using ROC - use PR</title>
      <link>/./post/are-you-in-genomics-stop-using-roc-use-pr/</link>
      <pubDate>Sat, 03 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/./post/are-you-in-genomics-stop-using-roc-use-pr/</guid>
      <description>&lt;div id=&#34;tldr&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;tldr&lt;/h2&gt;
&lt;p&gt;Area Under the Curve (AUC) of Receiver Operating Characteristic (ROC) is a terrible metric for a genomics problem. Do not use it. This metric also goes by AUC or AUROC. Use Precision Recall AUC.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;inspiration-for-this-post&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Inspiration for this post&lt;/h2&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;I am working on a machine learning problem in genomics&lt;/li&gt;
&lt;li&gt;I was getting really confused why AUROC was so worthless&lt;/li&gt;
&lt;li&gt;scienceTwitter featuring Anshul Kundaje &lt;img src=&#34;/./img/anshul_ROC_PR.png&#34; alt=&#34;https://twitter.com/anshulkundaje/status/965623852209352704&#34; /&gt;&lt;/li&gt;
&lt;li&gt;I want to save you (some time)&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;whats-a-roc&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What’s a ROC?&lt;/h2&gt;
&lt;p&gt;First, you do have to use them because everyone uses them and expects them, but try to move them in the supplementary figures. Eventually the field will stop expecting this and demand to see a useful metric - like AUC of Precision Recall. More on this later.&lt;/p&gt;
&lt;p&gt;Before we discuss how an ROC is constructed, let’s see first see a &lt;em&gt;Confusion Matrix&lt;/em&gt; of a model.&lt;/p&gt;
&lt;table&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Reference&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Positive&lt;/td&gt;
&lt;td&gt;Negative&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Prediction&lt;/td&gt;
&lt;td&gt;Positive&lt;/td&gt;
&lt;td&gt;236&lt;/td&gt;
&lt;td&gt;103&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Negative&lt;/td&gt;
&lt;td&gt;174&lt;/td&gt;
&lt;td&gt;116,952&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The two axes of a ROC are:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;True Positive Rate (TPR) / Sensitivity / Recall (I assume it goes by so many names because different fields kept re-inventing it)&lt;/li&gt;
&lt;li&gt;False Positive Rate (FPR)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The TPR of the model is: &lt;span class=&#34;math display&#34;&gt;\[\frac{236}{236 + 174}\approx0.576\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The FPR of the model is: &lt;span class=&#34;math display&#34;&gt;\[\frac{103}{103 + 116,952}\approx0.001\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The model does not actually spit out positive or negative. It gives out &lt;em&gt;probabilities&lt;/em&gt; that a given item is positive or negative. If we change the probabilities cutoff to different values (to make the classification more or less stringent) we can get different TPR and FPR. This is done to generate TPR and FPR from 0 to 1 and a line is plotted. The AUC for the ROC (AUROC) is then calculated by measuring the area under the curve. Either by taking the &lt;a href=&#34;https://en.wikipedia.org/wiki/Receiver_operating_characteristic&#34;&gt;integral or a trapezoidal approximation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;A larger AUROC is better. 1 is perfect. 0.5 is a bunch of grad students flipping coins.&lt;/p&gt;
&lt;p&gt;Now we have a rough idea of ROC works. Now let’s do some machine learning and see ROC works in practice.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;machine-learning&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Machine Learning&lt;/h2&gt;
&lt;p&gt;Load data. Briefly, they are ClinVar variants for a variety of eye disease. They’ve been classified as &lt;code&gt;Pathogenic&lt;/code&gt; or &lt;code&gt;NotPathogenic&lt;/code&gt; by groups submitting to ClinVar (ClinVar uses the term &lt;em&gt;benign&lt;/em&gt;). Each variant has been labeled with a variety of pathogenicity scores, population frequency info, and &lt;em&gt;in silico&lt;/em&gt; consequences. Empty values were assigned &lt;code&gt;-1&lt;/code&gt; (brief aside: I’m not sure if imputing missing data is a good idea here). One hot encoding was done to turn categorical information into numeric vectors. Each predictor (column) was centered and scaled.&lt;/p&gt;
&lt;p&gt;You can download the &lt;code&gt;clinvar_one_hot_CS_toy_set.tsv.gz&lt;/code&gt; file &lt;a href=&#34;https://github.com/davemcg/eye_var_Pathogenicity/blob/master/processed_data/clinvar_one_hot_CS_toy_set.tsv.gz&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Attaching packages ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.2.1 ──&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✔ ggplot2 2.2.1     ✔ purrr   0.2.4
## ✔ tibble  1.4.2     ✔ dplyr   0.7.4
## ✔ tidyr   0.7.2     ✔ stringr 1.2.0
## ✔ readr   1.1.1     ✔ forcats 0.2.0&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Conflicts ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
## ✖ dplyr::filter() masks stats::filter()
## ✖ dplyr::lag()    masks stats::lag()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;clinvar &amp;lt;- read_tsv(&amp;#39;~/git/eye_var_Pathogenicity/processed_data/clinvar_one_hot_CS_toy_set.tsv.gz&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Parsed with column specification:
## cols(
##   Status = col_character(),
##   is_lof = col_double(),
##   impact_severity = col_double(),
##   polyphen_score = col_double(),
##   sift_score = col_double(),
##   revel = col_double(),
##   cadd_phred = col_double(),
##   af_exac_all = col_double(),
##   pli = col_double(),
##   n_syn = col_double(),
##   n_mis = col_double(),
##   precessive = col_double(),
##   fathmm_mkl_coding_score = col_double()
## )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# set levels for status
clinvar $Status &amp;lt;- factor(clinvar$Status, levels=c(&amp;#39;Pathogenic&amp;#39;,&amp;#39;NotPathogenic&amp;#39;))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;quickly-check-our-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Quickly check our data&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;Status&lt;/code&gt; is the crucial column - it has the answer key&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;clinvar$Status %&amp;gt;% table()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## .
##    Pathogenic NotPathogenic 
##           186          8246&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Predictors&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;clinvar %&amp;gt;% select(-Status) %&amp;gt;% colnames()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;is_lof&amp;quot;                  &amp;quot;impact_severity&amp;quot;        
##  [3] &amp;quot;polyphen_score&amp;quot;          &amp;quot;sift_score&amp;quot;             
##  [5] &amp;quot;revel&amp;quot;                   &amp;quot;cadd_phred&amp;quot;             
##  [7] &amp;quot;af_exac_all&amp;quot;             &amp;quot;pli&amp;quot;                    
##  [9] &amp;quot;n_syn&amp;quot;                   &amp;quot;n_mis&amp;quot;                  
## [11] &amp;quot;precessive&amp;quot;              &amp;quot;fathmm_mkl_coding_score&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;split-data-into-training-and-testing-sets&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Split data into training and testing sets&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;clinvar$index &amp;lt;- seq(1:nrow(clinvar))
set.seed(9253)
train_set &amp;lt;- clinvar %&amp;gt;% group_by(Status) %&amp;gt;% sample_frac(0.5)
test_set &amp;lt;- clinvar %&amp;gt;% filter(!index %in% train_set$index)
# remove index so the models don&amp;#39;t use them to classify
train_set &amp;lt;- train_set %&amp;gt;% select(-index)
test_set &amp;lt;- test_set %&amp;gt;% select(-index)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;set-up-training-paramters&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Set up training paramters&lt;/h2&gt;
&lt;p&gt;This is a nice feature of the &lt;code&gt;caret&lt;/code&gt; package. You can customize training parameters and apply them to multiple algorithms&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(caret)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: lattice&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;caret&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following object is masked from &amp;#39;package:purrr&amp;#39;:
## 
##     lift&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# 5 fold cross validation
# twoClassSummary optimizes the algorithm for AUROC
fitControl_naive &amp;lt;- trainControl(
  classProbs=T, # we want probabilites returned for each prediction
  method = &amp;quot;cv&amp;quot;,
  number = 5,
  summaryFunction = twoClassSummary
)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;build-models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Build models&lt;/h2&gt;
&lt;p&gt;This is the big lie of machine learning. Look how trivial this is! Never mind the difficulty of all the work summarized above…&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bglmFit &amp;lt;- train(Status ~ ., data=train_set, 
                 method = &amp;#39;bayesglm&amp;#39;,
                 trControl = fitControl_naive)
rfFit &amp;lt;- train(Status ~ ., data=train_set, 
               method = &amp;#39;rf&amp;#39;,
                 trControl = fitControl_naive)
# let&amp;#39;s see how a popular pathogenicity score does alone
caddFit &amp;lt;- train(Status ~ ., data=train_set %&amp;gt;% select(Status, cadd_phred), 
                   method = &amp;#39;glm&amp;#39;,
                 trControl = fitControl_naive)


my_models &amp;lt;- list()
my_models$bglm &amp;lt;- bglmFit
my_models$rfFit &amp;lt;- rfFit
my_models$cadd &amp;lt;- caddFit&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;auroc-plot&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;AUROC Plot!&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(PRROC)
# AUROC
roc_maker &amp;lt;- function(model, data) {
  # new predictions on test set
  # don&amp;#39;t use the training set - if you are overfitting you will not get accurate idea of your models merit
  new_predictions &amp;lt;- predict(model, data, type = &amp;#39;prob&amp;#39;) %&amp;gt;%
    mutate(Answers = data$Status, 
           Prediction = case_when(Pathogenic &amp;gt; 0.5 ~ &amp;#39;Pathogenic&amp;#39;, 
                                  TRUE ~ &amp;#39;NotPathogenic&amp;#39;))
  roc.curve(scores.class0 = new_predictions %&amp;gt;% filter(Answers==&amp;#39;Pathogenic&amp;#39;) %&amp;gt;% pull(Pathogenic),
           scores.class1 = new_predictions %&amp;gt;% filter(Answers==&amp;#39;NotPathogenic&amp;#39;) %&amp;gt;% pull(Pathogenic),
           curve = T)
}

#bglm
plot(roc_maker(bglmFit, test_set))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-03-03-are-you-in-genomics-stop-using-roc-use-pr_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt; Wow! 97% AUC for a bayesian generalized linear model for predicting pathogenicity! Let’s go straight to Nature/Cell/PNAS/Science!&lt;/p&gt;
&lt;p&gt;Well, let’s plot all three predictors at once. I did make three models after all.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;roc_data &amp;lt;- data.frame()
for (i in names(my_models)){
  print(my_models[[i]]$method)
  roc &amp;lt;- roc_maker(my_models[[i]], test_set)
  out &amp;lt;- roc$curve[,1:2] %&amp;gt;% data.frame()
  colnames(out) &amp;lt;- c(&amp;#39;FPR&amp;#39;,&amp;#39;Sensitivity&amp;#39;)
  out$model &amp;lt;- i
  out$AUC &amp;lt;- roc$auc
  out$&amp;#39;Model (AUC)&amp;#39; &amp;lt;- paste0(i, &amp;#39; (&amp;#39;,round(roc$auc, 2),&amp;#39;)&amp;#39; )
  roc_data &amp;lt;- rbind(roc_data, out)
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;bayesglm&amp;quot;
## [1] &amp;quot;rf&amp;quot;
## [1] &amp;quot;glm&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;roc &amp;lt;- roc_data %&amp;gt;% 
  ggplot(aes(x=FPR, y=Sensitivity, colour=`Model (AUC)`)) + 
  geom_line() + 
  theme_minimal()  + 
  ggtitle(&amp;#39;AUROC&amp;#39;) +
  ggsci::scale_color_startrek()

roc&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-03-03-are-you-in-genomics-stop-using-roc-use-pr_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Wow, the random forests are even better! CADD alone isn’t so bad, either! 78% is almost a B, right?&lt;/p&gt;
&lt;p&gt;Well, maybe we should make those confusion matrix things I showed earlier. Just to be careful.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cm_maker &amp;lt;- function(model, data, cutoff=0.5, mode = &amp;#39;sens_spec&amp;#39;) {
  new_predictions &amp;lt;- predict(model, data, type=&amp;#39;prob&amp;#39;) %&amp;gt;%
    mutate(Answers = data$Status, Prediction = case_when(Pathogenic &amp;gt; cutoff ~ &amp;#39;Pathogenic&amp;#39;, TRUE ~ &amp;#39;NotPathogenic&amp;#39;))
  confusionMatrix(data = new_predictions$Prediction, reference = new_predictions$Answers, mode= mode)
}

for (i in names(my_models)){
  print(i)
  print(cm_maker(my_models[[i]], test_set)$table)
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;bglm&amp;quot;
##                Reference
## Prediction      Pathogenic NotPathogenic
##   Pathogenic            43            35
##   NotPathogenic         50          4088
## [1] &amp;quot;rfFit&amp;quot;
##                Reference
## Prediction      Pathogenic NotPathogenic
##   Pathogenic            56            14
##   NotPathogenic         37          4109
## [1] &amp;quot;cadd&amp;quot;
##                Reference
## Prediction      Pathogenic NotPathogenic
##   Pathogenic            10             3
##   NotPathogenic         83          4120&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Huh, these do not look so great….the TPR for the bayes glm model is only 46%. But the AUROC looked so awesome.&lt;/p&gt;
&lt;p&gt;What is happening?&lt;/p&gt;
&lt;p&gt;Well, the classes are imbalanced. ROC plots are designed to provide useful information &lt;strong&gt;when your classes are balanced&lt;/strong&gt;. You have a huge set of &lt;code&gt;NotPathogenic&lt;/code&gt; compared to &lt;code&gt;Pathogenic&lt;/code&gt;. We have 186 &lt;code&gt;Pathogenic&lt;/code&gt; and 8246 &lt;code&gt;NotPathogenic&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;A model that always guessed &lt;code&gt;NotPathogenic&lt;/code&gt; would also do great on the AUROC.&lt;/p&gt;
&lt;p&gt;How do we better represent reality?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;precision-recall-plots&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Precision Recall Plots&lt;/h2&gt;
&lt;p&gt;These plot precision against recall. The advantage compared to ROC is that they do not take into the &lt;em&gt;negative&lt;/em&gt; class. Let’s see what they look like with the same models. One thing to quickly note is that, by convention, the plots are ‘mirrored’ compared to ROC - you want your model to be in the top right for a PR plot, instead of the top left for a ROC.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# precision recall AUC
pr_maker &amp;lt;- function(model, data) {
  new_predictions &amp;lt;- predict(model, data, type = &amp;#39;prob&amp;#39;) %&amp;gt;%
    mutate(Answers = data$Status, Prediction = case_when(Pathogenic &amp;gt; 0.5 ~ &amp;#39;Pathogenic&amp;#39;, TRUE ~ &amp;#39;NotPathogenic&amp;#39;))
  pr.curve(scores.class0 = new_predictions %&amp;gt;% filter(Answers==&amp;#39;Pathogenic&amp;#39;) %&amp;gt;% pull(Pathogenic),
           scores.class1 = new_predictions %&amp;gt;% filter(Answers==&amp;#39;NotPathogenic&amp;#39;) %&amp;gt;% pull(Pathogenic),
           curve = T)
}

pr_data &amp;lt;- data.frame()
for (i in names(my_models)){
  print(my_models[[i]]$method)
  pr &amp;lt;- pr_maker(my_models[[i]], test_set)
  out &amp;lt;- pr$curve[,1:2] %&amp;gt;% data.frame()
  colnames(out) &amp;lt;- c(&amp;#39;Recall&amp;#39;,&amp;#39;Precision&amp;#39;)
  out$AUC &amp;lt;- pr$auc.integral
  out$model &amp;lt;- i
  out$&amp;#39;Model (AUC)&amp;#39; &amp;lt;- paste0(i, &amp;#39; (&amp;#39;,round(pr$auc.integral,2),&amp;#39;)&amp;#39; )
  pr_data &amp;lt;- rbind(pr_data, out)
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;bayesglm&amp;quot;
## [1] &amp;quot;rf&amp;quot;
## [1] &amp;quot;glm&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pr &amp;lt;- pr_data %&amp;gt;% 
  ggplot(aes(x=Recall, y=Precision, colour=`Model (AUC)`)) + 
  geom_line() + 
  theme_minimal() + 
  ggtitle(&amp;#39;Precision Recall Curve&amp;#39;) +
  ggsci::scale_color_startrek()

pr&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-03-03-are-you-in-genomics-stop-using-roc-use-pr_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This looks like a more reasonable way to assess performance. Also notice how the RF and bayes GLM have subtantially different performance when being assessed like this, even though the AUROC was only 0.02 apart.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Why again do I have to use PR plots in genomics - I balanced my two classes when I trained the model! Well because in actual problem space, the genome, the problems are &lt;em&gt;always&lt;/em&gt; wildly imbalanced between classes. The human genome is three gigabases (3e9) in size.&lt;/p&gt;
&lt;p&gt;Using knn to identify promoters? There are 20,000 genes * 1000 base pair (bp) promoter = 2e6 bp.&lt;/p&gt;
&lt;p&gt;3e9 / 2e6 = 1500:1 ratio&lt;/p&gt;
&lt;p&gt;Writing a deep convoluational neural network to identify CTCF binding sites? CTCF binds around 50,000 sites * 14bp = 7e5.&lt;/p&gt;
&lt;p&gt;3e9 / 7e5 = 4300:1 ratio&lt;/p&gt;
&lt;p&gt;Using random forests to create a pathogenicity metric? Well, in a given genome only 1-2 positions will contribute to a mendelian disorder.&lt;/p&gt;
&lt;p&gt;3e9 / 2 = 1.5e9:1 ratio&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;a-little-more-reading&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;A little more reading&lt;/h2&gt;
&lt;p&gt;If you have some more time, go read Lior Pachter’s &lt;a href=&#34;https://liorpachter.wordpress.com/2016/12/21/confusion-matrix-terminology-is-taxicab-trigonometry/&#34;&gt;post&lt;/a&gt; on metrics for assessing performance.&lt;/p&gt;
&lt;p&gt;Also check this tweet &lt;a href=&#34;https://twitter.com/michaelhoffman/status/969261327331061760&#34;&gt;conversation&lt;/a&gt; between Michael Hoffman and Anshul Kundaje.&lt;/p&gt;
&lt;p&gt;There are also several web posts that explain &lt;a href=&#34;https://www.kaggle.com/general/7517&#34;&gt;why&lt;/a&gt; &lt;a href=&#34;https://www.kaggle.com/lct14558/imbalanced-data-why-you-should-not-use-roc-curve&#34;&gt;ROC&lt;/a&gt; is bad for unbalanced classes and even a published &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4349800/&#34;&gt;paper&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Let’s Plot 4: R vs Excel, Round 1</title>
      <link>/./post/let-s-plot-4-r-vs-excel/</link>
      <pubDate>Thu, 01 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/./post/let-s-plot-4-r-vs-excel/</guid>
      <description>&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#data&#34;&gt;Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#cleaning&#34;&gt;Cleaning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#reformatting&#34;&gt;Reformatting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#box-plot&#34;&gt;Box Plot&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#boxplot-with-all-the-data-displayed&#34;&gt;Boxplot with all the data displayed&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#i-used-to-prefer-violin-plots&#34;&gt;I used to prefer violin plots&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#im-a-fan-of-beeswarm-plots-with-boxplots&#34;&gt;I’m a fan of beeswarm plots with boxplots&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#doing-statistics.&#34;&gt;Doing statistics.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#session&#34;&gt;Session&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;The battle that we’ve all been waiting for. Excel vs. R. Bar plot versus a plot that actually shows the data.&lt;/p&gt;
&lt;p&gt;Yeah, this isn’t a fair fight.&lt;/p&gt;
&lt;p&gt;Bar plots are terrible. Why? Simple. They don’t show what your data looks like. A bar plot gives you zero idea how many data points there are. You can add error bars, but you don’t know if you are looking at standard error or standard deviation.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/./img/excel_bar_plot_bad.png&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;Box plots are &lt;em&gt;much&lt;/em&gt; better. They display useful information like minimum, maximum, quartiles, and median. But they still can really mislead depending on how your data is structured.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/./img/BoxViolinSmaller.gif&#34; alt=&#34;https://www.autodeskresearch.com/publications/samestats&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;&lt;a href=&#34;https://www.autodeskresearch.com/publications/samestats&#34; class=&#34;uri&#34;&gt;https://www.autodeskresearch.com/publications/samestats&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/./img/journal.pbio.1002128.g001.png&#34; alt=&#34;https://doi.org/10.1371/journal.pbio.1002128&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;&lt;a href=&#34;https://doi.org/10.1371/journal.pbio.1002128&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1371/journal.pbio.1002128&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Why do so many scientists keep using bar (or box) plots? Well, simple. Excel makes bar plots with one click. Excel &lt;em&gt;can&lt;/em&gt; make box plots, but it is &lt;a href=&#34;https://support.office.com/en-us/article/create-a-box-plot-10204530-8cdf-40fe-a711-2eb9785e510f&#34;&gt;not easy&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Excel, as far as I can tell, can’t do what I’m about to show you: violin plots or box plots with the &lt;em&gt;raw data displayed inline&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;As a bonus, I made a short video to demonstrate how you can skip the below data cleaning in R with some clicking and dragging in Excel - then just plot in R.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=_teDfnv0gUE&amp;amp;feature=youtu.be&#34;&gt;Click here&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data&lt;/h2&gt;
&lt;p&gt;A variety of eye measurements between a wild-type zebrafish line and a mutant line.&lt;/p&gt;
&lt;p&gt;You can get the excel file &lt;a href=&#34;https://github.com/davemcg/Let_us_plot/blob/master/004_r_vs_excel/Compiled%20eye%20measurements.xlsx&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;tidyverse&amp;#39; was built under R version 3.4.2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Attaching packages ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.2.1 ──&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✔ ggplot2 2.2.1     ✔ purrr   0.2.4
## ✔ tibble  1.4.2     ✔ dplyr   0.7.4
## ✔ tidyr   0.7.2     ✔ stringr 1.2.0
## ✔ readr   1.1.1     ✔ forcats 0.2.0&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;tibble&amp;#39; was built under R version 3.4.3&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;tidyr&amp;#39; was built under R version 3.4.2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;purrr&amp;#39; was built under R version 3.4.2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;dplyr&amp;#39; was built under R version 3.4.2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Conflicts ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
## ✖ dplyr::filter() masks stats::filter()
## ✖ dplyr::lag()    masks stats::lag()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggsci)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;ggsci&amp;#39; was built under R version 3.4.2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggbeeswarm)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;ggbeeswarm&amp;#39; was built under R version 3.4.1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;micro &amp;lt;- readxl::read_xlsx(&amp;#39;~/git/Let_us_plot/004_r_vs_excel/Compiled eye measurements.xlsx&amp;#39;)
head(micro)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 13
##   X__1  Day3   X__2  Day5  X__3  X__4  X__5  X__6  X__7  X__8  X__9  X__10
##   &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;lgl&amp;gt; &amp;lt;lgl&amp;gt; &amp;lt;lgl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;
## 1 Fish  WT/Het Mut   WT/H… Mut   NA    NA    NA    &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt; 
## 2 1     6.099… 4.80… 7.29… 6.70… NA    NA    NA    &amp;lt;NA&amp;gt;  Day3  &amp;lt;NA&amp;gt;  Day5 
## 3 2     7.099… 5.29… 7.19… 8.20… NA    NA    NA    &amp;lt;NA&amp;gt;  WT/H… Mut   WT/H…
## 4 3     0.05   5.39… 7.69… 7.09… NA    NA    NA    avg   6.06… 5.37… 7.31…
## 5 4     6.3E-2 5.80… 7.19… 6.60… NA    NA    NA    &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt; 
## 6 5     6.400… 5.80… 6.09… 7.09… NA    NA    NA    se    1.50… 1.12… 1.12…
## # ... with 1 more variable: X__11 &amp;lt;chr&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;cleaning&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Cleaning&lt;/h2&gt;
&lt;p&gt;OK, a bit messy since this isn’t a computer-formatted file. I’m going to grab the relevant data (ignoring the summarize stats) by looking at the data and slicing and selecting by coordinates. Not worth doing anything fancier (regex, grep, neural network) to automate this.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# clean
micro &amp;lt;- micro %&amp;gt;% 
  slice(2:31) %&amp;gt;% 
  select(`Fish ID` = X__1, 
         Day3_Het = Day3, 
         Day3_Mut = X__2, 
         Day5_Het = Day5, 
         Day5_Mut = X__3) %&amp;gt;% 
  mutate(Day3_Het = as.numeric(Day3_Het),
         Day3_Mut = as.numeric(Day3_Mut),
         Day5_Het = as.numeric(Day5_Het),
         Day5_Mut = as.numeric(Day5_Mut))
micro&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 30 x 5
##    `Fish ID` Day3_Het Day3_Mut Day5_Het Day5_Mut
##    &amp;lt;chr&amp;gt;        &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
##  1 1           0.0610   0.0480   0.0730   0.0670
##  2 2           0.0710   0.0530   0.0720   0.0820
##  3 3           0.0500   0.0540   0.0770   0.0710
##  4 4           0.0630   0.0580   0.0720   0.0660
##  5 5           0.0640   0.0580   0.0610   0.0710
##  6 6           0.0650   0.0530   0.0750   0.0700
##  7 7           0.0580   0.0560   0.0800   0.0700
##  8 8           0.0570   0.0530   0.0630   0.0760
##  9 9           0.0650   0.0680   0.0730   0.0710
## 10 10          0.0620   0.0610   0.0720   0.0750
## # ... with 20 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;reformatting&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Reformatting&lt;/h2&gt;
&lt;p&gt;We are also going to have to reformat the data since Date and Genotype are mixed together in a column. Would rather have all the data in one column and the date and genotype in their own columns. Confused? Well, just compare the above data to the modified data.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Remember&lt;/strong&gt; - if this is too intimidating right now, then it is fine to just manually move the data around with Excel to make it look like the below data. Then you can just focus on making the figure.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# wide to long
micro &amp;lt;- micro %&amp;gt;% 
  gather(Date_Genotype, Size, -`Fish ID`) %&amp;gt;% 
  separate(Date_Genotype, c(&amp;#39;Date&amp;#39;,&amp;#39;Genotype&amp;#39;))
micro&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 120 x 4
##    `Fish ID` Date  Genotype   Size
##  * &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;     &amp;lt;dbl&amp;gt;
##  1 1         Day3  Het      0.0610
##  2 2         Day3  Het      0.0710
##  3 3         Day3  Het      0.0500
##  4 4         Day3  Het      0.0630
##  5 5         Day3  Het      0.0640
##  6 6         Day3  Het      0.0650
##  7 7         Day3  Het      0.0580
##  8 8         Day3  Het      0.0570
##  9 9         Day3  Het      0.0650
## 10 10        Day3  Het      0.0620
## # ... with 110 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;box-plot&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Box Plot&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;micro %&amp;gt;% ggplot(aes(x=Genotype, y=Size, colour=Genotype)) + 
  facet_wrap(~Date) +
  geom_boxplot() + 
  theme_minimal() + 
  scale_color_aaas()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-03-01-let-s-plot-r-vs-excel_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;boxplot-with-all-the-data-displayed&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Boxplot with all the data displayed&lt;/h2&gt;
&lt;p&gt;So easy with ggplot2&lt;/p&gt;
&lt;p&gt;Remember to have your &lt;code&gt;geom_boxplot&lt;/code&gt; remove display of outliers (since you are showing them now with &lt;code&gt;geom_jitter&lt;/code&gt;)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;micro %&amp;gt;% ggplot(aes(x=Genotype, y=Size, colour=Genotype)) + facet_wrap(~Date) +
  geom_boxplot(outlier.shape = NA) + 
  geom_jitter() + 
  theme_minimal() + 
  scale_color_aaas()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-03-01-let-s-plot-r-vs-excel_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;i-used-to-prefer-violin-plots&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;I used to prefer violin plots&lt;/h2&gt;
&lt;p&gt;But the smoothing for outlier points can be misleading. They also confuse people who haven’t seen them before &lt;strong&gt;and&lt;/strong&gt; you lose the quartile / median info a boxplot provides.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;micro %&amp;gt;% ggplot(aes(x=Genotype, y=Size, colour=Genotype)) + facet_wrap(~Date) +
  geom_violin() + 
  geom_jitter() + 
  theme_minimal() + 
  scale_color_aaas()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-03-01-let-s-plot-r-vs-excel_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;im-a-fan-of-beeswarm-plots-with-boxplots&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;I’m a fan of beeswarm plots with boxplots&lt;/h2&gt;
&lt;p&gt;You get the violin plot structure and the quartile / median info of boxplots. Win win.&lt;/p&gt;
&lt;p&gt;I’ve reduced the alpha (opacity) of the points to put more emphasis on the boxplot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;micro %&amp;gt;% ggplot(aes(x=Genotype, y=Size, colour=Genotype)) + facet_wrap(~Date) +
  geom_boxplot(outlier.shape = NA) + 
  geom_quasirandom(alpha=0.4) + 
  theme_minimal() + 
  scale_color_aaas()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-03-01-let-s-plot-r-vs-excel_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;doing-statistics.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Doing statistics.&lt;/h2&gt;
&lt;p&gt;Are the differences significant between genotype on Day3 and Day5? More precisely, can we reject the null hypothesis (no mean difference in size)?&lt;/p&gt;
&lt;p&gt;Let’s use the venerable t.test. The data eyeballs as normally distributed. I’m using &lt;code&gt;dplyr&lt;/code&gt; &lt;code&gt;filter&lt;/code&gt; to test Day 3 and Day 5 separately, testing for differences in mean between genotypes (hence the right half of the equation below ends with &lt;code&gt;pull(Genotype)&lt;/code&gt;)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Day 3
t.test(micro %&amp;gt;% filter(Date==&amp;#39;Day3&amp;#39;) %&amp;gt;% pull(Size) ~ micro %&amp;gt;% filter(Date==&amp;#39;Day3&amp;#39;) %&amp;gt;% pull(Genotype))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Welch Two Sample t-test
## 
## data:  micro %&amp;gt;% filter(Date == &amp;quot;Day3&amp;quot;) %&amp;gt;% pull(Size) by micro %&amp;gt;% filter(Date == &amp;quot;Day3&amp;quot;) %&amp;gt;% pull(Genotype)
## t = 3.5888, df = 53.629, p-value = 0.0007197
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  0.003029977 0.010703357
## sample estimates:
## mean in group Het mean in group Mut 
##        0.06060000        0.05373333&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Day 5
t.test(micro %&amp;gt;% filter(Date==&amp;#39;Day5&amp;#39;) %&amp;gt;% pull(Size) ~ micro %&amp;gt;% filter(Date==&amp;#39;Day5&amp;#39;) %&amp;gt;% pull(Genotype))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Welch Two Sample t-test
## 
## data:  micro %&amp;gt;% filter(Date == &amp;quot;Day5&amp;quot;) %&amp;gt;% pull(Size) by micro %&amp;gt;% filter(Date == &amp;quot;Day5&amp;quot;) %&amp;gt;% pull(Genotype)
## t = 1.4851, df = 52.164, p-value = 0.1435
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.001029920  0.006896587
## sample estimates:
## mean in group Het mean in group Mut 
##        0.07313333        0.07020000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Yes for Day 3, no for Day 5.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;session&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Session&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::session_info()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Session info -------------------------------------------------------------&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  setting  value                       
##  version  R version 3.4.0 (2017-04-21)
##  system   x86_64, darwin15.6.0        
##  ui       X11                         
##  language (EN)                        
##  collate  en_US.UTF-8                 
##  tz       America/New_York            
##  date     2018-03-01&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Packages -----------------------------------------------------------------&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  package    * version    date       source                          
##  assertthat   0.2.0      2017-04-11 CRAN (R 3.4.0)                  
##  backports    1.1.1      2017-09-25 CRAN (R 3.4.2)                  
##  base       * 3.4.0      2017-04-21 local                           
##  beeswarm     0.2.3      2016-04-25 CRAN (R 3.4.0)                  
##  bindr        0.1        2016-11-13 CRAN (R 3.4.0)                  
##  bindrcpp   * 0.2        2017-06-17 CRAN (R 3.4.0)                  
##  blogdown     0.5        2018-01-24 CRAN (R 3.4.3)                  
##  bookdown     0.6        2018-01-25 CRAN (R 3.4.3)                  
##  broom        0.4.3      2017-11-20 CRAN (R 3.4.0)                  
##  cellranger   1.1.0      2016-07-27 CRAN (R 3.4.0)                  
##  cli          1.0.0      2017-11-05 CRAN (R 3.4.2)                  
##  colorspace   1.3-2      2016-12-14 CRAN (R 3.4.0)                  
##  compiler     3.4.0      2017-04-21 local                           
##  crayon       1.3.4      2017-09-16 CRAN (R 3.4.1)                  
##  datasets   * 3.4.0      2017-04-21 local                           
##  devtools     1.13.4     2017-11-09 CRAN (R 3.4.2)                  
##  digest       0.6.12     2017-01-27 CRAN (R 3.4.0)                  
##  dplyr      * 0.7.4      2017-09-28 CRAN (R 3.4.2)                  
##  evaluate     0.10.1     2017-06-24 CRAN (R 3.4.1)                  
##  forcats    * 0.2.0      2017-01-23 CRAN (R 3.4.0)                  
##  foreign      0.8-69     2017-06-22 CRAN (R 3.4.1)                  
##  ggbeeswarm * 0.6.0      2017-08-07 CRAN (R 3.4.1)                  
##  ggplot2    * 2.2.1      2016-12-30 CRAN (R 3.4.0)                  
##  ggsci      * 2.8        2017-09-30 CRAN (R 3.4.2)                  
##  glue         1.2.0      2017-10-29 CRAN (R 3.4.2)                  
##  graphics   * 3.4.0      2017-04-21 local                           
##  grDevices  * 3.4.0      2017-04-21 local                           
##  grid         3.4.0      2017-04-21 local                           
##  gtable       0.2.0      2016-02-26 CRAN (R 3.4.0)                  
##  haven        1.1.0      2017-07-09 CRAN (R 3.4.0)                  
##  hms          0.3        2016-11-22 CRAN (R 3.4.0)                  
##  htmltools    0.3.6      2017-04-28 CRAN (R 3.4.0)                  
##  httr         1.3.1      2017-08-20 CRAN (R 3.4.1)                  
##  jsonlite     1.5        2017-06-01 CRAN (R 3.4.0)                  
##  knitr        1.17       2017-08-10 CRAN (R 3.4.1)                  
##  labeling     0.3        2014-08-23 CRAN (R 3.4.0)                  
##  lattice      0.20-35    2017-03-25 CRAN (R 3.4.0)                  
##  lazyeval     0.2.1      2017-10-29 CRAN (R 3.4.2)                  
##  lubridate    1.7.1      2017-11-03 CRAN (R 3.4.2)                  
##  magrittr     1.5        2014-11-22 CRAN (R 3.4.0)                  
##  memoise      1.1.0      2017-04-21 CRAN (R 3.4.0)                  
##  methods    * 3.4.0      2017-04-21 local                           
##  mnormt       1.5-5      2016-10-15 CRAN (R 3.4.0)                  
##  modelr       0.1.1      2017-07-24 CRAN (R 3.4.1)                  
##  munsell      0.4.3      2016-02-13 CRAN (R 3.4.0)                  
##  nlme         3.1-131    2017-02-06 CRAN (R 3.4.0)                  
##  parallel     3.4.0      2017-04-21 local                           
##  pillar       1.1.0      2018-01-14 cran (@1.1.0)                   
##  pkgconfig    2.0.1      2017-03-21 CRAN (R 3.4.0)                  
##  plyr         1.8.4      2016-06-08 CRAN (R 3.4.0)                  
##  psych        1.7.8      2017-09-09 CRAN (R 3.4.0)                  
##  purrr      * 0.2.4      2017-10-18 CRAN (R 3.4.2)                  
##  R6           2.2.2      2017-06-17 CRAN (R 3.4.0)                  
##  Rcpp         0.12.13    2017-09-28 CRAN (R 3.4.2)                  
##  readr      * 1.1.1      2017-05-16 CRAN (R 3.4.0)                  
##  readxl       1.0.0      2017-04-18 CRAN (R 3.4.0)                  
##  reshape2     1.4.2      2016-10-22 CRAN (R 3.4.0)                  
##  rlang        0.1.6      2017-12-21 cran (@0.1.6)                   
##  rmarkdown    1.8        2017-11-17 CRAN (R 3.4.2)                  
##  rprojroot    1.2        2017-01-16 CRAN (R 3.4.0)                  
##  rstudioapi   0.7        2017-09-07 CRAN (R 3.4.1)                  
##  rvest        0.3.2      2016-06-17 CRAN (R 3.4.0)                  
##  scales       0.5.0.9000 2017-09-20 Github (hadley/scales@d767915)  
##  stats      * 3.4.0      2017-04-21 local                           
##  stringi      1.1.6      2017-11-17 CRAN (R 3.4.2)                  
##  stringr    * 1.2.0      2017-02-18 CRAN (R 3.4.0)                  
##  tibble     * 1.4.2      2018-01-22 cran (@1.4.2)                   
##  tidyr      * 0.7.2      2017-10-16 CRAN (R 3.4.2)                  
##  tidyselect   0.2.3      2017-11-06 CRAN (R 3.4.2)                  
##  tidyverse  * 1.2.1      2017-11-14 CRAN (R 3.4.2)                  
##  tools        3.4.0      2017-04-21 local                           
##  utf8         1.1.3      2018-01-03 cran (@1.1.3)                   
##  utils      * 3.4.0      2017-04-21 local                           
##  vipor        0.4.5      2017-03-22 CRAN (R 3.4.0)                  
##  withr        2.1.0.9000 2017-11-22 Github (jimhester/withr@fe81c00)
##  xfun         0.1        2018-01-22 CRAN (R 3.4.3)                  
##  xml2         1.1.1      2017-01-24 CRAN (R 3.4.0)                  
##  yaml         2.1.14     2016-11-12 CRAN (R 3.4.0)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Let’s Plot 3: Base pair resolution NGS (exome) coverage plots - Part 2</title>
      <link>/./post/let-s-plot-3-base-pair-resolution-ngs-exome-coverage-plots/</link>
      <pubDate>Thu, 08 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/./post/let-s-plot-3-base-pair-resolution-ngs-exome-coverage-plots/</guid>
      <description>&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#call-mosdepth-on-bam-to-calculate-bp-specific-read-depth&#34;&gt;Call mosdepth on bam to calculate bp-specific read depth&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#intersect-base-pair-depth-info-with-transcript-and-exon-number&#34;&gt;Intersect base pair depth info with transcript and exon number&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#now-its-r-time&#34;&gt;Now it’s R time!&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#prepare-metadata&#34;&gt;Prepare Metadata&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#load-mosdepth-bedtools-intersect-data-and-prep&#34;&gt;Load mosdepth / bedtools intersect data and prep&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#plot-maker-version-1&#34;&gt;Plot Maker, version 1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#version-2&#34;&gt;Version 2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sessioninfo&#34;&gt;sessionInfo()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;This is a barebones (but detailed enough, I hope) discussion of how to take a bam file, extract base pair resolution coverage data, then finagle the data into coverage plots by gene and exon. No data will be given for the below code. I’m not sharing a bam file. Also, not much point to sharing the bed, HGNC name, and gtf file, as there’s a decent chance they won’t work for your bam.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;call-mosdepth-on-bam-to-calculate-bp-specific-read-depth&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Call mosdepth on bam to calculate bp-specific read depth&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/brentp/mosdepth&#34;&gt;mosdepth&lt;/a&gt;, by default, will generate base pair resolution coverage across the entire genome. Another fantastic tool from Brent Peterson and Aaron Quinlan (some point I’ll do a gushy post on &lt;a href=&#34;http://peddy.readthedocs.io/en/latest/&#34;&gt;all&lt;/a&gt; &lt;a href=&#34;http://gemini.readthedocs.io/en/latest/&#34;&gt;of&lt;/a&gt; &lt;a href=&#34;http://bedtools.readthedocs.io/en/latest/&#34;&gt;the&lt;/a&gt; useful tools &lt;a href=&#34;http://quinlanlab.org/#software&#34;&gt;Quinlan and company have made&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;&lt;code&gt;mosdepth&lt;/code&gt; will run &lt;em&gt;very&lt;/em&gt; quickly (minutes instead of hours), compared to &lt;code&gt;bedtools genomecov&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;# bash 
sinteractive --cpus-per-task 16
module load mosdepth
mosdepth -t 16 41001412010527 41001412010527_realigned_recal.bam &amp;amp;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;intersect-base-pair-depth-info-with-transcript-and-exon-number&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Intersect base pair depth info with transcript and exon number&lt;/h2&gt;
&lt;p&gt;The intersect is to select regions overlapping exons and to label them with the transcript name and exon number present in &lt;code&gt;gencode_genes_v27lift37.codingExons.ensembl.bed.gz&lt;/code&gt;. See the code below for how to make your own.&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;# bash

# gencode_genes_v27lift37.codingExons.bed was downloaded from the UCSC table browser from genocde gene v27lift37 and &amp;#39;coding exons&amp;#39; with 0 padding were selected as the output for the bed file
# my https://github.com/davemcg/ChromosomeMappings/ convert_notation.py script was then used to convert the UCSC notation in ensembl notation, which my bam uses
# files in biowulf2:/data/mcgaugheyd/genomes/GRCh37/
module load bedtools
~/git/ChromosomeMappings/convert_notation.py -c ~/git/ChromosomeMappings/GRCh37_gencode2ensembl.txt -f gencode_genes_v27lift37.codingExons.bed | sort -k1,1 -k2,2n | gzip &amp;gt; gencode_genes_v27lift37.codingExons.ensembl.bed.gz
bedtools intersect -wa -wb -a 41001412010527.per-base.bed.gz -b /data/mcgaugheyd/genomes/GRCh37/gencode_genes_v27lift37.codingExons.ensembl.bed.gz | bgzip  &amp;gt; 41001412010527.per-base.labeled.bed.gz &amp;amp;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;now-its-r-time&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Now it’s R time!&lt;/h1&gt;
&lt;div id=&#34;prepare-metadata&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Prepare Metadata&lt;/h2&gt;
&lt;p&gt;You’ll need &lt;a href=&#34;ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_27/GRCh37_mapping/gencode.v27lift37.metadata.HGNC.gz&#34;&gt;HGNC &amp;lt;-&amp;gt; Ensembl Transcript converter&lt;/a&gt; and the &lt;a href=&#34;ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_27/GRCh37_mapping/gencode.v27lift37.basic.annotation.gtf.gz&#34;&gt;Gencode GTF&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The first file is used to match gene ‘names’ with ensembl transcript ID&lt;/p&gt;
&lt;p&gt;The second file is used to semi-accurately pick the ‘canonical’ transcript for a gene (pick the appris transcript, then the longest)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(data.table)
library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Attaching packages ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.2.1 ──&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✔ ggplot2 2.2.1     ✔ purrr   0.2.4
## ✔ tibble  1.4.2     ✔ dplyr   0.7.4
## ✔ tidyr   0.8.0     ✔ stringr 1.3.0
## ✔ readr   1.1.1     ✔ forcats 0.3.0&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Conflicts ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
## ✖ dplyr::between()   masks data.table::between()
## ✖ dplyr::filter()    masks stats::filter()
## ✖ dplyr::first()     masks data.table::first()
## ✖ dplyr::lag()       masks stats::lag()
## ✖ dplyr::last()      masks data.table::last()
## ✖ purrr::transpose() masks data.table::transpose()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(cowplot)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;cowplot&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following object is masked from &amp;#39;package:ggplot2&amp;#39;:
## 
##     ggsave&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(stringr)
metadata &amp;lt;- fread(&amp;#39;gzcat ~/GenomicData/gencode.v27lift37.metadata.HGNC.gz&amp;#39;, header=F)
colnames(metadata) &amp;lt;- c(&amp;#39;Transcript&amp;#39;,&amp;#39;Name&amp;#39;)
gencode &amp;lt;- fread(&amp;#39;gzcat ~/GenomicData/gencode.v27lift37.basic.annotation.gtf.gz&amp;#39;, header=F, skip=4)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
Read 1.8% of 1651703 rows
Read 14.5% of 1651703 rows
Read 27.9% of 1651703 rows
Read 45.4% of 1651703 rows
Read 47.8% of 1651703 rows
Read 61.1% of 1651703 rows
Read 75.1% of 1651703 rows
Read 93.2% of 1651703 rows
Read 1651703 rows and 9 (of 9) columns from 0.822 GB file in 00:00:11&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gencode2 &amp;lt;- gencode %&amp;gt;% filter(V3==&amp;#39;transcript&amp;#39;) %&amp;gt;% 
  filter(grepl(&amp;#39;appris_principal&amp;#39;, V9)) %&amp;gt;% 
  rowwise() %&amp;gt;%  
  mutate(Transcript = str_extract(V9,&amp;#39;ENST\\d{11}\\.\\d+&amp;#39;), # use regex to graph ensembl transcript 
         Gene = str_extract(V9, &amp;#39;gene_name\\s\\&amp;quot;.*?;&amp;#39;), # and the gene name
         Size=V5-V4) %&amp;gt;% 
  separate(Gene, c(&amp;#39;skip&amp;#39;,&amp;#39;Name&amp;#39;,&amp;#39;skip2&amp;#39;),&amp;#39;\&amp;quot;&amp;#39;) %&amp;gt;% # now you have to remove the &amp;#39;gene name&amp;#39; part  
  select(-skip, -skip2) %&amp;gt;% 
  group_by(Name) %&amp;gt;% top_n(1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Selecting by Size&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;load-mosdepth-bedtools-intersect-data-and-prep&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Load mosdepth / bedtools intersect data and prep&lt;/h2&gt;
&lt;p&gt;Label coverage chunks with the depth of their coverage with case_when and extract the transcript name and exon number with a bunch of &lt;code&gt;separate&lt;/code&gt; commands&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;depth_data &amp;lt;- fread(&amp;#39;gzcat ~/Desktop/41001412010527.per-base.labeled.bed.gz&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
Read 0.0% of 50955214 rows
Read 4.6% of 50955214 rows
Read 8.9% of 50955214 rows
Read 13.2% of 50955214 rows
Read 17.4% of 50955214 rows
Read 21.7% of 50955214 rows
Read 24.4% of 50955214 rows
Read 29.0% of 50955214 rows
Read 33.7% of 50955214 rows
Read 34.6% of 50955214 rows
Read 39.3% of 50955214 rows
Read 43.9% of 50955214 rows
Read 48.6% of 50955214 rows
Read 53.3% of 50955214 rows
Read 57.9% of 50955214 rows
Read 62.6% of 50955214 rows
Read 67.3% of 50955214 rows
Read 71.9% of 50955214 rows
Read 76.6% of 50955214 rows
Read 81.2% of 50955214 rows
Read 85.7% of 50955214 rows
Read 90.1% of 50955214 rows
Read 94.5% of 50955214 rows
Read 99.1% of 50955214 rows
Read 50955214 rows and 10 (of 10) columns from 4.490 GB file in 00:00:40&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dd_processed &amp;lt;- depth_data %&amp;gt;% 
  separate(V8, c(&amp;#39;Transcript&amp;#39;,&amp;#39;Rest&amp;#39;), &amp;#39;_cds_&amp;#39;) %&amp;gt;% 
  separate(Rest, c(&amp;#39;Before&amp;#39;,&amp;#39;Stuff&amp;#39;),&amp;#39;_chr&amp;#39;) %&amp;gt;% 
  separate(Before, c(&amp;#39;Exon Number&amp;#39;,&amp;#39;Num2&amp;#39;),sep=&amp;#39;_&amp;#39;) %&amp;gt;% 
  mutate(Depth = case_when(V4 &amp;lt; 10 ~ &amp;#39;&amp;lt; 10 Reads&amp;#39;, 
                           V4 &amp;lt; 20 ~ &amp;#39;&amp;lt; 20 Reads&amp;#39;, 
                           TRUE ~ &amp;#39;&amp;gt;= 20 Reads&amp;#39;)) %&amp;gt;% 
  mutate(Depth=factor(Depth, levels=c(&amp;#39;&amp;lt; 10 Reads&amp;#39;,&amp;#39;&amp;lt; 20 Reads&amp;#39;,&amp;#39;&amp;gt;= 20 Reads&amp;#39;))) %&amp;gt;% 
  mutate(Transcript=case_when(grepl(&amp;#39;_&amp;#39;,Transcript) ~ gsub(&amp;#39;_.&amp;#39;,&amp;#39;&amp;#39;,Transcript), 
                              TRUE ~ Transcript)) %&amp;gt;% 
  select(Chr=V1, Start=V2, End=V3, Read_Depth=V4, Transcript, Strand=V10, Depth, `Exon Number`, ExonStart=V6, ExonEnd=V7)

dd_processed &amp;lt;- left_join(dd_processed, metadata, by=c(&amp;#39;Transcript&amp;#39;))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;plot-maker-version-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Plot Maker, version 1&lt;/h2&gt;
&lt;p&gt;Faceted by exon. One plot per gene and using cowplot to &lt;em&gt;glue&lt;/em&gt; them together&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;genes &amp;lt;- c(&amp;#39;PAX6&amp;#39;,&amp;#39;ABCA4&amp;#39;,&amp;#39;NRL&amp;#39;,&amp;#39;CRX&amp;#39;,&amp;#39;RPGR&amp;#39;)
transcripts = gencode2 %&amp;gt;% filter(Name %in% genes) %&amp;gt;% pull(Transcript)

# set a custom color that will work even if a category is missing
scale_colour_custom &amp;lt;- function(...){
  ggplot2:::manual_scale(&amp;#39;colour&amp;#39;, 
                         values = setNames(c(&amp;#39;darkred&amp;#39;, &amp;#39;red&amp;#39;, &amp;#39;black&amp;#39;),
                                           c(&amp;#39;&amp;lt; 10 Reads&amp;#39;,&amp;#39;&amp;lt; 20 Reads&amp;#39;,&amp;#39;&amp;gt;= 20 Reads&amp;#39;)), 
                         ...)
}

plot_maker &amp;lt;- function(tx){
  num_of_exons &amp;lt;- dd_processed %&amp;gt;% filter(Transcript==tx) %&amp;gt;% pull(`Exon Number`) %&amp;gt;% as.numeric() %&amp;gt;% max()
  gene_name &amp;lt;-  dd_processed %&amp;gt;% filter(Transcript==tx) %&amp;gt;% pull(Name) %&amp;gt;% unique()
  # expand to create a row for each sequence and fill in previous values
  dd_processed %&amp;gt;% filter(Transcript==tx) %&amp;gt;% group_by(`Exon Number`) %&amp;gt;% 
    expand(Start=full_seq(c(Start,End),1)) %&amp;gt;% 
    left_join(.,  dd_processed %&amp;gt;% filter(Transcript==tx)) %&amp;gt;% # create one row per base position, grouped by Exon Number https://stackoverflow.com/questions/42866119/fill-missing-values-in-data-frame-using-dplyr-complete-within-groups
    fill(Chr:Name) %&amp;gt;% # fill missing values https://stackoverflow.com/questions/40040834/r-replace-na-with-previous-or-next-value-by-group-using-dplyr
    ungroup() %&amp;gt;% # drop the exon number grouping, so I can mutate below
    mutate(`Exon Number`= factor(`Exon Number`,levels=0:num_of_exons)) %&amp;gt;% # Ah, reordering. I need it to be a factor, but then I have to explicitly give the order   
    mutate(Depth = factor(Depth, levels=c(&amp;#39;&amp;lt; 10 Reads&amp;#39;,&amp;#39;&amp;lt; 20 Reads&amp;#39;,&amp;#39;&amp;gt;= 20 Reads&amp;#39;))) %&amp;gt;%  # create three categories for coloring
    ggplot(aes(x=Start, xend=End, y=Read_Depth, yend=Read_Depth, colour=Depth)) + 
    facet_wrap(~`Exon Number`, scales = &amp;#39;free_x&amp;#39;, nrow=1, strip.position = &amp;#39;bottom&amp;#39;) + 
    geom_point(size=0.1) + theme_minimal()+ scale_colour_custom() +  # use my custom color set above for my three categories
    theme(axis.text.x=element_blank(), 
          axis.ticks.x = element_blank(), 
          panel.grid.minor = element_blank(), 
          panel.grid.major.x = element_blank(),
          legend.position = &amp;#39;none&amp;#39;) + 
    ylab(&amp;#39;Depth&amp;#39;) + 
    xlab(paste0(gene_name[1]))
}

# little for loop to roll through the transcripts and make plot, storing in a list
plots &amp;lt;- list()
for (i in transcripts){
  plots[[i]] &amp;lt;- plot_maker(i)
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Joining, by = c(&amp;quot;Exon Number&amp;quot;, &amp;quot;Start&amp;quot;)
## Joining, by = c(&amp;quot;Exon Number&amp;quot;, &amp;quot;Start&amp;quot;)
## Joining, by = c(&amp;quot;Exon Number&amp;quot;, &amp;quot;Start&amp;quot;)
## Joining, by = c(&amp;quot;Exon Number&amp;quot;, &amp;quot;Start&amp;quot;)
## Joining, by = c(&amp;quot;Exon Number&amp;quot;, &amp;quot;Start&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;legend &amp;lt;- get_legend(plots[[names(plots)[1]]] + theme(legend.position=&amp;#39;right&amp;#39;))
# cowplot can take a list and glue the plots together
# I&amp;#39;m commenting out the below line because blogdown makes it too damn small. You need to run it to make the plot
# plot_grid(plot_grid(plotlist = plots, ncol=1, hjust=-2), legend, ncol=2, rel_widths = c(5,0.5))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/./img/lets_plot_3.png&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;version-2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Version 2&lt;/h2&gt;
&lt;p&gt;A bit tighter. Recalculates coordinates to glue all of the exons together in one plot. I can facet by gene. A bit harder to read, but is more accurate as the exons and gene lengths are proportional&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;genes &amp;lt;- c(&amp;#39;PAX6&amp;#39;,&amp;#39;ABCA4&amp;#39;,&amp;#39;NRL&amp;#39;,&amp;#39;CRX&amp;#39;,&amp;#39;RPGR&amp;#39;)
tx = gencode2 %&amp;gt;% filter(Name %in% genes) %&amp;gt;% pull(Transcript)

dd_expanded &amp;lt;- dd_processed %&amp;gt;% filter(Transcript %in% tx) %&amp;gt;% group_by(Transcript, `Exon Number`) %&amp;gt;% 
  expand(Start=full_seq(c(Start,End),1)) %&amp;gt;% 
  left_join(.,  dd_processed %&amp;gt;% filter(Transcript %in% tx)) %&amp;gt;% # create one row per base position, grouped by Exon Number https://stackoverflow.com/questions/42866119/fill-missing-values-in-data-frame-using-dplyr-complete-within-groups
  fill(Chr:Name) # fill missing values https://stackoverflow.com/questions/40040834/r-replace-na-with-previous-or-next-value-by-group-using-dplyr&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Joining, by = c(&amp;quot;Transcript&amp;quot;, &amp;quot;Exon Number&amp;quot;, &amp;quot;Start&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dd_expanded &amp;lt;- dd_expanded %&amp;gt;% group_by(Name) %&amp;gt;% mutate(Pos = 1:n())
even_odds_marking &amp;lt;- dd_expanded %&amp;gt;% group_by(Name, `Exon Number`) %&amp;gt;% summarise(Start=min(Pos), End=max(Pos)) %&amp;gt;% mutate(Exon = case_when(as.numeric(`Exon Number`) %% 2 == 0 ~ &amp;#39;even&amp;#39;, TRUE ~ &amp;#39;odd&amp;#39;))
plot_data&amp;lt;-bind_rows(dd_expanded,even_odds_marking)

ggplot() + 
  geom_point(data =  plot_data %&amp;gt;% filter(is.na(Exon)), aes(x=Pos, y=Read_Depth, colour=Depth),size=0.1)  + 
  facet_wrap(~Name, ncol=1) + 
  geom_rect(data = plot_data %&amp;gt;% filter(!is.na(Exon)), aes(xmin=Start, xmax=End, ymin=-Inf, ymax=Inf, fill=Exon)) +  
  scale_fill_manual(values = alpha(c(&amp;quot;gray&amp;quot;, &amp;quot;white&amp;quot;), .3)) +  
  scale_colour_custom() +
  theme_minimal() +  
  theme(axis.text.x=element_blank(), 
        axis.ticks.x = element_blank(),
        panel.grid.minor = element_blank(), 
        panel.grid.major.x = element_blank())+
  guides(fill=FALSE) + 
  ylab(&amp;#39;Read Depth&amp;#39;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-02-08-let-s-plot-3-base-pair-resolution-ngs-exome-coverage-plots_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;sessioninfo&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;sessionInfo()&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::session_info()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Session info -------------------------------------------------------------&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  setting  value                       
##  version  R version 3.4.0 (2017-04-21)
##  system   x86_64, darwin15.6.0        
##  ui       X11                         
##  language (EN)                        
##  collate  en_US.UTF-8                 
##  tz       America/New_York            
##  date     2018-04-13&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Packages -----------------------------------------------------------------&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  package    * version    date       source                        
##  assertthat   0.2.0      2017-04-11 CRAN (R 3.4.0)                
##  backports    1.1.2      2017-12-13 CRAN (R 3.4.3)                
##  base       * 3.4.0      2017-04-21 local                         
##  bindr        0.1.1      2018-03-13 CRAN (R 3.4.4)                
##  bindrcpp   * 0.2        2017-06-17 CRAN (R 3.4.0)                
##  blogdown     0.5        2018-01-24 CRAN (R 3.4.3)                
##  bookdown     0.7        2018-02-18 CRAN (R 3.4.3)                
##  broom        0.4.3      2017-11-20 CRAN (R 3.4.0)                
##  cellranger   1.1.0      2016-07-27 CRAN (R 3.4.0)                
##  cli          1.0.0      2017-11-05 CRAN (R 3.4.2)                
##  colorspace   1.3-2      2016-12-14 CRAN (R 3.4.0)                
##  compiler     3.4.0      2017-04-21 local                         
##  cowplot    * 0.9.2      2017-12-17 CRAN (R 3.4.3)                
##  crayon       1.3.4      2017-09-16 CRAN (R 3.4.1)                
##  data.table * 1.10.4-3   2017-10-27 CRAN (R 3.4.2)                
##  datasets   * 3.4.0      2017-04-21 local                         
##  devtools     1.13.5     2018-02-18 CRAN (R 3.4.3)                
##  digest       0.6.15     2018-01-28 CRAN (R 3.4.3)                
##  dplyr      * 0.7.4      2017-09-28 CRAN (R 3.4.2)                
##  evaluate     0.10.1     2017-06-24 CRAN (R 3.4.1)                
##  forcats    * 0.3.0      2018-02-19 CRAN (R 3.4.3)                
##  foreign      0.8-69     2017-06-22 CRAN (R 3.4.1)                
##  ggplot2    * 2.2.1      2016-12-30 CRAN (R 3.4.0)                
##  glue         1.2.0      2017-10-29 CRAN (R 3.4.2)                
##  graphics   * 3.4.0      2017-04-21 local                         
##  grDevices  * 3.4.0      2017-04-21 local                         
##  grid         3.4.0      2017-04-21 local                         
##  gtable       0.2.0      2016-02-26 CRAN (R 3.4.0)                
##  haven        1.1.1      2018-01-18 CRAN (R 3.4.3)                
##  hms          0.4.2      2018-03-10 CRAN (R 3.4.4)                
##  htmltools    0.3.6      2017-04-28 CRAN (R 3.4.0)                
##  httr         1.3.1      2017-08-20 CRAN (R 3.4.1)                
##  jsonlite     1.5        2017-06-01 CRAN (R 3.4.0)                
##  knitr        1.20       2018-02-20 CRAN (R 3.4.3)                
##  labeling     0.3        2014-08-23 CRAN (R 3.4.0)                
##  lattice      0.20-35    2017-03-25 CRAN (R 3.4.0)                
##  lazyeval     0.2.1      2017-10-29 CRAN (R 3.4.2)                
##  lubridate    1.7.3      2018-02-27 CRAN (R 3.4.3)                
##  magrittr     1.5        2014-11-22 CRAN (R 3.4.0)                
##  memoise      1.1.0      2017-04-21 CRAN (R 3.4.0)                
##  methods    * 3.4.0      2017-04-21 local                         
##  mnormt       1.5-5      2016-10-15 CRAN (R 3.4.0)                
##  modelr       0.1.1      2017-07-24 CRAN (R 3.4.1)                
##  munsell      0.4.3      2016-02-13 CRAN (R 3.4.0)                
##  nlme         3.1-131.1  2018-02-16 CRAN (R 3.4.3)                
##  parallel     3.4.0      2017-04-21 local                         
##  pillar       1.2.1      2018-02-27 CRAN (R 3.4.3)                
##  pkgconfig    2.0.1      2017-03-21 CRAN (R 3.4.0)                
##  plyr         1.8.4      2016-06-08 CRAN (R 3.4.0)                
##  psych        1.7.8      2017-09-09 CRAN (R 3.4.0)                
##  purrr      * 0.2.4      2017-10-18 CRAN (R 3.4.2)                
##  R6           2.2.2      2017-06-17 CRAN (R 3.4.0)                
##  Rcpp         0.12.16    2018-03-13 CRAN (R 3.4.4)                
##  readr      * 1.1.1      2017-05-16 CRAN (R 3.4.0)                
##  readxl       1.0.0      2017-04-18 CRAN (R 3.4.0)                
##  reshape2     1.4.3      2017-12-11 CRAN (R 3.4.3)                
##  rlang        0.2.0      2018-02-20 CRAN (R 3.4.3)                
##  rmarkdown    1.9        2018-03-01 CRAN (R 3.4.3)                
##  rprojroot    1.3-2      2018-01-03 CRAN (R 3.4.3)                
##  rstudioapi   0.7        2017-09-07 CRAN (R 3.4.1)                
##  rvest        0.3.2      2016-06-17 CRAN (R 3.4.0)                
##  scales       0.5.0.9000 2017-09-20 Github (hadley/scales@d767915)
##  stats      * 3.4.0      2017-04-21 local                         
##  stringi      1.1.7      2018-03-12 CRAN (R 3.4.4)                
##  stringr    * 1.3.0      2018-02-19 CRAN (R 3.4.3)                
##  tibble     * 1.4.2      2018-01-22 cran (@1.4.2)                 
##  tidyr      * 0.8.0      2018-01-29 CRAN (R 3.4.3)                
##  tidyselect   0.2.4      2018-02-26 CRAN (R 3.4.3)                
##  tidyverse  * 1.2.1      2017-11-14 CRAN (R 3.4.2)                
##  tools        3.4.0      2017-04-21 local                         
##  utils      * 3.4.0      2017-04-21 local                         
##  withr        2.1.2      2018-03-15 CRAN (R 3.4.4)                
##  xfun         0.1        2018-01-22 CRAN (R 3.4.3)                
##  xml2         1.2.0      2018-01-24 CRAN (R 3.4.3)                
##  yaml         2.1.18     2018-03-08 CRAN (R 3.4.4)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Split VCF into n pieces by coordinate</title>
      <link>/./post/split-vcf-into-n-pieces-by-coordinate/</link>
      <pubDate>Wed, 07 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/./post/split-vcf-into-n-pieces-by-coordinate/</guid>
      <description>&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#read-in-vcf-header&#34;&gt;Read in vcf header&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#parse-out-chr-contig-sizes&#34;&gt;Parse out chr / contig sizes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#split-chr-above-3e7-base-pairs-into-equalish-size-pieces&#34;&gt;Split chr above 3e7 base pairs into equal(ish) size pieces&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#print-coordinates-given-a-chromosome-contig&#34;&gt;print coordinates given a chromosome / contig&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#calculate-coordinates&#34;&gt;calculate coordinates&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#print-em&#34;&gt;print ’em&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#output-em-for-python-input-snakemake&#34;&gt;output ’em for python input (Snakemake)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#rscript&#34;&gt;rscript&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#using-the-script-output&#34;&gt;Using the script output&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sessioninfo&#34;&gt;sessionInfo()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;bcftools view -r 1:40000-50000 vcf.gz&lt;/code&gt; will output (to stdout) a vcf containing the header and variants on chromosome 1 between coordinates 40,000 and 50,000 base pairs.&lt;/p&gt;
&lt;p&gt;I need to break down a large vcf into smaller pieces to dramatically speed up annotation. Let’s try 100 pieces.&lt;/p&gt;
&lt;p&gt;The human genome is &lt;em&gt;approximately&lt;/em&gt; 3 gigabases or 3e9 base pairs.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \frac{3 * 10^9\ base\ pairs}{100\ pieces} = 3*10^7\ base\ pairs\ per\ piece \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;That’s our target size.&lt;/p&gt;
&lt;p&gt;This is made a bit tricky since the genome is laid by chromosome. So we have to break into 3e7 pieces, accounting for chromosomes. There are also &lt;strong&gt;many&lt;/strong&gt; contigs, most of which are well under 3e7 in size. Those can be processed as a group with &lt;code&gt;bcftools&lt;/code&gt; by splitting each contig by a &lt;code&gt;,&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Let’s read in the header. It contains chromosome (and contig) sizes, which I’ve extracted from the vcf with &lt;code&gt;zcat EGAD00001002656.GATK.vcf.gz | head -n 1000 | grep ^## &amp;gt; /home/mcgaugheyd/git/OGVFB_one_offs/mcgaughey/split_VCFs_into_n_pieces/EGAD00001002656.header&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;read-in-vcf-header&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Read in vcf header&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Attaching packages ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.2.1 ──&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✔ ggplot2 2.2.1     ✔ purrr   0.2.4
## ✔ tibble  1.4.2     ✔ dplyr   0.7.4
## ✔ tidyr   0.7.2     ✔ stringr 1.2.0
## ✔ readr   1.1.1     ✔ forcats 0.2.0&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Conflicts ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
## ✖ dplyr::filter() masks stats::filter()
## ✖ dplyr::lag()    masks stats::lag()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(stringr)
vcf_header = scan(&amp;#39;~/git/OGVFB_one_offs/mcgaughey/split_VCFs_into_n_pieces/EGAD00001002656.header&amp;#39;, what=&amp;#39;character&amp;#39;)
vcf_header[grepl(&amp;#39;contig&amp;#39;,vcf_header)]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;##contig=&amp;lt;ID=1,length=249250621,assembly=b37&amp;gt;&amp;quot;      
##  [2] &amp;quot;##contig=&amp;lt;ID=2,length=243199373,assembly=b37&amp;gt;&amp;quot;      
##  [3] &amp;quot;##contig=&amp;lt;ID=3,length=198022430,assembly=b37&amp;gt;&amp;quot;      
##  [4] &amp;quot;##contig=&amp;lt;ID=4,length=191154276,assembly=b37&amp;gt;&amp;quot;      
##  [5] &amp;quot;##contig=&amp;lt;ID=5,length=180915260,assembly=b37&amp;gt;&amp;quot;      
##  [6] &amp;quot;##contig=&amp;lt;ID=6,length=171115067,assembly=b37&amp;gt;&amp;quot;      
##  [7] &amp;quot;##contig=&amp;lt;ID=7,length=159138663,assembly=b37&amp;gt;&amp;quot;      
##  [8] &amp;quot;##contig=&amp;lt;ID=8,length=146364022,assembly=b37&amp;gt;&amp;quot;      
##  [9] &amp;quot;##contig=&amp;lt;ID=9,length=141213431,assembly=b37&amp;gt;&amp;quot;      
## [10] &amp;quot;##contig=&amp;lt;ID=10,length=135534747,assembly=b37&amp;gt;&amp;quot;     
## [11] &amp;quot;##contig=&amp;lt;ID=11,length=135006516,assembly=b37&amp;gt;&amp;quot;     
## [12] &amp;quot;##contig=&amp;lt;ID=12,length=133851895,assembly=b37&amp;gt;&amp;quot;     
## [13] &amp;quot;##contig=&amp;lt;ID=13,length=115169878,assembly=b37&amp;gt;&amp;quot;     
## [14] &amp;quot;##contig=&amp;lt;ID=14,length=107349540,assembly=b37&amp;gt;&amp;quot;     
## [15] &amp;quot;##contig=&amp;lt;ID=15,length=102531392,assembly=b37&amp;gt;&amp;quot;     
## [16] &amp;quot;##contig=&amp;lt;ID=16,length=90354753,assembly=b37&amp;gt;&amp;quot;      
## [17] &amp;quot;##contig=&amp;lt;ID=17,length=81195210,assembly=b37&amp;gt;&amp;quot;      
## [18] &amp;quot;##contig=&amp;lt;ID=18,length=78077248,assembly=b37&amp;gt;&amp;quot;      
## [19] &amp;quot;##contig=&amp;lt;ID=19,length=59128983,assembly=b37&amp;gt;&amp;quot;      
## [20] &amp;quot;##contig=&amp;lt;ID=20,length=63025520,assembly=b37&amp;gt;&amp;quot;      
## [21] &amp;quot;##contig=&amp;lt;ID=21,length=48129895,assembly=b37&amp;gt;&amp;quot;      
## [22] &amp;quot;##contig=&amp;lt;ID=22,length=51304566,assembly=b37&amp;gt;&amp;quot;      
## [23] &amp;quot;##contig=&amp;lt;ID=X,length=155270560,assembly=b37&amp;gt;&amp;quot;      
## [24] &amp;quot;##contig=&amp;lt;ID=Y,length=59373566,assembly=b37&amp;gt;&amp;quot;       
## [25] &amp;quot;##contig=&amp;lt;ID=MT,length=16569,assembly=b37&amp;gt;&amp;quot;         
## [26] &amp;quot;##contig=&amp;lt;ID=GL000207.1,length=4262,assembly=b37&amp;gt;&amp;quot;  
## [27] &amp;quot;##contig=&amp;lt;ID=GL000226.1,length=15008,assembly=b37&amp;gt;&amp;quot; 
## [28] &amp;quot;##contig=&amp;lt;ID=GL000229.1,length=19913,assembly=b37&amp;gt;&amp;quot; 
## [29] &amp;quot;##contig=&amp;lt;ID=GL000231.1,length=27386,assembly=b37&amp;gt;&amp;quot; 
## [30] &amp;quot;##contig=&amp;lt;ID=GL000210.1,length=27682,assembly=b37&amp;gt;&amp;quot; 
## [31] &amp;quot;##contig=&amp;lt;ID=GL000239.1,length=33824,assembly=b37&amp;gt;&amp;quot; 
## [32] &amp;quot;##contig=&amp;lt;ID=GL000235.1,length=34474,assembly=b37&amp;gt;&amp;quot; 
## [33] &amp;quot;##contig=&amp;lt;ID=GL000201.1,length=36148,assembly=b37&amp;gt;&amp;quot; 
## [34] &amp;quot;##contig=&amp;lt;ID=GL000247.1,length=36422,assembly=b37&amp;gt;&amp;quot; 
## [35] &amp;quot;##contig=&amp;lt;ID=GL000245.1,length=36651,assembly=b37&amp;gt;&amp;quot; 
## [36] &amp;quot;##contig=&amp;lt;ID=GL000197.1,length=37175,assembly=b37&amp;gt;&amp;quot; 
## [37] &amp;quot;##contig=&amp;lt;ID=GL000203.1,length=37498,assembly=b37&amp;gt;&amp;quot; 
## [38] &amp;quot;##contig=&amp;lt;ID=GL000246.1,length=38154,assembly=b37&amp;gt;&amp;quot; 
## [39] &amp;quot;##contig=&amp;lt;ID=GL000249.1,length=38502,assembly=b37&amp;gt;&amp;quot; 
## [40] &amp;quot;##contig=&amp;lt;ID=GL000196.1,length=38914,assembly=b37&amp;gt;&amp;quot; 
## [41] &amp;quot;##contig=&amp;lt;ID=GL000248.1,length=39786,assembly=b37&amp;gt;&amp;quot; 
## [42] &amp;quot;##contig=&amp;lt;ID=GL000244.1,length=39929,assembly=b37&amp;gt;&amp;quot; 
## [43] &amp;quot;##contig=&amp;lt;ID=GL000238.1,length=39939,assembly=b37&amp;gt;&amp;quot; 
## [44] &amp;quot;##contig=&amp;lt;ID=GL000202.1,length=40103,assembly=b37&amp;gt;&amp;quot; 
## [45] &amp;quot;##contig=&amp;lt;ID=GL000234.1,length=40531,assembly=b37&amp;gt;&amp;quot; 
## [46] &amp;quot;##contig=&amp;lt;ID=GL000232.1,length=40652,assembly=b37&amp;gt;&amp;quot; 
## [47] &amp;quot;##contig=&amp;lt;ID=GL000206.1,length=41001,assembly=b37&amp;gt;&amp;quot; 
## [48] &amp;quot;##contig=&amp;lt;ID=GL000240.1,length=41933,assembly=b37&amp;gt;&amp;quot; 
## [49] &amp;quot;##contig=&amp;lt;ID=GL000236.1,length=41934,assembly=b37&amp;gt;&amp;quot; 
## [50] &amp;quot;##contig=&amp;lt;ID=GL000241.1,length=42152,assembly=b37&amp;gt;&amp;quot; 
## [51] &amp;quot;##contig=&amp;lt;ID=GL000243.1,length=43341,assembly=b37&amp;gt;&amp;quot; 
## [52] &amp;quot;##contig=&amp;lt;ID=GL000242.1,length=43523,assembly=b37&amp;gt;&amp;quot; 
## [53] &amp;quot;##contig=&amp;lt;ID=GL000230.1,length=43691,assembly=b37&amp;gt;&amp;quot; 
## [54] &amp;quot;##contig=&amp;lt;ID=GL000237.1,length=45867,assembly=b37&amp;gt;&amp;quot; 
## [55] &amp;quot;##contig=&amp;lt;ID=GL000233.1,length=45941,assembly=b37&amp;gt;&amp;quot; 
## [56] &amp;quot;##contig=&amp;lt;ID=GL000204.1,length=81310,assembly=b37&amp;gt;&amp;quot; 
## [57] &amp;quot;##contig=&amp;lt;ID=GL000198.1,length=90085,assembly=b37&amp;gt;&amp;quot; 
## [58] &amp;quot;##contig=&amp;lt;ID=GL000208.1,length=92689,assembly=b37&amp;gt;&amp;quot; 
## [59] &amp;quot;##contig=&amp;lt;ID=GL000191.1,length=106433,assembly=b37&amp;gt;&amp;quot;
## [60] &amp;quot;##contig=&amp;lt;ID=GL000227.1,length=128374,assembly=b37&amp;gt;&amp;quot;
## [61] &amp;quot;##contig=&amp;lt;ID=GL000228.1,length=129120,assembly=b37&amp;gt;&amp;quot;
## [62] &amp;quot;##contig=&amp;lt;ID=GL000214.1,length=137718,assembly=b37&amp;gt;&amp;quot;
## [63] &amp;quot;##contig=&amp;lt;ID=GL000221.1,length=155397,assembly=b37&amp;gt;&amp;quot;
## [64] &amp;quot;##contig=&amp;lt;ID=GL000209.1,length=159169,assembly=b37&amp;gt;&amp;quot;
## [65] &amp;quot;##contig=&amp;lt;ID=GL000218.1,length=161147,assembly=b37&amp;gt;&amp;quot;
## [66] &amp;quot;##contig=&amp;lt;ID=GL000220.1,length=161802,assembly=b37&amp;gt;&amp;quot;
## [67] &amp;quot;##contig=&amp;lt;ID=GL000213.1,length=164239,assembly=b37&amp;gt;&amp;quot;
## [68] &amp;quot;##contig=&amp;lt;ID=GL000211.1,length=166566,assembly=b37&amp;gt;&amp;quot;
## [69] &amp;quot;##contig=&amp;lt;ID=GL000199.1,length=169874,assembly=b37&amp;gt;&amp;quot;
## [70] &amp;quot;##contig=&amp;lt;ID=GL000217.1,length=172149,assembly=b37&amp;gt;&amp;quot;
## [71] &amp;quot;##contig=&amp;lt;ID=GL000216.1,length=172294,assembly=b37&amp;gt;&amp;quot;
## [72] &amp;quot;##contig=&amp;lt;ID=GL000215.1,length=172545,assembly=b37&amp;gt;&amp;quot;
## [73] &amp;quot;##contig=&amp;lt;ID=GL000205.1,length=174588,assembly=b37&amp;gt;&amp;quot;
## [74] &amp;quot;##contig=&amp;lt;ID=GL000219.1,length=179198,assembly=b37&amp;gt;&amp;quot;
## [75] &amp;quot;##contig=&amp;lt;ID=GL000224.1,length=179693,assembly=b37&amp;gt;&amp;quot;
## [76] &amp;quot;##contig=&amp;lt;ID=GL000223.1,length=180455,assembly=b37&amp;gt;&amp;quot;
## [77] &amp;quot;##contig=&amp;lt;ID=GL000195.1,length=182896,assembly=b37&amp;gt;&amp;quot;
## [78] &amp;quot;##contig=&amp;lt;ID=GL000212.1,length=186858,assembly=b37&amp;gt;&amp;quot;
## [79] &amp;quot;##contig=&amp;lt;ID=GL000222.1,length=186861,assembly=b37&amp;gt;&amp;quot;
## [80] &amp;quot;##contig=&amp;lt;ID=GL000200.1,length=187035,assembly=b37&amp;gt;&amp;quot;
## [81] &amp;quot;##contig=&amp;lt;ID=GL000193.1,length=189789,assembly=b37&amp;gt;&amp;quot;
## [82] &amp;quot;##contig=&amp;lt;ID=GL000194.1,length=191469,assembly=b37&amp;gt;&amp;quot;
## [83] &amp;quot;##contig=&amp;lt;ID=GL000225.1,length=211173,assembly=b37&amp;gt;&amp;quot;
## [84] &amp;quot;##contig=&amp;lt;ID=GL000192.1,length=547496,assembly=b37&amp;gt;&amp;quot;
## [85] &amp;quot;##contig=&amp;lt;ID=NC_007605,length=171823,assembly=b37&amp;gt;&amp;quot; 
## [86] &amp;quot;##contig=&amp;lt;ID=hs37d5,length=35477943,assembly=b37&amp;gt;&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;parse-out-chr-contig-sizes&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Parse out chr / contig sizes&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# turn into data frame (well, a tibble)
contig_size &amp;lt;- vcf_header[grepl(&amp;#39;contig&amp;#39;, vcf_header)] %&amp;gt;% 
  data.frame() %&amp;gt;% 
  select(1, &amp;#39;header&amp;#39; = 1) %&amp;gt;% 
  # separate by ,
  separate(header, c(&amp;#39;contig&amp;#39;,&amp;#39;length&amp;#39;,&amp;#39;assembly&amp;#39;),&amp;#39;,&amp;#39;) %&amp;gt;% 
  # extract values by splitting against = and taking the last element (first after reversing)
  rowwise() %&amp;gt;% 
  mutate(contig = str_split(contig,&amp;#39;=&amp;#39;)[[1]] %&amp;gt;% gsub(&amp;#39;&amp;gt;&amp;#39;,&amp;#39;&amp;#39;,.) %&amp;gt;% rev() %&amp;gt;% .[[1]],
         length = str_split(length,&amp;#39;=&amp;#39;)[[1]] %&amp;gt;% gsub(&amp;#39;&amp;gt;&amp;#39;,&amp;#39;&amp;#39;,.) %&amp;gt;% rev() %&amp;gt;% .[[1]] %&amp;gt;% as.numeric(),
         assembly = str_split(assembly,&amp;#39;=&amp;#39;)[[1]] %&amp;gt;% gsub(&amp;#39;&amp;gt;&amp;#39;,&amp;#39;&amp;#39;,.) %&amp;gt;% rev() %&amp;gt;% .[[1]])
contig_size&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Source: local data frame [86 x 3]
## Groups: &amp;lt;by row&amp;gt;
## 
## # A tibble: 86 x 3
##    contig    length assembly
##    &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;   
##  1 1      249250621 b37     
##  2 2      243199373 b37     
##  3 3      198022430 b37     
##  4 4      191154276 b37     
##  5 5      180915260 b37     
##  6 6      171115067 b37     
##  7 7      159138663 b37     
##  8 8      146364022 b37     
##  9 9      141213431 b37     
## 10 10     135534747 b37     
## # ... with 76 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;split-chr-above-3e7-base-pairs-into-equalish-size-pieces&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Split chr above 3e7 base pairs into equal(ish) size pieces&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;ceiling&lt;/code&gt; will allow intervals a bit less than 3e7 by rounding up the number of pieces per chromsome. Would rather have more splits with less than the target size.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n_split &amp;lt;- function(size){
  pieces &amp;lt;- ceiling(size / 3e7)
  seq(1, size, size/pieces)
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;print-coordinates-given-a-chromosome-contig&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;print coordinates given a chromosome / contig&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n_printer &amp;lt;- function(chr) {
  # grab the legnth of chr or contig
  size &amp;lt;- contig_size %&amp;gt;% filter(contig == chr) %&amp;gt;% pull(length)
  # split into ~30e7 sized pieces
  sequence &amp;lt;- n_split(size)
  # add the max size to end (plus another base pair since the loop below reduces size by 1 to eliminate overlaps)
  sequence &amp;lt;- c(sequence, size+1)
  df &amp;lt;- data.frame()
  for(i in 1:length(sequence)){
    row &amp;lt;- cbind(chr, as.integer(sequence[max(i-1,1)]), # for first row, makes sure you don&amp;#39;t pick the 0 position, which doesn&amp;#39;t exit
                 as.integer(sequence[i]-1)) # decrements by one so you don&amp;#39;t overlap
    df &amp;lt;- rbind(df, row)
  }
  colnames(df) &amp;lt;- c(&amp;#39;chr&amp;#39;,&amp;#39;start&amp;#39;,&amp;#39;end&amp;#39;)
  # skip first row which has dummy values
  df[-1,]
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;calculate-coordinates&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;calculate coordinates&lt;/h2&gt;
&lt;p&gt;Will skip contig &amp;lt; 3e7 (all but hs37d5, which I don’t process, so it will be eliminated). The contigs will be printed comma separated for &lt;code&gt;bcftools view -r&lt;/code&gt; purposes.&lt;/p&gt;
&lt;p&gt;How many regions do we have? Should have a bit more than 100.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;regions &amp;lt;- data.frame()
for (i in contig_size %&amp;gt;% filter(length &amp;gt; 3e7, contig != &amp;#39;hs37d5&amp;#39;) %&amp;gt;% pull(contig)){
  regions &amp;lt;- rbind(regions,(n_printer(i)))
}
regions %&amp;gt;% nrow()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 115&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;print-em&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;print ’em&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;regions %&amp;gt;% mutate(f = paste(paste(chr, start, sep =&amp;#39;:&amp;#39;), end, sep=&amp;#39;-&amp;#39;)) %&amp;gt;% select(f)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                          f
## 1             1:1-27694513
## 2      1:27694514-55389026
## 3      1:55389027-83083540
## 4     1:83083541-110778053
## 5    1:110778054-138472567
## 6    1:138472568-166167080
## 7    1:166167081-193861594
## 8    1:193861595-221556107
## 9    1:221556108-249250621
## 10            2:1-27022152
## 11     2:27022153-54044305
## 12     2:54044306-81066457
## 13    2:81066458-108088610
## 14   2:108088611-135110762
## 15   2:135110763-162132915
## 16   2:162132916-189155067
## 17   2:189155068-216177220
## 18   2:216177221-243199373
## 19            3:1-28288918
## 20     3:28288919-56577837
## 21     3:56577838-84866755
## 22    3:84866756-113155674
## 23   3:113155675-141444592
## 24   3:141444593-169733511
## 25   3:169733512-198022430
## 26            4:1-27307753
## 27     4:27307754-54615507
## 28     4:54615508-81923261
## 29    4:81923262-109231014
## 30   4:109231015-136538768
## 31   4:136538769-163846522
## 32   4:163846523-191154276
## 33            5:1-25845037
## 34     5:25845038-51690074
## 35     5:51690075-77535111
## 36    5:77535112-103380148
## 37   5:103380149-129225185
## 38   5:129225186-155070222
## 39   5:155070223-180915260
## 40            6:1-28519177
## 41     6:28519178-57038355
## 42     6:57038356-85557533
## 43    6:85557534-114076711
## 44   6:114076712-142595889
## 45   6:142595890-171115067
## 46            7:1-26523110
## 47     7:26523111-53046221
## 48     7:53046222-79569331
## 49    7:79569332-106092442
## 50   7:106092443-132615552
## 51   7:132615553-159138663
## 52            8:1-29272804
## 53     8:29272805-58545608
## 54     8:58545609-87818413
## 55    8:87818414-117091217
## 56   8:117091218-146364022
## 57            9:1-28242686
## 58     9:28242687-56485372
## 59     9:56485373-84728058
## 60    9:84728059-112970744
## 61   9:112970745-141213431
## 62           10:1-27106949
## 63    10:27106950-54213898
## 64    10:54213899-81320848
## 65   10:81320849-108427797
## 66  10:108427798-135534747
## 67           11:1-27001303
## 68    11:27001304-54002606
## 69    11:54002607-81003909
## 70   11:81003910-108005212
## 71  11:108005213-135006516
## 72           12:1-26770379
## 73    12:26770380-53540758
## 74    12:53540759-80311137
## 75   12:80311138-107081516
## 76  12:107081517-133851895
## 77           13:1-28792469
## 78    13:28792470-57584939
## 79    13:57584940-86377408
## 80   13:86377409-115169878
## 81           14:1-26837385
## 82    14:26837386-53674770
## 83    14:53674771-80512155
## 84   14:80512156-107349540
## 85           15:1-25632848
## 86    15:25632849-51265696
## 87    15:51265697-76898544
## 88   15:76898545-102531392
## 89           16:1-22588688
## 90    16:22588689-45177376
## 91    16:45177377-67766064
## 92    16:67766065-90354753
## 93           17:1-27065070
## 94    17:27065071-54130140
## 95    17:54130141-81195210
## 96           18:1-26025749
## 97    18:26025750-52051498
## 98    18:52051499-78077248
## 99           19:1-29564491
## 100   19:29564492-59128983
## 101          20:1-21008506
## 102   20:21008507-42017013
## 103   20:42017014-63025520
## 104          21:1-24064947
## 105   21:24064948-48129895
## 106          22:1-25652283
## 107   22:25652284-51304566
## 108           X:1-25878426
## 109    X:25878427-51756853
## 110    X:51756854-77635280
## 111   X:77635281-103513706
## 112  X:103513707-129392133
## 113  X:129392134-155270560
## 114           Y:1-29686783
## 115    Y:29686784-59373566&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;output-em-for-python-input-snakemake&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;output ’em for python input (Snakemake)&lt;/h2&gt;
&lt;p&gt;The second write command appends all of the chromosomes or contigs (in this case, just contigs) that are less than 3e7 in length to the output file. It comma separates them, which is how &lt;code&gt;bcftools view -r&lt;/code&gt; takes in multiple chromosomes or contigs. The &lt;code&gt;paste(., collapse=&#39;,&#39;)&lt;/code&gt; command at the end collapses the vector of contigs into a string with comma separation.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;write(regions %&amp;gt;% mutate(f = paste(paste(chr, start, sep =&amp;#39;:&amp;#39;), end, sep=&amp;#39;-&amp;#39;)) %&amp;gt;% pull(f), file=&amp;#39;vcf_region_split_coords.txt&amp;#39;)
write(contig_size %&amp;gt;% filter(length &amp;lt; 3e7, contig != &amp;#39;hs37d5&amp;#39;) %&amp;gt;% pull(contig) %&amp;gt;% paste(., collapse=&amp;#39;,&amp;#39;), file=&amp;#39;vcf_region_split_coords.txt&amp;#39;, append = T)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;rscript&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;rscript&lt;/h2&gt;
&lt;p&gt;I’ve wrapped up the functions and handling as a Rscript that takes the header of a vcf as input and outputs and writes to a user-given file the regions. The script also allows you to select desired number of regions (you will almost always get a few more), the output file name, and the genome size (defaults to human genome). The script is &lt;a href=&#34;/./files/scripts/split_vcf_into_n_pieces.R&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;using-the-script-output&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Using the script output&lt;/h2&gt;
&lt;p&gt;I’m using it in a Snakemake pipeline. &lt;code&gt;bcftools&lt;/code&gt; can use it with &lt;code&gt;-R&lt;/code&gt; (region) if you run the script like this (see source for comments): &lt;code&gt;Rscript split_vcf_into_n_pieces.R yourVCF.header 200 vcf_region_split_200_coords.txt 3e9 bed&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;sessioninfo&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;sessionInfo()&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::session_info()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Session info -------------------------------------------------------------&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  setting  value                       
##  version  R version 3.4.0 (2017-04-21)
##  system   x86_64, darwin15.6.0        
##  ui       X11                         
##  language (EN)                        
##  collate  en_US.UTF-8                 
##  tz       America/New_York            
##  date     2018-02-13&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Packages -----------------------------------------------------------------&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  package    * version    date       source                          
##  assertthat   0.2.0      2017-04-11 CRAN (R 3.4.0)                  
##  backports    1.1.1      2017-09-25 CRAN (R 3.4.2)                  
##  base       * 3.4.0      2017-04-21 local                           
##  bindr        0.1        2016-11-13 CRAN (R 3.4.0)                  
##  bindrcpp   * 0.2        2017-06-17 CRAN (R 3.4.0)                  
##  blogdown     0.5        2018-01-24 CRAN (R 3.4.3)                  
##  bookdown     0.6        2018-01-25 CRAN (R 3.4.3)                  
##  broom        0.4.3      2017-11-20 CRAN (R 3.4.0)                  
##  cellranger   1.1.0      2016-07-27 CRAN (R 3.4.0)                  
##  cli          1.0.0      2017-11-05 CRAN (R 3.4.2)                  
##  colorspace   1.3-2      2016-12-14 CRAN (R 3.4.0)                  
##  compiler     3.4.0      2017-04-21 local                           
##  crayon       1.3.4      2017-09-16 CRAN (R 3.4.1)                  
##  datasets   * 3.4.0      2017-04-21 local                           
##  devtools     1.13.4     2017-11-09 CRAN (R 3.4.2)                  
##  digest       0.6.12     2017-01-27 CRAN (R 3.4.0)                  
##  dplyr      * 0.7.4      2017-09-28 CRAN (R 3.4.2)                  
##  evaluate     0.10.1     2017-06-24 CRAN (R 3.4.1)                  
##  forcats    * 0.2.0      2017-01-23 CRAN (R 3.4.0)                  
##  foreign      0.8-69     2017-06-22 CRAN (R 3.4.1)                  
##  ggplot2    * 2.2.1      2016-12-30 CRAN (R 3.4.0)                  
##  glue         1.2.0      2017-10-29 CRAN (R 3.4.2)                  
##  graphics   * 3.4.0      2017-04-21 local                           
##  grDevices  * 3.4.0      2017-04-21 local                           
##  grid         3.4.0      2017-04-21 local                           
##  gtable       0.2.0      2016-02-26 CRAN (R 3.4.0)                  
##  haven        1.1.0      2017-07-09 CRAN (R 3.4.0)                  
##  hms          0.3        2016-11-22 CRAN (R 3.4.0)                  
##  htmltools    0.3.6      2017-04-28 CRAN (R 3.4.0)                  
##  httr         1.3.1      2017-08-20 CRAN (R 3.4.1)                  
##  jsonlite     1.5        2017-06-01 CRAN (R 3.4.0)                  
##  knitr        1.17       2017-08-10 CRAN (R 3.4.1)                  
##  lattice      0.20-35    2017-03-25 CRAN (R 3.4.0)                  
##  lazyeval     0.2.1      2017-10-29 CRAN (R 3.4.2)                  
##  lubridate    1.7.1      2017-11-03 CRAN (R 3.4.2)                  
##  magrittr     1.5        2014-11-22 CRAN (R 3.4.0)                  
##  memoise      1.1.0      2017-04-21 CRAN (R 3.4.0)                  
##  methods    * 3.4.0      2017-04-21 local                           
##  mnormt       1.5-5      2016-10-15 CRAN (R 3.4.0)                  
##  modelr       0.1.1      2017-07-24 CRAN (R 3.4.1)                  
##  munsell      0.4.3      2016-02-13 CRAN (R 3.4.0)                  
##  nlme         3.1-131    2017-02-06 CRAN (R 3.4.0)                  
##  parallel     3.4.0      2017-04-21 local                           
##  pillar       1.1.0      2018-01-14 cran (@1.1.0)                   
##  pkgconfig    2.0.1      2017-03-21 CRAN (R 3.4.0)                  
##  plyr         1.8.4      2016-06-08 CRAN (R 3.4.0)                  
##  psych        1.7.8      2017-09-09 CRAN (R 3.4.0)                  
##  purrr      * 0.2.4      2017-10-18 CRAN (R 3.4.2)                  
##  R6           2.2.2      2017-06-17 CRAN (R 3.4.0)                  
##  Rcpp         0.12.13    2017-09-28 CRAN (R 3.4.2)                  
##  readr      * 1.1.1      2017-05-16 CRAN (R 3.4.0)                  
##  readxl       1.0.0      2017-04-18 CRAN (R 3.4.0)                  
##  reshape2     1.4.2      2016-10-22 CRAN (R 3.4.0)                  
##  rlang        0.1.6      2017-12-21 cran (@0.1.6)                   
##  rmarkdown    1.8        2017-11-17 CRAN (R 3.4.2)                  
##  rprojroot    1.2        2017-01-16 CRAN (R 3.4.0)                  
##  rstudioapi   0.7        2017-09-07 CRAN (R 3.4.1)                  
##  rvest        0.3.2      2016-06-17 CRAN (R 3.4.0)                  
##  scales       0.5.0.9000 2017-09-20 Github (hadley/scales@d767915)  
##  stats      * 3.4.0      2017-04-21 local                           
##  stringi      1.1.6      2017-11-17 CRAN (R 3.4.2)                  
##  stringr    * 1.2.0      2017-02-18 CRAN (R 3.4.0)                  
##  tibble     * 1.4.2      2018-01-22 cran (@1.4.2)                   
##  tidyr      * 0.7.2      2017-10-16 CRAN (R 3.4.2)                  
##  tidyselect   0.2.3      2017-11-06 CRAN (R 3.4.2)                  
##  tidyverse  * 1.2.1      2017-11-14 CRAN (R 3.4.2)                  
##  tools        3.4.0      2017-04-21 local                           
##  utf8         1.1.3      2018-01-03 cran (@1.1.3)                   
##  utils      * 3.4.0      2017-04-21 local                           
##  withr        2.1.0.9000 2017-11-22 Github (jimhester/withr@fe81c00)
##  xfun         0.1        2018-01-22 CRAN (R 3.4.3)                  
##  xml2         1.1.1      2017-01-24 CRAN (R 3.4.0)                  
##  yaml         2.1.14     2016-11-12 CRAN (R 3.4.0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;```&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Let’s Plot 2: Smoothed Lines</title>
      <link>/./post/let-s-plot-2-smoothed-lines/</link>
      <pubDate>Sun, 04 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/./post/let-s-plot-2-smoothed-lines/</guid>
      <description>&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#get-data-two-xls-files-from-here&#34;&gt;Get data (two xls files) from here:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#load-data-and-look-at-structure-str&#34;&gt;Load data and look at structure (str)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#head-first-few-lines&#34;&gt;Head (first few lines)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#auc-n1p1-latency&#34;&gt;AUC, N1P1, Latency&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#summary-of-eel-and-cobra-auc&#34;&gt;Summary of eel and cobra AUC&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#what-kind-of-time-points-or-conditions-or-whatever-do-we-have-again&#34;&gt;What kind of time points or conditions or whatever do we have again?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#summary-by-pig-and-region&#34;&gt;Summary by pig and region&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#plot-auc-by-time-and-region-and-pig&#34;&gt;Plot AUC by time and region and pig&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#prettier-plot-with-lines-and-more-formatting&#34;&gt;Prettier plot with lines and more formatting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#n1p1-plot&#34;&gt;N1P1 Plot&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#latency-plot&#34;&gt;Latency plot&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#bonus&#34;&gt;Bonus&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;Data from Aaron Rising.&lt;/p&gt;
&lt;div id=&#34;get-data-two-xls-files-from-here&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Get data (two xls files) from here:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/davemcg/Let_us_plot/tree/master/002_smoothed_lines&#34; class=&#34;uri&#34;&gt;https://github.com/davemcg/Let_us_plot/tree/master/002_smoothed_lines&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;The rmd is also here if you want the source code&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Two different excel files (Cobra and Eel). Pig names?&lt;/p&gt;
&lt;p&gt;They have metrics for eye function across time.&lt;/p&gt;
&lt;p&gt;Aaron told me to take the ‘first tab’ in each excel file. Which is not the case, as at least to me, ‘Sheet 1’ is empty in both. So I’m using the next tab in both, which is ‘Normalized 2 Base For Comb’&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;load-data-and-look-at-structure-str&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Load data and look at structure (str)&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Attaching packages ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.2.1 ──&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✔ ggplot2 2.2.1     ✔ purrr   0.2.4
## ✔ tibble  1.4.2     ✔ dplyr   0.7.4
## ✔ tidyr   0.7.2     ✔ stringr 1.2.0
## ✔ readr   1.1.1     ✔ forcats 0.2.0&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Conflicts ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
## ✖ dplyr::filter() masks stats::filter()
## ✖ dplyr::lag()    masks stats::lag()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggsci)

cobra &amp;lt;- readxl::read_xls(&amp;#39;~/git/Let_us_plot/002_smoothed_lines/Cobra 749--_Normalized_Data_.xls&amp;#39;, sheet = &amp;#39;Normalized 2 Base For Comb&amp;#39;)
cobra %&amp;gt;% str()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Classes &amp;#39;tbl_df&amp;#39;, &amp;#39;tbl&amp;#39; and &amp;#39;data.frame&amp;#39;:    187 obs. of  8 variables:
##  $ Pig_Name  : chr  &amp;quot;Cobra 749&amp;quot; &amp;quot;Cobra 749&amp;quot; &amp;quot;Cobra 749&amp;quot; &amp;quot;Cobra 749&amp;quot; ...
##  $ Week      : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ Region    : chr  &amp;quot;Healthy_Implant&amp;quot; &amp;quot;Healthy_Implant&amp;quot; &amp;quot;Healthy_Implant&amp;quot; &amp;quot;Healthy_Implant&amp;quot; ...
##  $ Cells     : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...
##  $ Output    : chr  &amp;quot;Area-Under-Curve&amp;quot; &amp;quot;HFC-Scalar&amp;quot; &amp;quot;LFC-Scalar&amp;quot; &amp;quot;N1&amp;quot; ...
##  $ GroupCount: num  3 3 3 3 3 3 3 3 3 3 ...
##  $ Data      : num  1 1 1 1 15.7 ...
##  $ STD       : num  0.0994 0.3493 0.2259 0.1063 0.5774 ...&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;eel &amp;lt;- readxl::read_xls(&amp;#39;~/git/Let_us_plot/002_smoothed_lines/Eel 668--_Normalized_Data_.xls&amp;#39;, sheet = &amp;#39;Normalized 2 Base For Comb&amp;#39;)
eel %&amp;gt;% str()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Classes &amp;#39;tbl_df&amp;#39;, &amp;#39;tbl&amp;#39; and &amp;#39;data.frame&amp;#39;:    192 obs. of  8 variables:
##  $ Pig_Name  : chr  &amp;quot;Eel 668&amp;quot; &amp;quot;Eel 668&amp;quot; &amp;quot;Eel 668&amp;quot; &amp;quot;Eel 668&amp;quot; ...
##  $ Week      : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ Region    : chr  &amp;quot;Healthy_Sham&amp;quot; &amp;quot;Healthy_Sham&amp;quot; &amp;quot;Healthy_Sham&amp;quot; &amp;quot;Healthy_Sham&amp;quot; ...
##  $ Cells     : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...
##  $ Output    : chr  &amp;quot;Area-Under-Curve&amp;quot; &amp;quot;HFC-Scalar&amp;quot; &amp;quot;LFC-Scalar&amp;quot; &amp;quot;N1&amp;quot; ...
##  $ GroupCount: num  3 3 3 3 3 3 3 3 3 3 ...
##  $ Data      : num  1 1 1 1 20.7 ...
##  $ STD       : num  0.0537 0.5141 0.1355 0.0631 0.5774 ...&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;head-first-few-lines&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Head (first few lines)&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cobra %&amp;gt;% head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 8
##   Pig_Name   Week Region          Cells Output     GroupCount  Data    STD
##   &amp;lt;chr&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;           &amp;lt;lgl&amp;gt; &amp;lt;chr&amp;gt;           &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1 Cobra 749     0 Healthy_Implant F     Area-Unde…       3.00  1.00 0.0994
## 2 Cobra 749     0 Healthy_Implant F     HFC-Scalar       3.00  1.00 0.349 
## 3 Cobra 749     0 Healthy_Implant F     LFC-Scalar       3.00  1.00 0.226 
## 4 Cobra 749     0 Healthy_Implant F     N1               3.00  1.00 0.106 
## 5 Cobra 749     0 Healthy_Implant F     N1-Latency       3.00 15.7  0.577 
## 6 Cobra 749     0 Healthy_Implant F     N1-Prom          3.00  1.00 0.177&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;eel %&amp;gt;% head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 8
##   Pig_Name  Week Region       Cells Output         GroupCount  Data    STD
##   &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;        &amp;lt;lgl&amp;gt; &amp;lt;chr&amp;gt;               &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1 Eel 668      0 Healthy_Sham F     Area-Under-Cu…       3.00  1.00 0.0537
## 2 Eel 668      0 Healthy_Sham F     HFC-Scalar           3.00  1.00 0.514 
## 3 Eel 668      0 Healthy_Sham F     LFC-Scalar           3.00  1.00 0.135 
## 4 Eel 668      0 Healthy_Sham F     N1                   3.00  1.00 0.0631
## 5 Eel 668      0 Healthy_Sham F     N1-Latency           3.00 20.7  0.577 
## 6 Eel 668      0 Healthy_Sham F     N1-Prom              3.00  1.00 0.0781&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Looks like we have implant (cobra) vs sham (eel)?&lt;/p&gt;
&lt;p&gt;We have several types of &lt;code&gt;Output&lt;/code&gt; (Area-Under-Curve, HFC-Scalar, LFC-Scalar, N1, N1-Latency, N1-Prom, N1-Width, N1P1, N2, N2-Latency, N2-Prom, N2-Width, N2P2, P1, P1-Latency, P1-Prom, P1-Width, P1N2, P2, P2-Latency, P2-Prom, P2-Width, Pos.-Area-Under-Curve, RMS-HFC) which are different variables that have been measured. I asked Aaron what he cared most about and he suggested AUC, N1P1, and Latency&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;auc-n1p1-latency&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;AUC, N1P1, Latency&lt;/h2&gt;
&lt;p&gt;We need to get the exact names for those variables&lt;/p&gt;
&lt;p&gt;We can extract all of the &lt;code&gt;Output&lt;/code&gt; values and only print the unique ones&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;eel$Output %&amp;gt;% unique()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;Area-Under-Curve&amp;quot;      &amp;quot;HFC-Scalar&amp;quot;           
##  [3] &amp;quot;LFC-Scalar&amp;quot;            &amp;quot;N1&amp;quot;                   
##  [5] &amp;quot;N1-Latency&amp;quot;            &amp;quot;N1-Prom&amp;quot;              
##  [7] &amp;quot;N1-Width&amp;quot;              &amp;quot;N1P1&amp;quot;                 
##  [9] &amp;quot;N2&amp;quot;                    &amp;quot;N2-Latency&amp;quot;           
## [11] &amp;quot;N2-Prom&amp;quot;               &amp;quot;N2-Width&amp;quot;             
## [13] &amp;quot;N2P2&amp;quot;                  &amp;quot;P1&amp;quot;                   
## [15] &amp;quot;P1-Latency&amp;quot;            &amp;quot;P1-Prom&amp;quot;              
## [17] &amp;quot;P1-Width&amp;quot;              &amp;quot;P1N2&amp;quot;                 
## [19] &amp;quot;P2&amp;quot;                    &amp;quot;P2-Latency&amp;quot;           
## [21] &amp;quot;P2-Prom&amp;quot;               &amp;quot;P2-Width&amp;quot;             
## [23] &amp;quot;Pos.-Area-Under-Curve&amp;quot; &amp;quot;RMS-HFC&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;OK, so &lt;code&gt;Area-Under-Curve&lt;/code&gt;, &lt;code&gt;N1P1&lt;/code&gt;, and &lt;code&gt;N1-Latency&lt;/code&gt; are the three variables we’ll take a look at. Or fewer if I get confused.&lt;/p&gt;
&lt;p&gt;Let’s start by just looking at AUC. Generically it is a machine learning measure of how often an algorithm will distinguish the right answer over the wrong one. 1 is perfect. 0 is perfect wrong. 0.5 is a monkey flipping coins. Not sure what it means here.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;summary-of-eel-and-cobra-auc&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Summary of eel and cobra AUC&lt;/h2&gt;
&lt;p&gt;Get the summary data from just the AUC values for each pig&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cobra %&amp;gt;% filter(Output == &amp;#39;Area-Under-Curve&amp;#39;) %&amp;gt;% pull(Data) %&amp;gt;% summary()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  0.3653  0.4629  0.6895  0.6989  0.9675  1.0000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;eel %&amp;gt;% filter(Output == &amp;#39;Area-Under-Curve&amp;#39;) %&amp;gt;% pull(Data) %&amp;gt;% summary()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  0.6022  0.7717  0.9596  0.8698  0.9959  1.0000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So the sham (eel) has a better AUC?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;what-kind-of-time-points-or-conditions-or-whatever-do-we-have-again&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What kind of time points or conditions or whatever do we have again?&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cobra %&amp;gt;% filter(Output == &amp;#39;Area-Under-Curve&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 8 x 8
##   Pig_Name   Week Region          Cells Output     GroupCount  Data    STD
##   &amp;lt;chr&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;           &amp;lt;lgl&amp;gt; &amp;lt;chr&amp;gt;           &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1 Cobra 749   0   Healthy_Implant F     Area-Unde…       3.00 1.00  0.0994
## 2 Cobra 749  14.0 Healthy_Implant F     Area-Unde…       3.00 0.690 0.0877
## 3 Cobra 749  35.0 Healthy_Implant F     Area-Unde…       3.00 0.689 0.119 
## 4 Cobra 749  58.0 Healthy_Implant F     Area-Unde…       3.00 0.957 0.208 
## 5 Cobra 749   0   Implant_NoLx    F     Area-Unde…       3.00 1.00  0.0868
## 6 Cobra 749  14.0 Implant_NoLx    F     Area-Unde…       3.00 0.365 0.0964
## 7 Cobra 749  35.0 Implant_NoLx    F     Area-Unde…       3.00 0.409 0.102 
## 8 Cobra 749  58.0 Implant_NoLx    F     Area-Unde…       3.00 0.481 0.212&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Oh, we have &lt;em&gt;two kinds or regions&lt;/em&gt;. Didn’t see that before. So the above summary doesn’t take that into account.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;summary-by-pig-and-region&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Summary by pig and region&lt;/h2&gt;
&lt;p&gt;This summary is &lt;code&gt;group_by(Region)&lt;/code&gt; so we’ll get summary data (&lt;code&gt;mean&lt;/code&gt; and &lt;code&gt;median&lt;/code&gt;) by Region now&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cobra %&amp;gt;% filter(Output == &amp;#39;Area-Under-Curve&amp;#39;) %&amp;gt;% group_by(Region) %&amp;gt;% summarise(mean = mean(Data), median= median(Data))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 3
##   Region           mean median
##   &amp;lt;chr&amp;gt;           &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1 Healthy_Implant 0.834  0.823
## 2 Implant_NoLx    0.564  0.445&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;eel %&amp;gt;% filter(Output == &amp;#39;Area-Under-Curve&amp;#39;) %&amp;gt;% group_by(Region) %&amp;gt;% summarise(mean = mean(Data), median= median(Data))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 3
##   Region        mean median
##   &amp;lt;chr&amp;gt;        &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1 Healthy_Sham 0.978  0.992
## 2 Implant-Sham 0.761  0.721&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We also have time (Week). This will be our x axis when we plot, as this data is sampled across time&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;plot-auc-by-time-and-region-and-pig&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Plot AUC by time and region and pig&lt;/h2&gt;
&lt;p&gt;x axis is time, y axis is AUC, and split by region/pig&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cobra_eel_AUC &amp;lt;- rbind(cobra %&amp;gt;% filter(Output == &amp;#39;Area-Under-Curve&amp;#39;), 
                       eel %&amp;gt;% filter(Output == &amp;#39;Area-Under-Curve&amp;#39;))
cobra_eel_AUC %&amp;gt;% 
  ggplot(aes(x=Week, y=Data, shape=Region, colour=Region)) + 
   geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-02-04-let-s-plot-2-smoothed-lines_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;prettier-plot-with-lines-and-more-formatting&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Prettier plot with lines and more formatting&lt;/h2&gt;
&lt;p&gt;Using the ggsci library with the Nature Publishing Group color scheme (&lt;code&gt;scale_colour_npg()&lt;/code&gt;)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cobra_eel_AUC %&amp;gt;% 
  ggplot(aes(x=Week, y=Data, colour=Region, shape = Pig_Name)) + 
  geom_point(size=4) + 
  geom_smooth(method = &amp;#39;loess&amp;#39;) + ## this draws the smoothed lines through the four points. It auto picks an algorithm that works. loess was used here
  theme_bw() + scale_colour_npg() +
  ylab(&amp;#39;AUC&amp;#39;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-02-04-let-s-plot-2-smoothed-lines_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;n1p1-plot&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;N1P1 Plot&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rbind(cobra %&amp;gt;% filter(Output == &amp;#39;N1P1&amp;#39;), eel %&amp;gt;% filter(Output == &amp;#39;N1P1&amp;#39;)) %&amp;gt;% 
  ggplot(aes(x=Week, y=Data, colour=Region, shape = Pig_Name)) + 
  geom_point(size=4) + 
  geom_smooth() + ## this draws the smoothed lines through the four points. It auto picks an algorithm that works. loess was used here
  theme_bw() + scale_colour_npg() +
  ylab(&amp;#39;N1P1&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &amp;#39;loess&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-02-04-let-s-plot-2-smoothed-lines_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;latency-plot&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Latency plot&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rbind(cobra %&amp;gt;% filter(Output == &amp;#39;N1-Latency&amp;#39;), eel %&amp;gt;% filter(Output == &amp;#39;N1-Latency&amp;#39;)) %&amp;gt;% 
  ggplot(aes(x=Week, y=Data, colour=Region, shape = Pig_Name)) + 
  geom_point(size=4) + 
  geom_smooth() + ## this draws the smoothed lines through the four points. It auto picks an algorithm that works. loess was used here
  theme_bw() + scale_colour_npg() +
  ylab(&amp;#39;N1-Latency&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &amp;#39;loess&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-02-04-let-s-plot-2-smoothed-lines_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;bonus&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Bonus&lt;/h2&gt;
&lt;p&gt;We have many variables. We can get a quick sense of how all of the variables separate out the major data categories with a PCA&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all_pigs &amp;lt;- rbind(cobra, eel) %&amp;gt;% 
  select(Region, Pig_Name, Week, Output, Data) %&amp;gt;% 
  spread(Output, Data)
## toss P-Prime-Latency column
all_pigs &amp;lt;- all_pigs %&amp;gt;% select(-`P-Prime-Latency`)
## remove columns with NA
all_pigs &amp;lt;- all_pigs[complete.cases(all_pigs), complete.cases(t(all_pigs))]
pca &amp;lt;- prcomp(all_pigs[,4:ncol(all_pigs)], scale. = T)

## pull out PCA coordinates (pca$x) and add to all_pigs with the cbind
all_pigs &amp;lt;- cbind(all_pigs, pca$x)

ggplot(all_pigs, aes(x=PC1, y=PC4, color=as.factor(Week), shape=Region)) + 
  geom_point(size=5, alpha=0.7) + 
  theme_bw() + 
  scale_colour_npg() &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-02-04-let-s-plot-2-smoothed-lines_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>John Bryan</title>
      <link>/./people/john_bryan/</link>
      <pubDate>Thu, 01 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/./people/john_bryan/</guid>
      <description>

&lt;h2 id=&#34;november-2016-may-2018&#34;&gt;November 2016 - May 2018&lt;/h2&gt;

&lt;h2 id=&#34;education&#34;&gt;Education&lt;/h2&gt;

&lt;p&gt;BA, Mathematics Major, from Clarement 2016&lt;/p&gt;

&lt;h2 id=&#34;next-position&#34;&gt;Next position&lt;/h2&gt;

&lt;p&gt;[BLANK] Medical School&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Let’s Plot 1: Going in circles </title>
      <link>/./post/let-s-plot-1/</link>
      <pubDate>Thu, 01 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/./post/let-s-plot-1/</guid>
      <description>&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#what-is-going-on&#34;&gt;What is going on?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#where-to-get-the-code-and-data&#34;&gt;Where to get the code and data?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#import-data-with-readxl&#34;&gt;Import data with readxl&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#ok-first-lets-remove-the-notes.&#34;&gt;OK, first let’s remove the notes.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#however-we-arent-done.-the-data-is-wide-instead-of-long-and-we-have-mixed-session-ids-amp-1-3-and-angle-1-3-with-the-value-type.&#34;&gt;However, we aren’t done. The data is “wide” instead of “long” and we have mixed session IDs (Amp 1-3 and Angle 1-3) with the value type.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#now-we-need-to-extract-the-session-123-and-the-test-type-amp-or-angle&#34;&gt;Now we need to extract the session (1,2,3) and the test type (Amp or Angle)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#now-we-have-two-value-types-angle-and-amplitude-in-one-column.-so-we-need-to-go-from-long-to-wide-to-split-them-apart.&#34;&gt;Now we have two value types (Angle and Amplitude) in one column. So we need to go from long to wide to split them apart.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#putting-it-all-together-and-saving-so-we-dont-have-to-see-this-big-code-block-later.&#34;&gt;Putting it all together and saving so we don’t have to see this big code block later.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#first-plot.-does-this-work&#34;&gt;First plot. Does this work?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#but-wait-this-is-a-polar-plot.&#34;&gt;But wait, this is a polar plot….&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#not-bad-but-we-have-a-lot-of-little-things-to-do.&#34;&gt;Not bad, but we have a lot of little things to do.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#yeah-so-we-need-to-tell-ggplot-what-the-range-of-values-is.&#34;&gt;Yeah, so we need to tell ggplot what the range of values is.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#cool-the-range-goes-to-360-as-expected.-still-a-few-more-things-to-do&#34;&gt;Cool, the range goes to 360 as expected. Still a few more things to do:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#hmm-wrong-way.-want-180-on-the-left-lets-make-it-negative.&#34;&gt;Hmm, wrong way. (want 180 on the left) Let’s make it negative.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#ok-final-plot-with-some-color-and-geom_point-tweaking&#34;&gt;OK, Final plot with some color and geom_point tweaking!&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sessioninfo&#34;&gt;sessionInfo&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;what-is-going-on&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What is going on?&lt;/h2&gt;
&lt;p&gt;See &lt;a href=&#34;https://davemcg.github.io/post/what-is-let-s-plot/&#34; class=&#34;uri&#34;&gt;https://davemcg.github.io/post/what-is-let-s-plot/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;where-to-get-the-code-and-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Where to get the code and data?&lt;/h2&gt;
&lt;p&gt;Rmarkdown document: &lt;a href=&#34;https://github.com/davemcg/Let_us_plot/blob/master/001_polar_figure/polar_plot.Rmd&#34; class=&#34;uri&#34;&gt;https://github.com/davemcg/Let_us_plot/blob/master/001_polar_figure/polar_plot.Rmd&lt;/a&gt; Data: &lt;a href=&#34;https://github.com/davemcg/Let_us_plot/blob/master/001_polar_figure/polar_values.xlsx&#34; class=&#34;uri&#34;&gt;https://github.com/davemcg/Let_us_plot/blob/master/001_polar_figure/polar_values.xlsx&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;First time making a polar plot….let’s see if ggplot2 can do it.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;import-data-with-readxl&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Import data with readxl&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Attaching packages ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.2.1 ──&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✔ ggplot2 2.2.1     ✔ purrr   0.2.4
## ✔ tibble  1.4.2     ✔ dplyr   0.7.4
## ✔ tidyr   0.7.2     ✔ stringr 1.2.0
## ✔ readr   1.1.1     ✔ forcats 0.2.0&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Conflicts ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
## ✖ dplyr::filter() masks stats::filter()
## ✖ dplyr::lag()    masks stats::lag()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(stringr)
polar_values &amp;lt;- readxl::read_xlsx(&amp;#39;~/git/Let_us_plot/001_polar_figure/polar_values.xlsx&amp;#39;)
polar_values&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 8 x 8
##   X__1         `Od Amp1` `Od Amp2` `Od Amp3` X__2  `Od Angle1` `Od Angle2`
##   &amp;lt;chr&amp;gt;            &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;lgl&amp;gt;       &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt;
## 1 3                2.10      3.01      2.96  NA           66.0        67.7
## 2 5                1.56      1.36      1.54  NA           19.6        14.7
## 3 14               4.79      4.73      4.72  NA          360         353  
## 4 15               0.350     0.320     0.300 NA          257         234  
## 5 18               0.910     0.830     1.12  NA          350         344  
## 6 &amp;lt;NA&amp;gt;            NA        NA        NA     NA           NA          NA  
## 7 1,2,3 are t…    NA        NA        NA     NA           NA          NA  
## 8 Amp and Ang…    NA        NA        NA     NA           NA          NA  
## # ... with 1 more variable: `Od Angle3` &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;ok-first-lets-remove-the-notes.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;OK, first let’s remove the notes.&lt;/h2&gt;
&lt;p&gt;We first slice the first 5 rows, then fix the encoding for &lt;code&gt;Od Amp1&lt;/code&gt;, then remove the empty column in between&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;polar_values &amp;lt;- polar_values %&amp;gt;% 
  slice(1:5) %&amp;gt;% 
  mutate(Patient=as.factor(X__1)) %&amp;gt;% 
  select(Patient,`Od Amp1`:`Od Amp3`, `Od Angle1`:`Od Angle3`)
polar_values&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 5 x 7
##   Patient `Od Amp1` `Od Amp2` `Od Amp3` `Od Angle1` `Od Angle2`
##   &amp;lt;fct&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt;
## 1 3           2.10      3.01      2.96         66.0        67.7
## 2 5           1.56      1.36      1.54         19.6        14.7
## 3 14          4.79      4.73      4.72        360         353  
## 4 15          0.350     0.320     0.300       257         234  
## 5 18          0.910     0.830     1.12        350         344  
## # ... with 1 more variable: `Od Angle3` &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;however-we-arent-done.-the-data-is-wide-instead-of-long-and-we-have-mixed-session-ids-amp-1-3-and-angle-1-3-with-the-value-type.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;However, we aren’t done. The data is “wide” instead of “long” and we have mixed session IDs (Amp 1-3 and Angle 1-3) with the value type.&lt;/h2&gt;
&lt;p&gt;Let’s first deal with the wide issue. If we google “R wide to long” we find this page near the top &lt;a href=&#34;http://www.cookbook-r.com/Manipulating_data/Converting_data_between_wide_and_long_format/&#34; class=&#34;uri&#34;&gt;http://www.cookbook-r.com/Manipulating_data/Converting_data_between_wide_and_long_format/&lt;/a&gt; which tells us that &lt;code&gt;gather&lt;/code&gt; is the function we want.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Test_Session&lt;/code&gt; is the name for the column containing &lt;code&gt;Od Amp1 to Od Angle&lt;/code&gt; &lt;code&gt;Value&lt;/code&gt; is the name for the column holding the test measurements.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;polar_values %&amp;gt;% 
  gather(Test_Session, Value, `Od Amp1`:`Od Angle3`) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 30 x 3
##    Patient Test_Session Value
##    &amp;lt;fct&amp;gt;   &amp;lt;chr&amp;gt;        &amp;lt;dbl&amp;gt;
##  1 3       Od Amp1      2.10 
##  2 5       Od Amp1      1.56 
##  3 14      Od Amp1      4.79 
##  4 15      Od Amp1      0.350
##  5 18      Od Amp1      0.910
##  6 3       Od Amp2      3.01 
##  7 5       Od Amp2      1.36 
##  8 14      Od Amp2      4.73 
##  9 15      Od Amp2      0.320
## 10 18      Od Amp2      0.830
## # ... with 20 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;now-we-need-to-extract-the-session-123-and-the-test-type-amp-or-angle&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Now we need to extract the session (1,2,3) and the test type (Amp or Angle)&lt;/h2&gt;
&lt;p&gt;We will use the fact that the session is &lt;em&gt;always&lt;/em&gt; at the end to our advantage.&lt;/p&gt;
&lt;p&gt;The str_sub function from the stringr package allows you to pick ‘negative’ positions in the string. So we pick last value and the first to the second last position to get what we need.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;polar_values %&amp;gt;% 
  gather(Test_Session, Value, `Od Amp1`:`Od Angle3`) %&amp;gt;% 
  mutate(Session = str_sub(Test_Session, -1), Test = str_sub(Test_Session,1,-2))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 30 x 5
##    Patient Test_Session Value Session Test  
##    &amp;lt;fct&amp;gt;   &amp;lt;chr&amp;gt;        &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt; 
##  1 3       Od Amp1      2.10  1       Od Amp
##  2 5       Od Amp1      1.56  1       Od Amp
##  3 14      Od Amp1      4.79  1       Od Amp
##  4 15      Od Amp1      0.350 1       Od Amp
##  5 18      Od Amp1      0.910 1       Od Amp
##  6 3       Od Amp2      3.01  2       Od Amp
##  7 5       Od Amp2      1.36  2       Od Amp
##  8 14      Od Amp2      4.73  2       Od Amp
##  9 15      Od Amp2      0.320 2       Od Amp
## 10 18      Od Amp2      0.830 2       Od Amp
## # ... with 20 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;now-we-have-two-value-types-angle-and-amplitude-in-one-column.-so-we-need-to-go-from-long-to-wide-to-split-them-apart.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Now we have two value types (Angle and Amplitude) in one column. So we need to go from long to wide to split them apart.&lt;/h2&gt;
&lt;p&gt;We drop the now useless Test_Session column, grab the session number from the end with &lt;code&gt;str_sub&lt;/code&gt;, then us the &lt;code&gt;spread&lt;/code&gt; function to use the Test and Value columns to get it wide.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;polar_values %&amp;gt;% 
  gather(Test_Session, Value, `Od Amp1`:`Od Angle3`) %&amp;gt;% 
  mutate(Session = str_sub(Test_Session, -1), Test = str_sub(Test_Session,1,-2)) %&amp;gt;% 
  select(-Test_Session) %&amp;gt;% 
  spread(Test, Value)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 15 x 4
##    Patient Session `Od Amp` `Od Angle`
##  * &amp;lt;fct&amp;gt;   &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;
##  1 14      1          4.79       360  
##  2 14      2          4.73       353  
##  3 14      3          4.72       353  
##  4 15      1          0.350      257  
##  5 15      2          0.320      234  
##  6 15      3          0.300      276  
##  7 18      1          0.910      350  
##  8 18      2          0.830      344  
##  9 18      3          1.12       349  
## 10 3       1          2.10        66.0
## 11 3       2          3.01        67.7
## 12 3       3          2.96        65.7
## 13 5       1          1.56        19.6
## 14 5       2          1.36        14.7
## 15 5       3          1.54       360&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Boom. Mic drop.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;putting-it-all-together-and-saving-so-we-dont-have-to-see-this-big-code-block-later.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Putting it all together and saving so we don’t have to see this big code block later.&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;reformatted_values &amp;lt;- 
  polar_values %&amp;gt;% 
  gather(Test_Session, Value, `Od Amp1`:`Od Angle3`) %&amp;gt;% 
  mutate(Session = str_sub(Test_Session, -1), Test = str_sub(Test_Session,1,-2)) %&amp;gt;% 
  select(-Test_Session) %&amp;gt;% 
  spread(Test, Value)

reformatted_values&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 15 x 4
##    Patient Session `Od Amp` `Od Angle`
##  * &amp;lt;fct&amp;gt;   &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;
##  1 14      1          4.79       360  
##  2 14      2          4.73       353  
##  3 14      3          4.72       353  
##  4 15      1          0.350      257  
##  5 15      2          0.320      234  
##  6 15      3          0.300      276  
##  7 18      1          0.910      350  
##  8 18      2          0.830      344  
##  9 18      3          1.12       349  
## 10 3       1          2.10        66.0
## 11 3       2          3.01        67.7
## 12 3       3          2.96        65.7
## 13 5       1          1.56        19.6
## 14 5       2          1.36        14.7
## 15 5       3          1.54       360&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;first-plot.-does-this-work&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;First plot. Does this work?&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;reformatted_values %&amp;gt;% ggplot(aes(y=`Od Amp`, x=`Od Angle`)) + geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-02-01-let-s-plot-1_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;but-wait-this-is-a-polar-plot.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;But wait, this is a polar plot….&lt;/h2&gt;
&lt;p&gt;Fortunately ggplot has a function to transform cartesian values into polar values: &lt;code&gt;coord_polar&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;reformatted_values %&amp;gt;% ggplot(aes(y=`Od Amp`, x=`Od Angle`)) + coord_polar() + geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-02-01-let-s-plot-1_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;not-bad-but-we-have-a-lot-of-little-things-to-do.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Not bad, but we have a lot of little things to do.&lt;/h2&gt;
&lt;p&gt;First, I’m suspicious that the ranges of values is from the smallest to the largest. Or maybe 0 to the largest. We can test this by filtering out the bigger values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;reformatted_values %&amp;gt;% 
  filter(`Od Angle` &amp;lt; 300) %&amp;gt;% 
  ggplot(aes(y=`Od Amp`, x=`Od Angle`)) + coord_polar() + geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-02-01-let-s-plot-1_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;yeah-so-we-need-to-tell-ggplot-what-the-range-of-values-is.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Yeah, so we need to tell ggplot what the range of values is.&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;reformatted_values %&amp;gt;% filter(`Od Angle` &amp;lt; 300) %&amp;gt;% 
  ggplot(aes(y=`Od Amp`, x=`Od Angle`)) + 
  coord_polar() + 
  geom_point() +
  scale_x_continuous(limits=c(0,360), breaks = c(0,30,60,90,120,150,180,210,240,270,300,330)) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-02-01-let-s-plot-1_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;cool-the-range-goes-to-360-as-expected.-still-a-few-more-things-to-do&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Cool, the range goes to 360 as expected. Still a few more things to do:&lt;/h2&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Rotate the start point so 90 is the top&lt;/li&gt;
&lt;li&gt;Change directions of values from CW to CCW&lt;/li&gt;
&lt;li&gt;Add color and prettify&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We examine the coord_polar options (type &lt;code&gt;?coord_polar&lt;/code&gt; in the R console) and see that &lt;code&gt;start&lt;/code&gt; and &lt;code&gt;direction&lt;/code&gt; are options. We want to shift 90 degrees…but the &lt;code&gt;start&lt;/code&gt; parameter is in radians. Some quick googling let’s us know that 90 degree ~ 1.57 radians. Let’s use that. And -1 for direction to make it counter clockwise.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;reformatted_values %&amp;gt;% 
  ggplot(aes(y=`Od Amp`, x=`Od Angle`)) + 
  coord_polar(start = 1.57, direction = -1) + 
  geom_point() +
  scale_x_continuous(limits=c(0,360), breaks = c(0,30,60,90,120,150,180,210,240,270,300,330)) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-02-01-let-s-plot-1_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;hmm-wrong-way.-want-180-on-the-left-lets-make-it-negative.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Hmm, wrong way. (want 180 on the left) Let’s make it negative.&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;reformatted_values %&amp;gt;% 
  ggplot(aes(y=`Od Amp`, x=`Od Angle`)) + 
  coord_polar(start = -1.57, direction = -1) + 
  geom_point() +
  scale_x_continuous(limits=c(0,360), breaks = c(0,30,60,90,120,150,180,210,240,270,300,330)) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-02-01-let-s-plot-1_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ok-final-plot-with-some-color-and-geom_point-tweaking&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;OK, Final plot with some color and geom_point tweaking!&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;theme_bw&lt;/code&gt; makes the background white instead of gray, which I prefer&lt;/p&gt;
&lt;p&gt;&lt;code&gt;alpha&lt;/code&gt; in &lt;code&gt;geom_point&lt;/code&gt; makes the points semi-transparent&lt;/p&gt;
&lt;p&gt;&lt;code&gt;scale_colour_brewer&lt;/code&gt; is a nicer color palette, in my opinion&lt;/p&gt;
&lt;p&gt;&lt;code&gt;colour&lt;/code&gt; and &lt;code&gt;shape&lt;/code&gt; in ggplot() gives us color and shape for the patients and three sessions&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;reformatted_values %&amp;gt;% ggplot(aes(y=`Od Amp`, x=`Od Angle`, colour=Patient, shape=Session)) + 
  coord_polar(start = -1.57, direction = -1) + 
  geom_point(size=3, alpha=0.7) + 
  theme_bw() + 
  scale_x_continuous(limits=c(0,360), breaks = c(0,30,60,90,120,150,180,210,240,270,300,330)) + 
  scale_color_brewer(palette =&amp;#39;Set1&amp;#39;) + xlab(&amp;#39;Angle&amp;#39;) + ylab(&amp;#39;Amplitude&amp;#39;) + ggtitle(&amp;#39;OD&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-02-01-let-s-plot-1_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;sessioninfo&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;sessionInfo&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sessionInfo()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 3.4.0 (2017-04-21)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: OS X El Capitan 10.11.6
## 
## Matrix products: default
## BLAS: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] methods   stats     graphics  grDevices utils     datasets  base     
## 
## other attached packages:
##  [1] bindrcpp_0.2    forcats_0.2.0   stringr_1.2.0   dplyr_0.7.4    
##  [5] purrr_0.2.4     readr_1.1.1     tidyr_0.7.2     tibble_1.4.2   
##  [9] ggplot2_2.2.1   tidyverse_1.2.1
## 
## loaded via a namespace (and not attached):
##  [1] tidyselect_0.2.3   xfun_0.1           reshape2_1.4.2    
##  [4] haven_1.1.0        lattice_0.20-35    colorspace_1.3-2  
##  [7] htmltools_0.3.6    yaml_2.1.14        utf8_1.1.3        
## [10] rlang_0.1.6        pillar_1.1.0       foreign_0.8-69    
## [13] glue_1.2.0         RColorBrewer_1.1-2 modelr_0.1.1      
## [16] readxl_1.0.0       bindr_0.1          plyr_1.8.4        
## [19] munsell_0.4.3      blogdown_0.5       gtable_0.2.0      
## [22] cellranger_1.1.0   rvest_0.3.2        psych_1.7.8       
## [25] evaluate_0.10.1    labeling_0.3       knitr_1.17        
## [28] parallel_3.4.0     broom_0.4.3        Rcpp_0.12.13      
## [31] backports_1.1.1    scales_0.5.0.9000  jsonlite_1.5      
## [34] mnormt_1.5-5       hms_0.3            digest_0.6.12     
## [37] stringi_1.1.6      bookdown_0.6       grid_3.4.0        
## [40] rprojroot_1.2      cli_1.0.0          tools_3.4.0       
## [43] magrittr_1.5       lazyeval_0.2.1     crayon_1.3.4      
## [46] pkgconfig_2.0.1    xml2_1.1.1         lubridate_1.7.1   
## [49] assertthat_0.2.0   rmarkdown_1.8      httr_1.3.1        
## [52] rstudioapi_0.7     R6_2.2.2           nlme_3.1-131      
## [55] compiler_3.4.0&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>eyeIntegration</title>
      <link>/./project/eyeintegration/</link>
      <pubDate>Thu, 01 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/./project/eyeintegration/</guid>
      <description></description>
    </item>
    
    <item>
      <title>What is Let’s Plot?</title>
      <link>/./post/what-is-let-s-plot/</link>
      <pubDate>Wed, 31 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/./post/what-is-let-s-plot/</guid>
      <description>&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#tooling&#34;&gt;Tooling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#how-can-i-follow-along&#34;&gt;How can I follow along?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;The concept is simple - I get data from one of the scientists in my group. Or I get my own. Then I demonstrate, step-by-step, how I generate the plot(s). I’ll also toss in some &lt;em&gt;data science&lt;/em&gt; concepts occasionally.&lt;/p&gt;
&lt;p&gt;They are a bit sparse on the words because I’m presenting these in person. But I believe they are clear enough for someone to follow along. Let me know if I’m wrong.&lt;/p&gt;
&lt;div id=&#34;tooling&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Tooling&lt;/h1&gt;
&lt;p&gt;I like R. I like ggplot. I like the tidyverse. That’s what I’ll be using.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;how-can-i-follow-along&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;How can I follow along?&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Download and install R: &lt;a href=&#34;https://cran.r-project.org/&#34; class=&#34;uri&#34;&gt;https://cran.r-project.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Download and install Rstudio: &lt;a href=&#34;https://www.rstudio.com/products/rstudio/download/#download&#34; class=&#34;uri&#34;&gt;https://www.rstudio.com/products/rstudio/download/#download&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;In Rstudio install any libraries that throw an error when you run &lt;code&gt;library (LIBRARYNAME)&lt;/code&gt; with &lt;code&gt;install.packages(LIBRARYNAME)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Then you can (largely) go line by line through the blog post&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Identifying Core Biological Processes Distinguishing Human Eye Tissues With Systems-Level Gene Expression Analyses And Weighted Correlation Networks</title>
      <link>/./publication/eyeintegration/</link>
      <pubDate>Thu, 11 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/./publication/eyeintegration/</guid>
      <description>&lt;p&gt;More detail can easily be written here using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
