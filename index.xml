<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>eye Bioinformatician on eye Bioinformatician</title>
    <link>/./</link>
    <description>Recent content in eye Bioinformatician on eye Bioinformatician</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 -0400</lastBuildDate>
    <atom:link href="//" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Template for rmarkdown reports</title>
      <link>/./post/template-for-rmarkdown-reports/</link>
      <pubDate>Fri, 04 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/./post/template-for-rmarkdown-reports/</guid>
      <description>&lt;div id=&#34;what-is-this&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;What is this?&lt;/h1&gt;
&lt;p&gt;Since I keep opening up random recent Rmarkdown documents to copy the header to paste into my next document, I figure it would be more efficient to just make a post I could reach from anywhere (with an internet connection).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;copy-paste&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Copy / paste:&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt;---
title: THE TITLE
author: David McGaughey
date: &amp;#39;`r format(Sys.Date(), &amp;quot;%Y-%m-%d&amp;quot;)`&amp;#39;
output: 
  html_notebook:
    theme: flatly
    toc: true
    code_folding: hide
---&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;```{r, message=F, warning=F, include=F}
# Load Libraries without printing any warnings or messages
library(tidyverse)
```&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;# Session Info&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```{r}
devtools::session_info()
```&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Easy bam downsampling</title>
      <link>/./post/easy-bam-downsampling/</link>
      <pubDate>Fri, 20 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/./post/easy-bam-downsampling/</guid>
      <description>&lt;p&gt;When you have a set of ChIP-seq (like) files, it is sometimes useful to downsample the larger samples to more closely match most of the samples. Tommy Tang goes into more detail in his &lt;a href=&#34;http://crazyhottommy.blogspot.com/2016/05/downsampling-for-bam-files-to-certain.html&#34;&gt;blog post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Unfortunately the tool suites I use most for bam files (samtools and picard) only downsample to a &lt;em&gt;percentage&lt;/em&gt;. Which isn’t ideal when you want your files to be no more than &lt;code&gt;n&lt;/code&gt; reads.&lt;/p&gt;
&lt;p&gt;This post is just a slight one-upping of Tommy Tang’s &lt;a href=&#34;http://crazyhottommy.blogspot.com/2016/05/downsampling-for-bam-files-to-certain.html&#34;&gt;process&lt;/a&gt; to easily downsample a bam. If you do some googling you’ll find lots of &lt;em&gt;boutique&lt;/em&gt; tools to downsample. Which I tend to avoid because I don’t want to have to sift through the source to make sure what they are doing looks reasonable and often-times there are dependencies to worry about. For something this simple, there &lt;em&gt;should&lt;/em&gt; be a way to pipe together a few commands to get what we want. Which Tommy &lt;em&gt;almost&lt;/em&gt; does.&lt;/p&gt;
&lt;p&gt;His little code snippet is &lt;code&gt;samtools idxstats example.bam | cut -f3 | awk &#39;BEGIN {total=0} {total += $1} END {print total}&#39;&lt;/code&gt;. It sums up the reads present in each chromosome/contig that the bam index holds. It is robust and will work unless the output format &lt;code&gt;idxstats&lt;/code&gt; sub-program is altered. Which I think is unlikely.&lt;/p&gt;
&lt;p&gt;The problem is that you have to do a &lt;em&gt;little&lt;/em&gt; more work to get the percentage to feed &lt;code&gt;samtools view -s&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;So here’s my extension, using &lt;code&gt;awk&lt;/code&gt; to calculate the percentage of the bam file to sample if you want to get to &lt;code&gt;n&lt;/code&gt; reads. It also will return &lt;code&gt;1&lt;/code&gt; if your bam file has fewer reads than your target.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;frac=$( samtools idxstats  input.bam | cut -f3 | awk &#39;BEGIN {total=0} {total += $1} END {frac=15000000/total; if (frac &amp;gt; 1) {print 1} else {print frac}}&#39; )&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;If you &lt;code&gt;echo $frac&lt;/code&gt; you get the downsample percentage: &lt;code&gt;0.334801&lt;/code&gt; for one of my bam files. You replace the 15000000 (15 million) with whatever you want to the the maximum number of reads.&lt;/p&gt;
&lt;p&gt;If your bam has fewer than &lt;code&gt;n&lt;/code&gt; reads you’ll get back &lt;code&gt;1&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;You can then just feed this into &lt;code&gt;samtools view&lt;/code&gt; like so: &lt;code&gt;samtools view -bs $frac input.bam &amp;gt; subsample.bam&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Putting it all together we have a nice two step process which fits nicely into an automated pipeline / workflow:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;frac=$( samtools idxstats  input.bam | cut -f3 | awk &#39;BEGIN {total=0} {total += $1} END {frac=15000000/total; if (frac &amp;gt; 1) {print 1} else {print frac}}&#39; )&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;samtools view -bs $frac input.bam &amp;gt; subsample.bam&lt;/code&gt;&lt;/p&gt;
&lt;div id=&#34;update&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;UPDATE&lt;/h1&gt;
&lt;p&gt;Tommy pointed out that you should run this &lt;strong&gt;after&lt;/strong&gt; you have removed reads that are duplicated, singletons, and low quality. It is not unusual to see bam files with &amp;gt;50% duplicate reads.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Let’s Plot 5: ridgeline density plots</title>
      <link>/./post/let-s-plot-5-ridgeline-density-plots/</link>
      <pubDate>Thu, 12 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/./post/let-s-plot-5-ridgeline-density-plots/</guid>
      <description>&lt;div id=&#34;intro&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Intro&lt;/h1&gt;
&lt;p&gt;For this installment of Let’s Plot (where anyone can make a figure!), we’ll be making the hottest visualization of 2017 - the &lt;em&gt;joy plot&lt;/em&gt; or &lt;em&gt;ridgeline plot&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Joy plots are partially overlapping density line plots. They are useful for densely showing changes in many distributions over time / condition / etc.&lt;/p&gt;
&lt;p&gt;This type of visualization was inspired by the &lt;a href=&#34;https://en.wikipedia.org/wiki/Unknown_Pleasures&#34;&gt;cover art&lt;/a&gt; from Joy Division’s album Unknown Pleasures and implemented in the R package &lt;a href=&#34;http://cran.r-project.org/web/packages/ggridges&#34;&gt;ggridges&lt;/a&gt; by Claus Wilke.
&lt;img src=&#34;/./img/lets_plot_5_cover.jpg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;While the original term for this plot took off as &lt;em&gt;joy plot&lt;/em&gt; it has since been changed to a &lt;em&gt;ridgeline plot&lt;/em&gt; or &lt;em&gt;ridges plots&lt;/em&gt;, as discussed at length &lt;a href=&#34;http://serialmentor.com/blog/2017/9/15/goodbye-joyplots&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Anyways, Claus has a &lt;em&gt;beautiful&lt;/em&gt; intro to his package &lt;a href=&#34;https://cran.r-project.org/web/packages/ggridges/vignettes/gallery.html&#34;&gt;here&lt;/a&gt;. I will not reproduce any of his plots, as I want you to click the link. Plus they are way cooler looking than what we will be making. Which is real(ish) data from people in my division.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;load-davide-merged-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Load Davide merged data&lt;/h1&gt;
&lt;p&gt;This is a highly cut down version of his original data - which is a 160mb csv file. The csv for this exercise can be found &lt;a href=&#34;https://github.com/davemcg/Let_us_plot/blob/master/005_ggridges/davide_cell_size_data.csv&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It contains cell area size for thousands of cells which have had a drug perturbation, split by wells in a dish. One drug per well.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(ggridges)
merged.df &amp;lt;- read_csv(&amp;#39;~/git/Let_us_plot/005_ggridges/davide_cell_size_data.csv&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;what-does-the-data-look-like&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;What does the data look like?&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(merged.df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 3
##   Well.names  Area Drug 
##   &amp;lt;chr&amp;gt;      &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;
## 1 D07          643 20(S 
## 2 D07          388 20(S 
## 3 D09          290 20(S 
## 4 D08         1174 20(S 
## 5 D09          186 20(S 
## 6 D09         7062 20(S&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;first-we-create-a-fake-dmso-to-match-each-drug-so-we-can-see-the-null-distribution-matched-with-each-drug-in-the-visualization-below&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;First we create a fake DMSO to match each drug so we can see the ‘null’ distribution matched with each drug in the visualization below&lt;/h1&gt;
&lt;p&gt;I know &lt;code&gt;for&lt;/code&gt; loops are out of trend, but I find them easier to write &lt;em&gt;and&lt;/em&gt; read compared to &lt;code&gt;purrr&lt;/code&gt;. A lot less compact, I concede.&lt;/p&gt;
&lt;p&gt;This is a bit hacky, but I want to duplicate the DMSO data and assign it to each drug. Later we’ll be splitting the plot by drug, so we can see both the drug data &lt;em&gt;and&lt;/em&gt; the DMSO data in the section.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# for background DMSO plot
fake_DMSO_drug &amp;lt;- data.frame()
for (i in (merged.df$Drug %&amp;gt;% unique())){
  print(i)
  fake_DMSO_drug &amp;lt;- rbind(fake_DMSO_drug, merged.df %&amp;gt;% filter(Drug==&amp;#39;DMSO&amp;#39;) %&amp;gt;% mutate(Drug = i, Well.names=paste0(&amp;#39;0DMSO_&amp;#39;, i), DMSO=&amp;#39;Yes&amp;#39;))
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;20(S&amp;quot;
## [1] &amp;quot;3-Am&amp;quot;
## [1] &amp;quot;Brom&amp;quot;
## [1] &amp;quot;Cili&amp;quot;
## [1] &amp;quot;Ctrl&amp;quot;
## [1] &amp;quot;DMSO&amp;quot;
## [1] &amp;quot;ETP&amp;quot;
## [1] &amp;quot;G-Pr&amp;quot;
## [1] &amp;quot;GANT&amp;quot;
## [1] &amp;quot;HA 1&amp;quot;
## [1] &amp;quot;IMR-&amp;quot;
## [1] &amp;quot;IWP-&amp;quot;
## [1] &amp;quot;IWR-&amp;quot;
## [1] &amp;quot;LGK-&amp;quot;
## [1] &amp;quot;LY41&amp;quot;
## [1] &amp;quot;Metf&amp;quot;
## [1] &amp;quot;PJ 3&amp;quot;
## [1] &amp;quot;SANT&amp;quot;
## [1] &amp;quot;Sodi&amp;quot;
## [1] &amp;quot;Tori&amp;quot;
## [1] &amp;quot;UNC&amp;quot;
## [1] &amp;quot;Valp&amp;quot;
## [1] &amp;quot;Wnt-&amp;quot;
## [1] &amp;quot;WYE&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# order drugs by median area
drug_order &amp;lt;- merged.df %&amp;gt;% group_by(Drug) %&amp;gt;% summarise(MedianArea=median(Area)) %&amp;gt;% arrange(MedianArea) %&amp;gt;% pull(Drug)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;ridgeline-plot-showing-each-well-separately&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;ridgeline plot, showing each well separately&lt;/h1&gt;
&lt;p&gt;Several wells got the same drugs. So there are multiple plots per drug.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bind_rows(merged.df %&amp;gt;% mutate(DMSO=&amp;#39;No&amp;#39;),fake_DMSO_drug) %&amp;gt;% 
  filter(Drug!=&amp;#39;DMSO&amp;#39;, Drug!=&amp;#39;Pyr&amp;#39;) %&amp;gt;% # don&amp;#39;t need DMSO plot now and Pyr is empty
  mutate(Drug=factor(Drug, levels=drug_order)) %&amp;gt;% # reorder drugs by drug_order above 
  ggplot(aes(y = Drug, x=log2(Area), group=Well.names, fill=DMSO)) +
  geom_density_ridges(alpha=0.6) + 
  theme_ridges() + 
  scale_fill_brewer(palette = &amp;#39;Set1&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Picking joint bandwidth of 0.258&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-04-12-let-s-plot-5-ridgeline-density-plots_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;same-but-merging-all-wells-together&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Same, but merging all wells together&lt;/h1&gt;
&lt;p&gt;Now merge all the wells together. Notice how the group is now &lt;code&gt;Well.names2&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bind_rows(merged.df %&amp;gt;% 
            mutate(DMSO=&amp;#39;No&amp;#39;, Well.names2=paste0(&amp;#39;Orig&amp;#39;, Drug)),
          fake_DMSO_drug %&amp;gt;% 
            mutate(Well.names2 = Well.names)) %&amp;gt;% 
  filter(Drug!=&amp;#39;DMSO&amp;#39;, Drug!=&amp;#39;Pyro&amp;#39;) %&amp;gt;% # dont&amp;#39; need DMSO plot now and Pyroxamine is empty
  mutate(Drug=factor(Drug, levels=drug_order)) %&amp;gt;% # reorder drugs by drug_order above 
  ggplot(aes(y = Drug, x = log2(Area), group=Well.names2, fill=DMSO)) +
  geom_density_ridges(alpha=0.6) + 
  theme_ridges() + 
  scale_fill_brewer(palette = &amp;#39;Set1&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Picking joint bandwidth of 0.204&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-04-12-let-s-plot-5-ridgeline-density-plots_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;theres-a-large-variation-in-the-number-of-counts&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;There’s a large variation in the number of counts&lt;/h1&gt;
&lt;p&gt;How did I know? Because a bunch of the density plots were super wavy - which means (almost always) that the number of counts in that sample is very low. Low numbers = high variance.&lt;/p&gt;
&lt;p&gt;So IMR, IMP, Tori, and WYE are &lt;em&gt;problem&lt;/em&gt; tests. Perhaps they are just killing the cells? Something for Davide to examine.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cell_area_counts_by_drug &amp;lt;- merged.df %&amp;gt;% 
  group_by(Drug) %&amp;gt;% 
  summarise(Count=n())

cell_area_counts_by_drug  %&amp;gt;% 
  ggplot(aes(x=Drug, y=Count)) +
  geom_bar(stat=&amp;#39;identity&amp;#39;) + 
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-04-12-let-s-plot-5-ridgeline-density-plots_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Are you in genomics and building models? Stop using ROC - use PR</title>
      <link>/./post/are-you-in-genomics-stop-using-roc-use-pr/</link>
      <pubDate>Sat, 03 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/./post/are-you-in-genomics-stop-using-roc-use-pr/</guid>
      <description>&lt;div id=&#34;tldr&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;tldr&lt;/h2&gt;
&lt;p&gt;Area Under the Curve (AUC) of Receiver Operating Characteristic (ROC) is a terrible metric for a genomics problem. Do not use it. This metric also goes by AUC or AUROC. Use Precision Recall AUC.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;inspiration-for-this-post&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Inspiration for this post&lt;/h2&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;I am working on a machine learning problem in genomics&lt;/li&gt;
&lt;li&gt;I was getting really confused why AUROC was so worthless&lt;/li&gt;
&lt;li&gt;scienceTwitter featuring Anshul Kundaje &lt;img src=&#34;/./img/anshul_ROC_PR.png&#34; alt=&#34;https://twitter.com/anshulkundaje/status/965623852209352704&#34; /&gt;&lt;/li&gt;
&lt;li&gt;I want to save you (some time)&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;whats-a-roc&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What’s a ROC?&lt;/h2&gt;
&lt;p&gt;First, you do have to use them because everyone uses them and expects them, but try to move them in the supplementary figures. Eventually the field will stop expecting this and demand to see a useful metric - like AUC of Precision Recall. More on this later.&lt;/p&gt;
&lt;p&gt;Before we discuss how an ROC is constructed, let’s see first see a &lt;em&gt;Confusion Matrix&lt;/em&gt; of a model.&lt;/p&gt;
&lt;table&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Reference&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Positive&lt;/td&gt;
&lt;td&gt;Negative&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Prediction&lt;/td&gt;
&lt;td&gt;Positive&lt;/td&gt;
&lt;td&gt;236&lt;/td&gt;
&lt;td&gt;103&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Negative&lt;/td&gt;
&lt;td&gt;174&lt;/td&gt;
&lt;td&gt;116,952&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The two axes of a ROC are:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;True Positive Rate (TPR) / Sensitivity / Recall (I assume it goes by so many names because different fields kept re-inventing it)&lt;/li&gt;
&lt;li&gt;False Positive Rate (FPR)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The TPR of the model is: &lt;span class=&#34;math display&#34;&gt;\[\frac{236}{236 + 174}\approx0.576\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The FPR of the model is: &lt;span class=&#34;math display&#34;&gt;\[\frac{103}{103 + 116,952}\approx0.001\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The model does not actually spit out positive or negative. It gives out &lt;em&gt;probabilities&lt;/em&gt; that a given item is positive or negative. If we change the probabilities cutoff to different values (to make the classification more or less stringent) we can get different TPR and FPR. This is done to generate TPR and FPR from 0 to 1 and a line is plotted. The AUC for the ROC (AUROC) is then calculated by measuring the area under the curve. Either by taking the &lt;a href=&#34;https://en.wikipedia.org/wiki/Receiver_operating_characteristic&#34;&gt;integral or a trapezoidal approximation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;A larger AUROC is better. 1 is perfect. 0.5 is a bunch of grad students flipping coins.&lt;/p&gt;
&lt;p&gt;Now we have a rough idea of ROC works. Now let’s do some machine learning and see ROC works in practice.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;machine-learning&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Machine Learning&lt;/h2&gt;
&lt;p&gt;Load data. Briefly, they are ClinVar variants for a variety of eye disease. They’ve been classified as &lt;code&gt;Pathogenic&lt;/code&gt; or &lt;code&gt;NotPathogenic&lt;/code&gt; by groups submitting to ClinVar (ClinVar uses the term &lt;em&gt;benign&lt;/em&gt;). Each variant has been labeled with a variety of pathogenicity scores, population frequency info, and &lt;em&gt;in silico&lt;/em&gt; consequences. Empty values were assigned &lt;code&gt;-1&lt;/code&gt; (brief aside: I’m not sure if imputing missing data is a good idea here). One hot encoding was done to turn categorical information into numeric vectors. Each predictor (column) was centered and scaled.&lt;/p&gt;
&lt;p&gt;You can download the &lt;code&gt;clinvar_one_hot_CS_toy_set.tsv.gz&lt;/code&gt; file &lt;a href=&#34;https://github.com/davemcg/eye_var_Pathogenicity/blob/master/processed_data/clinvar_one_hot_CS_toy_set.tsv.gz&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Attaching packages ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.2.1 ──&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✔ ggplot2 2.2.1     ✔ purrr   0.2.4
## ✔ tibble  1.4.2     ✔ dplyr   0.7.4
## ✔ tidyr   0.7.2     ✔ stringr 1.2.0
## ✔ readr   1.1.1     ✔ forcats 0.2.0&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Conflicts ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
## ✖ dplyr::filter() masks stats::filter()
## ✖ dplyr::lag()    masks stats::lag()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;clinvar &amp;lt;- read_tsv(&amp;#39;~/git/eye_var_Pathogenicity/processed_data/clinvar_one_hot_CS_toy_set.tsv.gz&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Parsed with column specification:
## cols(
##   Status = col_character(),
##   is_lof = col_double(),
##   impact_severity = col_double(),
##   polyphen_score = col_double(),
##   sift_score = col_double(),
##   revel = col_double(),
##   cadd_phred = col_double(),
##   af_exac_all = col_double(),
##   pli = col_double(),
##   n_syn = col_double(),
##   n_mis = col_double(),
##   precessive = col_double(),
##   fathmm_mkl_coding_score = col_double()
## )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# set levels for status
clinvar $Status &amp;lt;- factor(clinvar$Status, levels=c(&amp;#39;Pathogenic&amp;#39;,&amp;#39;NotPathogenic&amp;#39;))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;quickly-check-our-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Quickly check our data&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;Status&lt;/code&gt; is the crucial column - it has the answer key&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;clinvar$Status %&amp;gt;% table()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## .
##    Pathogenic NotPathogenic 
##           186          8246&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Predictors&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;clinvar %&amp;gt;% select(-Status) %&amp;gt;% colnames()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;is_lof&amp;quot;                  &amp;quot;impact_severity&amp;quot;        
##  [3] &amp;quot;polyphen_score&amp;quot;          &amp;quot;sift_score&amp;quot;             
##  [5] &amp;quot;revel&amp;quot;                   &amp;quot;cadd_phred&amp;quot;             
##  [7] &amp;quot;af_exac_all&amp;quot;             &amp;quot;pli&amp;quot;                    
##  [9] &amp;quot;n_syn&amp;quot;                   &amp;quot;n_mis&amp;quot;                  
## [11] &amp;quot;precessive&amp;quot;              &amp;quot;fathmm_mkl_coding_score&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;split-data-into-training-and-testing-sets&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Split data into training and testing sets&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;clinvar$index &amp;lt;- seq(1:nrow(clinvar))
set.seed(9253)
train_set &amp;lt;- clinvar %&amp;gt;% group_by(Status) %&amp;gt;% sample_frac(0.5)
test_set &amp;lt;- clinvar %&amp;gt;% filter(!index %in% train_set$index)
# remove index so the models don&amp;#39;t use them to classify
train_set &amp;lt;- train_set %&amp;gt;% select(-index)
test_set &amp;lt;- test_set %&amp;gt;% select(-index)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;set-up-training-paramters&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Set up training paramters&lt;/h2&gt;
&lt;p&gt;This is a nice feature of the &lt;code&gt;caret&lt;/code&gt; package. You can customize training parameters and apply them to multiple algorithms&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(caret)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: lattice&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;caret&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following object is masked from &amp;#39;package:purrr&amp;#39;:
## 
##     lift&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# 5 fold cross validation
# twoClassSummary optimizes the algorithm for AUROC
fitControl_naive &amp;lt;- trainControl(
  classProbs=T, # we want probabilites returned for each prediction
  method = &amp;quot;cv&amp;quot;,
  number = 5,
  summaryFunction = twoClassSummary
)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;build-models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Build models&lt;/h2&gt;
&lt;p&gt;This is the big lie of machine learning. Look how trivial this is! Never mind the difficulty of all the work summarized above…&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bglmFit &amp;lt;- train(Status ~ ., data=train_set, 
                 method = &amp;#39;bayesglm&amp;#39;,
                 trControl = fitControl_naive)
rfFit &amp;lt;- train(Status ~ ., data=train_set, 
               method = &amp;#39;rf&amp;#39;,
                 trControl = fitControl_naive)
# let&amp;#39;s see how a popular pathogenicity score does alone
caddFit &amp;lt;- train(Status ~ ., data=train_set %&amp;gt;% select(Status, cadd_phred), 
                   method = &amp;#39;glm&amp;#39;,
                 trControl = fitControl_naive)


my_models &amp;lt;- list()
my_models$bglm &amp;lt;- bglmFit
my_models$rfFit &amp;lt;- rfFit
my_models$cadd &amp;lt;- caddFit&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;auroc-plot&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;AUROC Plot!&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(PRROC)
# AUROC
roc_maker &amp;lt;- function(model, data) {
  # new predictions on test set
  # don&amp;#39;t use the training set - if you are overfitting you will not get accurate idea of your models merit
  new_predictions &amp;lt;- predict(model, data, type = &amp;#39;prob&amp;#39;) %&amp;gt;%
    mutate(Answers = data$Status, 
           Prediction = case_when(Pathogenic &amp;gt; 0.5 ~ &amp;#39;Pathogenic&amp;#39;, 
                                  TRUE ~ &amp;#39;NotPathogenic&amp;#39;))
  roc.curve(scores.class0 = new_predictions %&amp;gt;% filter(Answers==&amp;#39;Pathogenic&amp;#39;) %&amp;gt;% pull(Pathogenic),
           scores.class1 = new_predictions %&amp;gt;% filter(Answers==&amp;#39;NotPathogenic&amp;#39;) %&amp;gt;% pull(Pathogenic),
           curve = T)
}

#bglm
plot(roc_maker(bglmFit, test_set))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-03-03-are-you-in-genomics-stop-using-roc-use-pr_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt; Wow! 97% AUC for a bayesian generalized linear model for predicting pathogenicity! Let’s go straight to Nature/Cell/PNAS/Science!&lt;/p&gt;
&lt;p&gt;Well, let’s plot all three predictors at once. I did make three models after all.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;roc_data &amp;lt;- data.frame()
for (i in names(my_models)){
  print(my_models[[i]]$method)
  roc &amp;lt;- roc_maker(my_models[[i]], test_set)
  out &amp;lt;- roc$curve[,1:2] %&amp;gt;% data.frame()
  colnames(out) &amp;lt;- c(&amp;#39;FPR&amp;#39;,&amp;#39;Sensitivity&amp;#39;)
  out$model &amp;lt;- i
  out$AUC &amp;lt;- roc$auc
  out$&amp;#39;Model (AUC)&amp;#39; &amp;lt;- paste0(i, &amp;#39; (&amp;#39;,round(roc$auc, 2),&amp;#39;)&amp;#39; )
  roc_data &amp;lt;- rbind(roc_data, out)
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;bayesglm&amp;quot;
## [1] &amp;quot;rf&amp;quot;
## [1] &amp;quot;glm&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;roc &amp;lt;- roc_data %&amp;gt;% 
  ggplot(aes(x=FPR, y=Sensitivity, colour=`Model (AUC)`)) + 
  geom_line() + 
  theme_minimal()  + 
  ggtitle(&amp;#39;AUROC&amp;#39;) +
  ggsci::scale_color_startrek()

roc&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-03-03-are-you-in-genomics-stop-using-roc-use-pr_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Wow, the random forests are even better! CADD alone isn’t so bad, either! 78% is almost a B, right?&lt;/p&gt;
&lt;p&gt;Well, maybe we should make those confusion matrix things I showed earlier. Just to be careful.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cm_maker &amp;lt;- function(model, data, cutoff=0.5, mode = &amp;#39;sens_spec&amp;#39;) {
  new_predictions &amp;lt;- predict(model, data, type=&amp;#39;prob&amp;#39;) %&amp;gt;%
    mutate(Answers = data$Status, Prediction = case_when(Pathogenic &amp;gt; cutoff ~ &amp;#39;Pathogenic&amp;#39;, TRUE ~ &amp;#39;NotPathogenic&amp;#39;))
  confusionMatrix(data = new_predictions$Prediction, reference = new_predictions$Answers, mode= mode)
}

for (i in names(my_models)){
  print(i)
  print(cm_maker(my_models[[i]], test_set)$table)
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;bglm&amp;quot;
##                Reference
## Prediction      Pathogenic NotPathogenic
##   Pathogenic            43            35
##   NotPathogenic         50          4088
## [1] &amp;quot;rfFit&amp;quot;
##                Reference
## Prediction      Pathogenic NotPathogenic
##   Pathogenic            56            14
##   NotPathogenic         37          4109
## [1] &amp;quot;cadd&amp;quot;
##                Reference
## Prediction      Pathogenic NotPathogenic
##   Pathogenic            10             3
##   NotPathogenic         83          4120&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Huh, these do not look so great….the TPR for the bayes glm model is only 46%. But the AUROC looked so awesome.&lt;/p&gt;
&lt;p&gt;What is happening?&lt;/p&gt;
&lt;p&gt;Well, the classes are imbalanced. ROC plots are designed to provide useful information &lt;strong&gt;when your classes are balanced&lt;/strong&gt;. You have a huge set of &lt;code&gt;NotPathogenic&lt;/code&gt; compared to &lt;code&gt;Pathogenic&lt;/code&gt;. We have 186 &lt;code&gt;Pathogenic&lt;/code&gt; and 8246 &lt;code&gt;NotPathogenic&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;A model that always guessed &lt;code&gt;NotPathogenic&lt;/code&gt; would also do great on the AUROC.&lt;/p&gt;
&lt;p&gt;How do we better represent reality?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;precision-recall-plots&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Precision Recall Plots&lt;/h2&gt;
&lt;p&gt;These plot precision against recall. The advantage compared to ROC is that they do not take into the &lt;em&gt;negative&lt;/em&gt; class. Let’s see what they look like with the same models. One thing to quickly note is that, by convention, the plots are ‘mirrored’ compared to ROC - you want your model to be in the top right for a PR plot, instead of the top left for a ROC.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# precision recall AUC
pr_maker &amp;lt;- function(model, data) {
  new_predictions &amp;lt;- predict(model, data, type = &amp;#39;prob&amp;#39;) %&amp;gt;%
    mutate(Answers = data$Status, Prediction = case_when(Pathogenic &amp;gt; 0.5 ~ &amp;#39;Pathogenic&amp;#39;, TRUE ~ &amp;#39;NotPathogenic&amp;#39;))
  pr.curve(scores.class0 = new_predictions %&amp;gt;% filter(Answers==&amp;#39;Pathogenic&amp;#39;) %&amp;gt;% pull(Pathogenic),
           scores.class1 = new_predictions %&amp;gt;% filter(Answers==&amp;#39;NotPathogenic&amp;#39;) %&amp;gt;% pull(Pathogenic),
           curve = T)
}

pr_data &amp;lt;- data.frame()
for (i in names(my_models)){
  print(my_models[[i]]$method)
  pr &amp;lt;- pr_maker(my_models[[i]], test_set)
  out &amp;lt;- pr$curve[,1:2] %&amp;gt;% data.frame()
  colnames(out) &amp;lt;- c(&amp;#39;Recall&amp;#39;,&amp;#39;Precision&amp;#39;)
  out$AUC &amp;lt;- pr$auc.integral
  out$model &amp;lt;- i
  out$&amp;#39;Model (AUC)&amp;#39; &amp;lt;- paste0(i, &amp;#39; (&amp;#39;,round(pr$auc.integral,2),&amp;#39;)&amp;#39; )
  pr_data &amp;lt;- rbind(pr_data, out)
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;bayesglm&amp;quot;
## [1] &amp;quot;rf&amp;quot;
## [1] &amp;quot;glm&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pr &amp;lt;- pr_data %&amp;gt;% 
  ggplot(aes(x=Recall, y=Precision, colour=`Model (AUC)`)) + 
  geom_line() + 
  theme_minimal() + 
  ggtitle(&amp;#39;Precision Recall Curve&amp;#39;) +
  ggsci::scale_color_startrek()

pr&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-03-03-are-you-in-genomics-stop-using-roc-use-pr_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This looks like a more reasonable way to assess performance. Also notice how the RF and bayes GLM have subtantially different performance when being assessed like this, even though the AUROC was only 0.02 apart.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Why again do I have to use PR plots in genomics - I balanced my two classes when I trained the model! Well because in actual problem space, the genome, the problems are &lt;em&gt;always&lt;/em&gt; wildly imbalanced between classes. The human genome is three gigabases (3e9) in size.&lt;/p&gt;
&lt;p&gt;Using knn to identify promoters? There are 20,000 genes * 1000 base pair (bp) promoter = 2e6 bp.&lt;/p&gt;
&lt;p&gt;3e9 / 2e6 = 1500:1 ratio&lt;/p&gt;
&lt;p&gt;Writing a deep convoluational neural network to identify CTCF binding sites? CTCF binds around 50,000 sites * 14bp = 7e5.&lt;/p&gt;
&lt;p&gt;3e9 / 7e5 = 4300:1 ratio&lt;/p&gt;
&lt;p&gt;Using random forests to create a pathogenicity metric? Well, in a given genome only 1-2 positions will contribute to a mendelian disorder.&lt;/p&gt;
&lt;p&gt;3e9 / 2 = 1.5e9:1 ratio&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;a-little-more-reading&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;A little more reading&lt;/h2&gt;
&lt;p&gt;If you have some more time, go read Lior Pachter’s &lt;a href=&#34;https://liorpachter.wordpress.com/2016/12/21/confusion-matrix-terminology-is-taxicab-trigonometry/&#34;&gt;post&lt;/a&gt; on metrics for assessing performance.&lt;/p&gt;
&lt;p&gt;Also check this tweet &lt;a href=&#34;https://twitter.com/michaelhoffman/status/969261327331061760&#34;&gt;conversation&lt;/a&gt; between Michael Hoffman and Anshul Kundaje.&lt;/p&gt;
&lt;p&gt;There are also several web posts that explain &lt;a href=&#34;https://www.kaggle.com/general/7517&#34;&gt;why&lt;/a&gt; &lt;a href=&#34;https://www.kaggle.com/lct14558/imbalanced-data-why-you-should-not-use-roc-curve&#34;&gt;ROC&lt;/a&gt; is bad for unbalanced classes and even a published &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4349800/&#34;&gt;paper&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Let’s Plot 4: R vs Excel, Round 1</title>
      <link>/./post/let-s-plot-4-r-vs-excel/</link>
      <pubDate>Thu, 01 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/./post/let-s-plot-4-r-vs-excel/</guid>
      <description>&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#data&#34;&gt;Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#cleaning&#34;&gt;Cleaning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#reformatting&#34;&gt;Reformatting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#box-plot&#34;&gt;Box Plot&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#boxplot-with-all-the-data-displayed&#34;&gt;Boxplot with all the data displayed&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#i-used-to-prefer-violin-plots&#34;&gt;I used to prefer violin plots&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#im-a-fan-of-beeswarm-plots-with-boxplots&#34;&gt;I’m a fan of beeswarm plots with boxplots&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#doing-statistics.&#34;&gt;Doing statistics.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#session&#34;&gt;Session&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;The battle that we’ve all been waiting for. Excel vs. R. Bar plot versus a plot that actually shows the data.&lt;/p&gt;
&lt;p&gt;Yeah, this isn’t a fair fight.&lt;/p&gt;
&lt;p&gt;Bar plots are terrible. Why? Simple. They don’t show what your data looks like. A bar plot gives you zero idea how many data points there are. You can add error bars, but you don’t know if you are looking at standard error or standard deviation.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/./img/excel_bar_plot_bad.png&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;Box plots are &lt;em&gt;much&lt;/em&gt; better. They display useful information like minimum, maximum, quartiles, and median. But they still can really mislead depending on how your data is structured.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/./img/BoxViolinSmaller.gif&#34; alt=&#34;https://www.autodeskresearch.com/publications/samestats&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;&lt;a href=&#34;https://www.autodeskresearch.com/publications/samestats&#34; class=&#34;uri&#34;&gt;https://www.autodeskresearch.com/publications/samestats&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/./img/journal.pbio.1002128.g001.png&#34; alt=&#34;https://doi.org/10.1371/journal.pbio.1002128&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;&lt;a href=&#34;https://doi.org/10.1371/journal.pbio.1002128&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1371/journal.pbio.1002128&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Why do so many scientists keep using bar (or box) plots? Well, simple. Excel makes bar plots with one click. Excel &lt;em&gt;can&lt;/em&gt; make box plots, but it is &lt;a href=&#34;https://support.office.com/en-us/article/create-a-box-plot-10204530-8cdf-40fe-a711-2eb9785e510f&#34;&gt;not easy&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Excel, as far as I can tell, can’t do what I’m about to show you: violin plots or box plots with the &lt;em&gt;raw data displayed inline&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;As a bonus, I made a short video to demonstrate how you can skip the below data cleaning in R with some clicking and dragging in Excel - then just plot in R.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=_teDfnv0gUE&amp;amp;feature=youtu.be&#34;&gt;Click here&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data&lt;/h2&gt;
&lt;p&gt;A variety of eye measurements between a wild-type zebrafish line and a mutant line.&lt;/p&gt;
&lt;p&gt;You can get the excel file &lt;a href=&#34;https://github.com/davemcg/Let_us_plot/blob/master/004_r_vs_excel/Compiled%20eye%20measurements.xlsx&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;tidyverse&amp;#39; was built under R version 3.4.2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Attaching packages ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.2.1 ──&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✔ ggplot2 2.2.1     ✔ purrr   0.2.4
## ✔ tibble  1.4.2     ✔ dplyr   0.7.4
## ✔ tidyr   0.7.2     ✔ stringr 1.2.0
## ✔ readr   1.1.1     ✔ forcats 0.2.0&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;tibble&amp;#39; was built under R version 3.4.3&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;tidyr&amp;#39; was built under R version 3.4.2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;purrr&amp;#39; was built under R version 3.4.2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;dplyr&amp;#39; was built under R version 3.4.2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Conflicts ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
## ✖ dplyr::filter() masks stats::filter()
## ✖ dplyr::lag()    masks stats::lag()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggsci)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;ggsci&amp;#39; was built under R version 3.4.2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggbeeswarm)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;ggbeeswarm&amp;#39; was built under R version 3.4.1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;micro &amp;lt;- readxl::read_xlsx(&amp;#39;~/git/Let_us_plot/004_r_vs_excel/Compiled eye measurements.xlsx&amp;#39;)
head(micro)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 13
##   X__1  Day3   X__2  Day5  X__3  X__4  X__5  X__6  X__7  X__8  X__9  X__10
##   &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;lgl&amp;gt; &amp;lt;lgl&amp;gt; &amp;lt;lgl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;
## 1 Fish  WT/Het Mut   WT/H… Mut   NA    NA    NA    &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt; 
## 2 1     6.099… 4.80… 7.29… 6.70… NA    NA    NA    &amp;lt;NA&amp;gt;  Day3  &amp;lt;NA&amp;gt;  Day5 
## 3 2     7.099… 5.29… 7.19… 8.20… NA    NA    NA    &amp;lt;NA&amp;gt;  WT/H… Mut   WT/H…
## 4 3     0.05   5.39… 7.69… 7.09… NA    NA    NA    avg   6.06… 5.37… 7.31…
## 5 4     6.3E-2 5.80… 7.19… 6.60… NA    NA    NA    &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt; 
## 6 5     6.400… 5.80… 6.09… 7.09… NA    NA    NA    se    1.50… 1.12… 1.12…
## # ... with 1 more variable: X__11 &amp;lt;chr&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;cleaning&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Cleaning&lt;/h2&gt;
&lt;p&gt;OK, a bit messy since this isn’t a computer-formatted file. I’m going to grab the relevant data (ignoring the summarize stats) by looking at the data and slicing and selecting by coordinates. Not worth doing anything fancier (regex, grep, neural network) to automate this.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# clean
micro &amp;lt;- micro %&amp;gt;% 
  slice(2:31) %&amp;gt;% 
  select(`Fish ID` = X__1, 
         Day3_Het = Day3, 
         Day3_Mut = X__2, 
         Day5_Het = Day5, 
         Day5_Mut = X__3) %&amp;gt;% 
  mutate(Day3_Het = as.numeric(Day3_Het),
         Day3_Mut = as.numeric(Day3_Mut),
         Day5_Het = as.numeric(Day5_Het),
         Day5_Mut = as.numeric(Day5_Mut))
micro&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 30 x 5
##    `Fish ID` Day3_Het Day3_Mut Day5_Het Day5_Mut
##    &amp;lt;chr&amp;gt;        &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
##  1 1           0.0610   0.0480   0.0730   0.0670
##  2 2           0.0710   0.0530   0.0720   0.0820
##  3 3           0.0500   0.0540   0.0770   0.0710
##  4 4           0.0630   0.0580   0.0720   0.0660
##  5 5           0.0640   0.0580   0.0610   0.0710
##  6 6           0.0650   0.0530   0.0750   0.0700
##  7 7           0.0580   0.0560   0.0800   0.0700
##  8 8           0.0570   0.0530   0.0630   0.0760
##  9 9           0.0650   0.0680   0.0730   0.0710
## 10 10          0.0620   0.0610   0.0720   0.0750
## # ... with 20 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;reformatting&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Reformatting&lt;/h2&gt;
&lt;p&gt;We are also going to have to reformat the data since Date and Genotype are mixed together in a column. Would rather have all the data in one column and the date and genotype in their own columns. Confused? Well, just compare the above data to the modified data.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Remember&lt;/strong&gt; - if this is too intimidating right now, then it is fine to just manually move the data around with Excel to make it look like the below data. Then you can just focus on making the figure.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# wide to long
micro &amp;lt;- micro %&amp;gt;% 
  gather(Date_Genotype, Size, -`Fish ID`) %&amp;gt;% 
  separate(Date_Genotype, c(&amp;#39;Date&amp;#39;,&amp;#39;Genotype&amp;#39;))
micro&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 120 x 4
##    `Fish ID` Date  Genotype   Size
##  * &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;     &amp;lt;dbl&amp;gt;
##  1 1         Day3  Het      0.0610
##  2 2         Day3  Het      0.0710
##  3 3         Day3  Het      0.0500
##  4 4         Day3  Het      0.0630
##  5 5         Day3  Het      0.0640
##  6 6         Day3  Het      0.0650
##  7 7         Day3  Het      0.0580
##  8 8         Day3  Het      0.0570
##  9 9         Day3  Het      0.0650
## 10 10        Day3  Het      0.0620
## # ... with 110 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;box-plot&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Box Plot&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;micro %&amp;gt;% ggplot(aes(x=Genotype, y=Size, colour=Genotype)) + 
  facet_wrap(~Date) +
  geom_boxplot() + 
  theme_minimal() + 
  scale_color_aaas()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-03-01-let-s-plot-r-vs-excel_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;boxplot-with-all-the-data-displayed&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Boxplot with all the data displayed&lt;/h2&gt;
&lt;p&gt;So easy with ggplot2&lt;/p&gt;
&lt;p&gt;Remember to have your &lt;code&gt;geom_boxplot&lt;/code&gt; remove display of outliers (since you are showing them now with &lt;code&gt;geom_jitter&lt;/code&gt;)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;micro %&amp;gt;% ggplot(aes(x=Genotype, y=Size, colour=Genotype)) + facet_wrap(~Date) +
  geom_boxplot(outlier.shape = NA) + 
  geom_jitter() + 
  theme_minimal() + 
  scale_color_aaas()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-03-01-let-s-plot-r-vs-excel_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;i-used-to-prefer-violin-plots&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;I used to prefer violin plots&lt;/h2&gt;
&lt;p&gt;But the smoothing for outlier points can be misleading. They also confuse people who haven’t seen them before &lt;strong&gt;and&lt;/strong&gt; you lose the quartile / median info a boxplot provides.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;micro %&amp;gt;% ggplot(aes(x=Genotype, y=Size, colour=Genotype)) + facet_wrap(~Date) +
  geom_violin() + 
  geom_jitter() + 
  theme_minimal() + 
  scale_color_aaas()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-03-01-let-s-plot-r-vs-excel_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;im-a-fan-of-beeswarm-plots-with-boxplots&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;I’m a fan of beeswarm plots with boxplots&lt;/h2&gt;
&lt;p&gt;You get the violin plot structure and the quartile / median info of boxplots. Win win.&lt;/p&gt;
&lt;p&gt;I’ve reduced the alpha (opacity) of the points to put more emphasis on the boxplot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;micro %&amp;gt;% ggplot(aes(x=Genotype, y=Size, colour=Genotype)) + facet_wrap(~Date) +
  geom_boxplot(outlier.shape = NA) + 
  geom_quasirandom(alpha=0.4) + 
  theme_minimal() + 
  scale_color_aaas()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-03-01-let-s-plot-r-vs-excel_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;doing-statistics.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Doing statistics.&lt;/h2&gt;
&lt;p&gt;Are the differences significant between genotype on Day3 and Day5? More precisely, can we reject the null hypothesis (no mean difference in size)?&lt;/p&gt;
&lt;p&gt;Let’s use the venerable t.test. The data eyeballs as normally distributed. I’m using &lt;code&gt;dplyr&lt;/code&gt; &lt;code&gt;filter&lt;/code&gt; to test Day 3 and Day 5 separately, testing for differences in mean between genotypes (hence the right half of the equation below ends with &lt;code&gt;pull(Genotype)&lt;/code&gt;)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Day 3
t.test(micro %&amp;gt;% filter(Date==&amp;#39;Day3&amp;#39;) %&amp;gt;% pull(Size) ~ micro %&amp;gt;% filter(Date==&amp;#39;Day3&amp;#39;) %&amp;gt;% pull(Genotype))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Welch Two Sample t-test
## 
## data:  micro %&amp;gt;% filter(Date == &amp;quot;Day3&amp;quot;) %&amp;gt;% pull(Size) by micro %&amp;gt;% filter(Date == &amp;quot;Day3&amp;quot;) %&amp;gt;% pull(Genotype)
## t = 3.5888, df = 53.629, p-value = 0.0007197
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  0.003029977 0.010703357
## sample estimates:
## mean in group Het mean in group Mut 
##        0.06060000        0.05373333&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Day 5
t.test(micro %&amp;gt;% filter(Date==&amp;#39;Day5&amp;#39;) %&amp;gt;% pull(Size) ~ micro %&amp;gt;% filter(Date==&amp;#39;Day5&amp;#39;) %&amp;gt;% pull(Genotype))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Welch Two Sample t-test
## 
## data:  micro %&amp;gt;% filter(Date == &amp;quot;Day5&amp;quot;) %&amp;gt;% pull(Size) by micro %&amp;gt;% filter(Date == &amp;quot;Day5&amp;quot;) %&amp;gt;% pull(Genotype)
## t = 1.4851, df = 52.164, p-value = 0.1435
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.001029920  0.006896587
## sample estimates:
## mean in group Het mean in group Mut 
##        0.07313333        0.07020000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Yes for Day 3, no for Day 5.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;session&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Session&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::session_info()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Session info -------------------------------------------------------------&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  setting  value                       
##  version  R version 3.4.0 (2017-04-21)
##  system   x86_64, darwin15.6.0        
##  ui       X11                         
##  language (EN)                        
##  collate  en_US.UTF-8                 
##  tz       America/New_York            
##  date     2018-03-01&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Packages -----------------------------------------------------------------&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  package    * version    date       source                          
##  assertthat   0.2.0      2017-04-11 CRAN (R 3.4.0)                  
##  backports    1.1.1      2017-09-25 CRAN (R 3.4.2)                  
##  base       * 3.4.0      2017-04-21 local                           
##  beeswarm     0.2.3      2016-04-25 CRAN (R 3.4.0)                  
##  bindr        0.1        2016-11-13 CRAN (R 3.4.0)                  
##  bindrcpp   * 0.2        2017-06-17 CRAN (R 3.4.0)                  
##  blogdown     0.5        2018-01-24 CRAN (R 3.4.3)                  
##  bookdown     0.6        2018-01-25 CRAN (R 3.4.3)                  
##  broom        0.4.3      2017-11-20 CRAN (R 3.4.0)                  
##  cellranger   1.1.0      2016-07-27 CRAN (R 3.4.0)                  
##  cli          1.0.0      2017-11-05 CRAN (R 3.4.2)                  
##  colorspace   1.3-2      2016-12-14 CRAN (R 3.4.0)                  
##  compiler     3.4.0      2017-04-21 local                           
##  crayon       1.3.4      2017-09-16 CRAN (R 3.4.1)                  
##  datasets   * 3.4.0      2017-04-21 local                           
##  devtools     1.13.4     2017-11-09 CRAN (R 3.4.2)                  
##  digest       0.6.12     2017-01-27 CRAN (R 3.4.0)                  
##  dplyr      * 0.7.4      2017-09-28 CRAN (R 3.4.2)                  
##  evaluate     0.10.1     2017-06-24 CRAN (R 3.4.1)                  
##  forcats    * 0.2.0      2017-01-23 CRAN (R 3.4.0)                  
##  foreign      0.8-69     2017-06-22 CRAN (R 3.4.1)                  
##  ggbeeswarm * 0.6.0      2017-08-07 CRAN (R 3.4.1)                  
##  ggplot2    * 2.2.1      2016-12-30 CRAN (R 3.4.0)                  
##  ggsci      * 2.8        2017-09-30 CRAN (R 3.4.2)                  
##  glue         1.2.0      2017-10-29 CRAN (R 3.4.2)                  
##  graphics   * 3.4.0      2017-04-21 local                           
##  grDevices  * 3.4.0      2017-04-21 local                           
##  grid         3.4.0      2017-04-21 local                           
##  gtable       0.2.0      2016-02-26 CRAN (R 3.4.0)                  
##  haven        1.1.0      2017-07-09 CRAN (R 3.4.0)                  
##  hms          0.3        2016-11-22 CRAN (R 3.4.0)                  
##  htmltools    0.3.6      2017-04-28 CRAN (R 3.4.0)                  
##  httr         1.3.1      2017-08-20 CRAN (R 3.4.1)                  
##  jsonlite     1.5        2017-06-01 CRAN (R 3.4.0)                  
##  knitr        1.17       2017-08-10 CRAN (R 3.4.1)                  
##  labeling     0.3        2014-08-23 CRAN (R 3.4.0)                  
##  lattice      0.20-35    2017-03-25 CRAN (R 3.4.0)                  
##  lazyeval     0.2.1      2017-10-29 CRAN (R 3.4.2)                  
##  lubridate    1.7.1      2017-11-03 CRAN (R 3.4.2)                  
##  magrittr     1.5        2014-11-22 CRAN (R 3.4.0)                  
##  memoise      1.1.0      2017-04-21 CRAN (R 3.4.0)                  
##  methods    * 3.4.0      2017-04-21 local                           
##  mnormt       1.5-5      2016-10-15 CRAN (R 3.4.0)                  
##  modelr       0.1.1      2017-07-24 CRAN (R 3.4.1)                  
##  munsell      0.4.3      2016-02-13 CRAN (R 3.4.0)                  
##  nlme         3.1-131    2017-02-06 CRAN (R 3.4.0)                  
##  parallel     3.4.0      2017-04-21 local                           
##  pillar       1.1.0      2018-01-14 cran (@1.1.0)                   
##  pkgconfig    2.0.1      2017-03-21 CRAN (R 3.4.0)                  
##  plyr         1.8.4      2016-06-08 CRAN (R 3.4.0)                  
##  psych        1.7.8      2017-09-09 CRAN (R 3.4.0)                  
##  purrr      * 0.2.4      2017-10-18 CRAN (R 3.4.2)                  
##  R6           2.2.2      2017-06-17 CRAN (R 3.4.0)                  
##  Rcpp         0.12.13    2017-09-28 CRAN (R 3.4.2)                  
##  readr      * 1.1.1      2017-05-16 CRAN (R 3.4.0)                  
##  readxl       1.0.0      2017-04-18 CRAN (R 3.4.0)                  
##  reshape2     1.4.2      2016-10-22 CRAN (R 3.4.0)                  
##  rlang        0.1.6      2017-12-21 cran (@0.1.6)                   
##  rmarkdown    1.8        2017-11-17 CRAN (R 3.4.2)                  
##  rprojroot    1.2        2017-01-16 CRAN (R 3.4.0)                  
##  rstudioapi   0.7        2017-09-07 CRAN (R 3.4.1)                  
##  rvest        0.3.2      2016-06-17 CRAN (R 3.4.0)                  
##  scales       0.5.0.9000 2017-09-20 Github (hadley/scales@d767915)  
##  stats      * 3.4.0      2017-04-21 local                           
##  stringi      1.1.6      2017-11-17 CRAN (R 3.4.2)                  
##  stringr    * 1.2.0      2017-02-18 CRAN (R 3.4.0)                  
##  tibble     * 1.4.2      2018-01-22 cran (@1.4.2)                   
##  tidyr      * 0.7.2      2017-10-16 CRAN (R 3.4.2)                  
##  tidyselect   0.2.3      2017-11-06 CRAN (R 3.4.2)                  
##  tidyverse  * 1.2.1      2017-11-14 CRAN (R 3.4.2)                  
##  tools        3.4.0      2017-04-21 local                           
##  utf8         1.1.3      2018-01-03 cran (@1.1.3)                   
##  utils      * 3.4.0      2017-04-21 local                           
##  vipor        0.4.5      2017-03-22 CRAN (R 3.4.0)                  
##  withr        2.1.0.9000 2017-11-22 Github (jimhester/withr@fe81c00)
##  xfun         0.1        2018-01-22 CRAN (R 3.4.3)                  
##  xml2         1.1.1      2017-01-24 CRAN (R 3.4.0)                  
##  yaml         2.1.14     2016-11-12 CRAN (R 3.4.0)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Let’s Plot 3: Base pair resolution NGS (exome) coverage plots - Part 2</title>
      <link>/./post/let-s-plot-3-base-pair-resolution-ngs-exome-coverage-plots/</link>
      <pubDate>Thu, 08 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/./post/let-s-plot-3-base-pair-resolution-ngs-exome-coverage-plots/</guid>
      <description>&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#call-mosdepth-on-bam-to-calculate-bp-specific-read-depth&#34;&gt;Call mosdepth on bam to calculate bp-specific read depth&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#intersect-base-pair-depth-info-with-transcript-and-exon-number&#34;&gt;Intersect base pair depth info with transcript and exon number&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#now-its-r-time&#34;&gt;Now it’s R time!&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#prepare-metadata&#34;&gt;Prepare Metadata&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#load-mosdepth-bedtools-intersect-data-and-prep&#34;&gt;Load mosdepth / bedtools intersect data and prep&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#plot-maker-version-1&#34;&gt;Plot Maker, version 1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#version-2&#34;&gt;Version 2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sessioninfo&#34;&gt;sessionInfo()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;This is a barebones (but detailed enough, I hope) discussion of how to take a bam file, extract base pair resolution coverage data, then finagle the data into coverage plots by gene and exon. No data will be given for the below code. I’m not sharing a bam file. Also, not much point to sharing the bed, HGNC name, and gtf file, as there’s a decent chance they won’t work for your bam.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;call-mosdepth-on-bam-to-calculate-bp-specific-read-depth&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Call mosdepth on bam to calculate bp-specific read depth&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/brentp/mosdepth&#34;&gt;mosdepth&lt;/a&gt;, by default, will generate base pair resolution coverage across the entire genome. Another fantastic tool from Brent Peterson and Aaron Quinlan (some point I’ll do a gushy post on &lt;a href=&#34;http://peddy.readthedocs.io/en/latest/&#34;&gt;all&lt;/a&gt; &lt;a href=&#34;http://gemini.readthedocs.io/en/latest/&#34;&gt;of&lt;/a&gt; &lt;a href=&#34;http://bedtools.readthedocs.io/en/latest/&#34;&gt;the&lt;/a&gt; useful tools &lt;a href=&#34;http://quinlanlab.org/#software&#34;&gt;Quinlan and company have made&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;&lt;code&gt;mosdepth&lt;/code&gt; will run &lt;em&gt;very&lt;/em&gt; quickly (minutes instead of hours), compared to &lt;code&gt;bedtools genomecov&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;# bash 
sinteractive --cpus-per-task 16
module load mosdepth
mosdepth -t 16 41001412010527 41001412010527_realigned_recal.bam &amp;amp;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;intersect-base-pair-depth-info-with-transcript-and-exon-number&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Intersect base pair depth info with transcript and exon number&lt;/h2&gt;
&lt;p&gt;The intersect is to select regions overlapping exons and to label them with the transcript name and exon number present in &lt;code&gt;gencode_genes_v27lift37.codingExons.ensembl.bed.gz&lt;/code&gt;. See the code below for how to make your own.&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;# bash

# gencode_genes_v27lift37.codingExons.bed was downloaded from the UCSC table browser from genocde gene v27lift37 and &amp;#39;coding exons&amp;#39; with 0 padding were selected as the output for the bed file
# my https://github.com/davemcg/ChromosomeMappings/ convert_notation.py script was then used to convert the UCSC notation in ensembl notation, which my bam uses
# files in biowulf2:/data/mcgaugheyd/genomes/GRCh37/
module load bedtools
~/git/ChromosomeMappings/convert_notation.py -c ~/git/ChromosomeMappings/GRCh37_gencode2ensembl.txt -f gencode_genes_v27lift37.codingExons.bed | sort -k1,1 -k2,2n | gzip &amp;gt; gencode_genes_v27lift37.codingExons.ensembl.bed.gz
bedtools intersect -wa -wb -a 41001412010527.per-base.bed.gz -b /data/mcgaugheyd/genomes/GRCh37/gencode_genes_v27lift37.codingExons.ensembl.bed.gz | bgzip  &amp;gt; 41001412010527.per-base.labeled.bed.gz &amp;amp;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;now-its-r-time&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Now it’s R time!&lt;/h1&gt;
&lt;div id=&#34;prepare-metadata&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Prepare Metadata&lt;/h2&gt;
&lt;p&gt;You’ll need &lt;a href=&#34;ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_27/GRCh37_mapping/gencode.v27lift37.metadata.HGNC.gz&#34;&gt;HGNC &amp;lt;-&amp;gt; Ensembl Transcript converter&lt;/a&gt; and the &lt;a href=&#34;ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_27/GRCh37_mapping/gencode.v27lift37.basic.annotation.gtf.gz&#34;&gt;Gencode GTF&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The first file is used to match gene ‘names’ with ensembl transcript ID&lt;/p&gt;
&lt;p&gt;The second file is used to semi-accurately pick the ‘canonical’ transcript for a gene (pick the appris transcript, then the longest)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(data.table)
library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Attaching packages ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.2.1 ──&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✔ ggplot2 2.2.1     ✔ purrr   0.2.4
## ✔ tibble  1.4.2     ✔ dplyr   0.7.4
## ✔ tidyr   0.8.0     ✔ stringr 1.3.0
## ✔ readr   1.1.1     ✔ forcats 0.3.0&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Conflicts ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
## ✖ dplyr::between()   masks data.table::between()
## ✖ dplyr::filter()    masks stats::filter()
## ✖ dplyr::first()     masks data.table::first()
## ✖ dplyr::lag()       masks stats::lag()
## ✖ dplyr::last()      masks data.table::last()
## ✖ purrr::transpose() masks data.table::transpose()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(cowplot)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;cowplot&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following object is masked from &amp;#39;package:ggplot2&amp;#39;:
## 
##     ggsave&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(stringr)
metadata &amp;lt;- fread(&amp;#39;gzcat ~/GenomicData/gencode.v27lift37.metadata.HGNC.gz&amp;#39;, header=F)
colnames(metadata) &amp;lt;- c(&amp;#39;Transcript&amp;#39;,&amp;#39;Name&amp;#39;)
gencode &amp;lt;- fread(&amp;#39;gzcat ~/GenomicData/gencode.v27lift37.basic.annotation.gtf.gz&amp;#39;, header=F, skip=4)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
Read 1.8% of 1651703 rows
Read 14.5% of 1651703 rows
Read 27.9% of 1651703 rows
Read 45.4% of 1651703 rows
Read 47.8% of 1651703 rows
Read 61.1% of 1651703 rows
Read 75.1% of 1651703 rows
Read 93.2% of 1651703 rows
Read 1651703 rows and 9 (of 9) columns from 0.822 GB file in 00:00:11&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gencode2 &amp;lt;- gencode %&amp;gt;% filter(V3==&amp;#39;transcript&amp;#39;) %&amp;gt;% 
  filter(grepl(&amp;#39;appris_principal&amp;#39;, V9)) %&amp;gt;% 
  rowwise() %&amp;gt;%  
  mutate(Transcript = str_extract(V9,&amp;#39;ENST\\d{11}\\.\\d+&amp;#39;), # use regex to graph ensembl transcript 
         Gene = str_extract(V9, &amp;#39;gene_name\\s\\&amp;quot;.*?;&amp;#39;), # and the gene name
         Size=V5-V4) %&amp;gt;% 
  separate(Gene, c(&amp;#39;skip&amp;#39;,&amp;#39;Name&amp;#39;,&amp;#39;skip2&amp;#39;),&amp;#39;\&amp;quot;&amp;#39;) %&amp;gt;% # now you have to remove the &amp;#39;gene name&amp;#39; part  
  select(-skip, -skip2) %&amp;gt;% 
  group_by(Name) %&amp;gt;% top_n(1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Selecting by Size&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;load-mosdepth-bedtools-intersect-data-and-prep&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Load mosdepth / bedtools intersect data and prep&lt;/h2&gt;
&lt;p&gt;Label coverage chunks with the depth of their coverage with case_when and extract the transcript name and exon number with a bunch of &lt;code&gt;separate&lt;/code&gt; commands&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;depth_data &amp;lt;- fread(&amp;#39;gzcat ~/Desktop/41001412010527.per-base.labeled.bed.gz&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
Read 0.0% of 50955214 rows
Read 4.6% of 50955214 rows
Read 8.9% of 50955214 rows
Read 13.2% of 50955214 rows
Read 17.4% of 50955214 rows
Read 21.7% of 50955214 rows
Read 24.4% of 50955214 rows
Read 29.0% of 50955214 rows
Read 33.7% of 50955214 rows
Read 34.6% of 50955214 rows
Read 39.3% of 50955214 rows
Read 43.9% of 50955214 rows
Read 48.6% of 50955214 rows
Read 53.3% of 50955214 rows
Read 57.9% of 50955214 rows
Read 62.6% of 50955214 rows
Read 67.3% of 50955214 rows
Read 71.9% of 50955214 rows
Read 76.6% of 50955214 rows
Read 81.2% of 50955214 rows
Read 85.7% of 50955214 rows
Read 90.1% of 50955214 rows
Read 94.5% of 50955214 rows
Read 99.1% of 50955214 rows
Read 50955214 rows and 10 (of 10) columns from 4.490 GB file in 00:00:40&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dd_processed &amp;lt;- depth_data %&amp;gt;% 
  separate(V8, c(&amp;#39;Transcript&amp;#39;,&amp;#39;Rest&amp;#39;), &amp;#39;_cds_&amp;#39;) %&amp;gt;% 
  separate(Rest, c(&amp;#39;Before&amp;#39;,&amp;#39;Stuff&amp;#39;),&amp;#39;_chr&amp;#39;) %&amp;gt;% 
  separate(Before, c(&amp;#39;Exon Number&amp;#39;,&amp;#39;Num2&amp;#39;),sep=&amp;#39;_&amp;#39;) %&amp;gt;% 
  mutate(Depth = case_when(V4 &amp;lt; 10 ~ &amp;#39;&amp;lt; 10 Reads&amp;#39;, 
                           V4 &amp;lt; 20 ~ &amp;#39;&amp;lt; 20 Reads&amp;#39;, 
                           TRUE ~ &amp;#39;&amp;gt;= 20 Reads&amp;#39;)) %&amp;gt;% 
  mutate(Depth=factor(Depth, levels=c(&amp;#39;&amp;lt; 10 Reads&amp;#39;,&amp;#39;&amp;lt; 20 Reads&amp;#39;,&amp;#39;&amp;gt;= 20 Reads&amp;#39;))) %&amp;gt;% 
  mutate(Transcript=case_when(grepl(&amp;#39;_&amp;#39;,Transcript) ~ gsub(&amp;#39;_.&amp;#39;,&amp;#39;&amp;#39;,Transcript), 
                              TRUE ~ Transcript)) %&amp;gt;% 
  select(Chr=V1, Start=V2, End=V3, Read_Depth=V4, Transcript, Strand=V10, Depth, `Exon Number`, ExonStart=V6, ExonEnd=V7)

dd_processed &amp;lt;- left_join(dd_processed, metadata, by=c(&amp;#39;Transcript&amp;#39;))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;plot-maker-version-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Plot Maker, version 1&lt;/h2&gt;
&lt;p&gt;Faceted by exon. One plot per gene and using cowplot to &lt;em&gt;glue&lt;/em&gt; them together&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;genes &amp;lt;- c(&amp;#39;PAX6&amp;#39;,&amp;#39;ABCA4&amp;#39;,&amp;#39;NRL&amp;#39;,&amp;#39;CRX&amp;#39;,&amp;#39;RPGR&amp;#39;)
transcripts = gencode2 %&amp;gt;% filter(Name %in% genes) %&amp;gt;% pull(Transcript)

# set a custom color that will work even if a category is missing
scale_colour_custom &amp;lt;- function(...){
  ggplot2:::manual_scale(&amp;#39;colour&amp;#39;, 
                         values = setNames(c(&amp;#39;darkred&amp;#39;, &amp;#39;red&amp;#39;, &amp;#39;black&amp;#39;),
                                           c(&amp;#39;&amp;lt; 10 Reads&amp;#39;,&amp;#39;&amp;lt; 20 Reads&amp;#39;,&amp;#39;&amp;gt;= 20 Reads&amp;#39;)), 
                         ...)
}

plot_maker &amp;lt;- function(tx){
  num_of_exons &amp;lt;- dd_processed %&amp;gt;% filter(Transcript==tx) %&amp;gt;% pull(`Exon Number`) %&amp;gt;% as.numeric() %&amp;gt;% max()
  gene_name &amp;lt;-  dd_processed %&amp;gt;% filter(Transcript==tx) %&amp;gt;% pull(Name) %&amp;gt;% unique()
  # expand to create a row for each sequence and fill in previous values
  dd_processed %&amp;gt;% filter(Transcript==tx) %&amp;gt;% group_by(`Exon Number`) %&amp;gt;% 
    expand(Start=full_seq(c(Start,End),1)) %&amp;gt;% 
    left_join(.,  dd_processed %&amp;gt;% filter(Transcript==tx)) %&amp;gt;% # create one row per base position, grouped by Exon Number https://stackoverflow.com/questions/42866119/fill-missing-values-in-data-frame-using-dplyr-complete-within-groups
    fill(Chr:Name) %&amp;gt;% # fill missing values https://stackoverflow.com/questions/40040834/r-replace-na-with-previous-or-next-value-by-group-using-dplyr
    ungroup() %&amp;gt;% # drop the exon number grouping, so I can mutate below
    mutate(`Exon Number`= factor(`Exon Number`,levels=0:num_of_exons)) %&amp;gt;% # Ah, reordering. I need it to be a factor, but then I have to explicitly give the order   
    mutate(Depth = factor(Depth, levels=c(&amp;#39;&amp;lt; 10 Reads&amp;#39;,&amp;#39;&amp;lt; 20 Reads&amp;#39;,&amp;#39;&amp;gt;= 20 Reads&amp;#39;))) %&amp;gt;%  # create three categories for coloring
    ggplot(aes(x=Start, xend=End, y=Read_Depth, yend=Read_Depth, colour=Depth)) + 
    facet_wrap(~`Exon Number`, scales = &amp;#39;free_x&amp;#39;, nrow=1, strip.position = &amp;#39;bottom&amp;#39;) + 
    geom_point(size=0.1) + theme_minimal()+ scale_colour_custom() +  # use my custom color set above for my three categories
    theme(axis.text.x=element_blank(), 
          axis.ticks.x = element_blank(), 
          panel.grid.minor = element_blank(), 
          panel.grid.major.x = element_blank(),
          legend.position = &amp;#39;none&amp;#39;) + 
    ylab(&amp;#39;Depth&amp;#39;) + 
    xlab(paste0(gene_name[1]))
}

# little for loop to roll through the transcripts and make plot, storing in a list
plots &amp;lt;- list()
for (i in transcripts){
  plots[[i]] &amp;lt;- plot_maker(i)
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Joining, by = c(&amp;quot;Exon Number&amp;quot;, &amp;quot;Start&amp;quot;)
## Joining, by = c(&amp;quot;Exon Number&amp;quot;, &amp;quot;Start&amp;quot;)
## Joining, by = c(&amp;quot;Exon Number&amp;quot;, &amp;quot;Start&amp;quot;)
## Joining, by = c(&amp;quot;Exon Number&amp;quot;, &amp;quot;Start&amp;quot;)
## Joining, by = c(&amp;quot;Exon Number&amp;quot;, &amp;quot;Start&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;legend &amp;lt;- get_legend(plots[[names(plots)[1]]] + theme(legend.position=&amp;#39;right&amp;#39;))
# cowplot can take a list and glue the plots together
# I&amp;#39;m commenting out the below line because blogdown makes it too damn small. You need to run it to make the plot
# plot_grid(plot_grid(plotlist = plots, ncol=1, hjust=-2), legend, ncol=2, rel_widths = c(5,0.5))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/./img/lets_plot_3.png&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;version-2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Version 2&lt;/h2&gt;
&lt;p&gt;A bit tighter. Recalculates coordinates to glue all of the exons together in one plot. I can facet by gene. A bit harder to read, but is more accurate as the exons and gene lengths are proportional&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;genes &amp;lt;- c(&amp;#39;PAX6&amp;#39;,&amp;#39;ABCA4&amp;#39;,&amp;#39;NRL&amp;#39;,&amp;#39;CRX&amp;#39;,&amp;#39;RPGR&amp;#39;)
tx = gencode2 %&amp;gt;% filter(Name %in% genes) %&amp;gt;% pull(Transcript)

dd_expanded &amp;lt;- dd_processed %&amp;gt;% filter(Transcript %in% tx) %&amp;gt;% group_by(Transcript, `Exon Number`) %&amp;gt;% 
  expand(Start=full_seq(c(Start,End),1)) %&amp;gt;% 
  left_join(.,  dd_processed %&amp;gt;% filter(Transcript %in% tx)) %&amp;gt;% # create one row per base position, grouped by Exon Number https://stackoverflow.com/questions/42866119/fill-missing-values-in-data-frame-using-dplyr-complete-within-groups
  fill(Chr:Name) # fill missing values https://stackoverflow.com/questions/40040834/r-replace-na-with-previous-or-next-value-by-group-using-dplyr&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Joining, by = c(&amp;quot;Transcript&amp;quot;, &amp;quot;Exon Number&amp;quot;, &amp;quot;Start&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dd_expanded &amp;lt;- dd_expanded %&amp;gt;% group_by(Name) %&amp;gt;% mutate(Pos = 1:n())
even_odds_marking &amp;lt;- dd_expanded %&amp;gt;% group_by(Name, `Exon Number`) %&amp;gt;% summarise(Start=min(Pos), End=max(Pos)) %&amp;gt;% mutate(Exon = case_when(as.numeric(`Exon Number`) %% 2 == 0 ~ &amp;#39;even&amp;#39;, TRUE ~ &amp;#39;odd&amp;#39;))
plot_data&amp;lt;-bind_rows(dd_expanded,even_odds_marking)

ggplot() + 
  geom_point(data =  plot_data %&amp;gt;% filter(is.na(Exon)), aes(x=Pos, y=Read_Depth, colour=Depth),size=0.1)  + 
  facet_wrap(~Name, ncol=1) + 
  geom_rect(data = plot_data %&amp;gt;% filter(!is.na(Exon)), aes(xmin=Start, xmax=End, ymin=-Inf, ymax=Inf, fill=Exon)) +  
  scale_fill_manual(values = alpha(c(&amp;quot;gray&amp;quot;, &amp;quot;white&amp;quot;), .3)) +  
  scale_colour_custom() +
  theme_minimal() +  
  theme(axis.text.x=element_blank(), 
        axis.ticks.x = element_blank(),
        panel.grid.minor = element_blank(), 
        panel.grid.major.x = element_blank())+
  guides(fill=FALSE) + 
  ylab(&amp;#39;Read Depth&amp;#39;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-02-08-let-s-plot-3-base-pair-resolution-ngs-exome-coverage-plots_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;sessioninfo&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;sessionInfo()&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::session_info()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Session info -------------------------------------------------------------&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  setting  value                       
##  version  R version 3.4.0 (2017-04-21)
##  system   x86_64, darwin15.6.0        
##  ui       X11                         
##  language (EN)                        
##  collate  en_US.UTF-8                 
##  tz       America/New_York            
##  date     2018-04-13&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Packages -----------------------------------------------------------------&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  package    * version    date       source                        
##  assertthat   0.2.0      2017-04-11 CRAN (R 3.4.0)                
##  backports    1.1.2      2017-12-13 CRAN (R 3.4.3)                
##  base       * 3.4.0      2017-04-21 local                         
##  bindr        0.1.1      2018-03-13 CRAN (R 3.4.4)                
##  bindrcpp   * 0.2        2017-06-17 CRAN (R 3.4.0)                
##  blogdown     0.5        2018-01-24 CRAN (R 3.4.3)                
##  bookdown     0.7        2018-02-18 CRAN (R 3.4.3)                
##  broom        0.4.3      2017-11-20 CRAN (R 3.4.0)                
##  cellranger   1.1.0      2016-07-27 CRAN (R 3.4.0)                
##  cli          1.0.0      2017-11-05 CRAN (R 3.4.2)                
##  colorspace   1.3-2      2016-12-14 CRAN (R 3.4.0)                
##  compiler     3.4.0      2017-04-21 local                         
##  cowplot    * 0.9.2      2017-12-17 CRAN (R 3.4.3)                
##  crayon       1.3.4      2017-09-16 CRAN (R 3.4.1)                
##  data.table * 1.10.4-3   2017-10-27 CRAN (R 3.4.2)                
##  datasets   * 3.4.0      2017-04-21 local                         
##  devtools     1.13.5     2018-02-18 CRAN (R 3.4.3)                
##  digest       0.6.15     2018-01-28 CRAN (R 3.4.3)                
##  dplyr      * 0.7.4      2017-09-28 CRAN (R 3.4.2)                
##  evaluate     0.10.1     2017-06-24 CRAN (R 3.4.1)                
##  forcats    * 0.3.0      2018-02-19 CRAN (R 3.4.3)                
##  foreign      0.8-69     2017-06-22 CRAN (R 3.4.1)                
##  ggplot2    * 2.2.1      2016-12-30 CRAN (R 3.4.0)                
##  glue         1.2.0      2017-10-29 CRAN (R 3.4.2)                
##  graphics   * 3.4.0      2017-04-21 local                         
##  grDevices  * 3.4.0      2017-04-21 local                         
##  grid         3.4.0      2017-04-21 local                         
##  gtable       0.2.0      2016-02-26 CRAN (R 3.4.0)                
##  haven        1.1.1      2018-01-18 CRAN (R 3.4.3)                
##  hms          0.4.2      2018-03-10 CRAN (R 3.4.4)                
##  htmltools    0.3.6      2017-04-28 CRAN (R 3.4.0)                
##  httr         1.3.1      2017-08-20 CRAN (R 3.4.1)                
##  jsonlite     1.5        2017-06-01 CRAN (R 3.4.0)                
##  knitr        1.20       2018-02-20 CRAN (R 3.4.3)                
##  labeling     0.3        2014-08-23 CRAN (R 3.4.0)                
##  lattice      0.20-35    2017-03-25 CRAN (R 3.4.0)                
##  lazyeval     0.2.1      2017-10-29 CRAN (R 3.4.2)                
##  lubridate    1.7.3      2018-02-27 CRAN (R 3.4.3)                
##  magrittr     1.5        2014-11-22 CRAN (R 3.4.0)                
##  memoise      1.1.0      2017-04-21 CRAN (R 3.4.0)                
##  methods    * 3.4.0      2017-04-21 local                         
##  mnormt       1.5-5      2016-10-15 CRAN (R 3.4.0)                
##  modelr       0.1.1      2017-07-24 CRAN (R 3.4.1)                
##  munsell      0.4.3      2016-02-13 CRAN (R 3.4.0)                
##  nlme         3.1-131.1  2018-02-16 CRAN (R 3.4.3)                
##  parallel     3.4.0      2017-04-21 local                         
##  pillar       1.2.1      2018-02-27 CRAN (R 3.4.3)                
##  pkgconfig    2.0.1      2017-03-21 CRAN (R 3.4.0)                
##  plyr         1.8.4      2016-06-08 CRAN (R 3.4.0)                
##  psych        1.7.8      2017-09-09 CRAN (R 3.4.0)                
##  purrr      * 0.2.4      2017-10-18 CRAN (R 3.4.2)                
##  R6           2.2.2      2017-06-17 CRAN (R 3.4.0)                
##  Rcpp         0.12.16    2018-03-13 CRAN (R 3.4.4)                
##  readr      * 1.1.1      2017-05-16 CRAN (R 3.4.0)                
##  readxl       1.0.0      2017-04-18 CRAN (R 3.4.0)                
##  reshape2     1.4.3      2017-12-11 CRAN (R 3.4.3)                
##  rlang        0.2.0      2018-02-20 CRAN (R 3.4.3)                
##  rmarkdown    1.9        2018-03-01 CRAN (R 3.4.3)                
##  rprojroot    1.3-2      2018-01-03 CRAN (R 3.4.3)                
##  rstudioapi   0.7        2017-09-07 CRAN (R 3.4.1)                
##  rvest        0.3.2      2016-06-17 CRAN (R 3.4.0)                
##  scales       0.5.0.9000 2017-09-20 Github (hadley/scales@d767915)
##  stats      * 3.4.0      2017-04-21 local                         
##  stringi      1.1.7      2018-03-12 CRAN (R 3.4.4)                
##  stringr    * 1.3.0      2018-02-19 CRAN (R 3.4.3)                
##  tibble     * 1.4.2      2018-01-22 cran (@1.4.2)                 
##  tidyr      * 0.8.0      2018-01-29 CRAN (R 3.4.3)                
##  tidyselect   0.2.4      2018-02-26 CRAN (R 3.4.3)                
##  tidyverse  * 1.2.1      2017-11-14 CRAN (R 3.4.2)                
##  tools        3.4.0      2017-04-21 local                         
##  utils      * 3.4.0      2017-04-21 local                         
##  withr        2.1.2      2018-03-15 CRAN (R 3.4.4)                
##  xfun         0.1        2018-01-22 CRAN (R 3.4.3)                
##  xml2         1.2.0      2018-01-24 CRAN (R 3.4.3)                
##  yaml         2.1.18     2018-03-08 CRAN (R 3.4.4)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Split VCF into n pieces by coordinate</title>
      <link>/./post/split-vcf-into-n-pieces-by-coordinate/</link>
      <pubDate>Wed, 07 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/./post/split-vcf-into-n-pieces-by-coordinate/</guid>
      <description>&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#read-in-vcf-header&#34;&gt;Read in vcf header&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#parse-out-chr-contig-sizes&#34;&gt;Parse out chr / contig sizes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#split-chr-above-3e7-base-pairs-into-equalish-size-pieces&#34;&gt;Split chr above 3e7 base pairs into equal(ish) size pieces&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#print-coordinates-given-a-chromosome-contig&#34;&gt;print coordinates given a chromosome / contig&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#calculate-coordinates&#34;&gt;calculate coordinates&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#print-em&#34;&gt;print ’em&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#output-em-for-python-input-snakemake&#34;&gt;output ’em for python input (Snakemake)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#rscript&#34;&gt;rscript&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#using-the-script-output&#34;&gt;Using the script output&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sessioninfo&#34;&gt;sessionInfo()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;bcftools view -r 1:40000-50000 vcf.gz&lt;/code&gt; will output (to stdout) a vcf containing the header and variants on chromosome 1 between coordinates 40,000 and 50,000 base pairs.&lt;/p&gt;
&lt;p&gt;I need to break down a large vcf into smaller pieces to dramatically speed up annotation. Let’s try 100 pieces.&lt;/p&gt;
&lt;p&gt;The human genome is &lt;em&gt;approximately&lt;/em&gt; 3 gigabases or 3e9 base pairs.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \frac{3 * 10^9\ base\ pairs}{100\ pieces} = 3*10^7\ base\ pairs\ per\ piece \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;That’s our target size.&lt;/p&gt;
&lt;p&gt;This is made a bit tricky since the genome is laid by chromosome. So we have to break into 3e7 pieces, accounting for chromosomes. There are also &lt;strong&gt;many&lt;/strong&gt; contigs, most of which are well under 3e7 in size. Those can be processed as a group with &lt;code&gt;bcftools&lt;/code&gt; by splitting each contig by a &lt;code&gt;,&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Let’s read in the header. It contains chromosome (and contig) sizes, which I’ve extracted from the vcf with &lt;code&gt;zcat EGAD00001002656.GATK.vcf.gz | head -n 1000 | grep ^## &amp;gt; /home/mcgaugheyd/git/OGVFB_one_offs/mcgaughey/split_VCFs_into_n_pieces/EGAD00001002656.header&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;read-in-vcf-header&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Read in vcf header&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Attaching packages ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.2.1 ──&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✔ ggplot2 2.2.1     ✔ purrr   0.2.4
## ✔ tibble  1.4.2     ✔ dplyr   0.7.4
## ✔ tidyr   0.7.2     ✔ stringr 1.2.0
## ✔ readr   1.1.1     ✔ forcats 0.2.0&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Conflicts ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
## ✖ dplyr::filter() masks stats::filter()
## ✖ dplyr::lag()    masks stats::lag()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(stringr)
vcf_header = scan(&amp;#39;~/git/OGVFB_one_offs/mcgaughey/split_VCFs_into_n_pieces/EGAD00001002656.header&amp;#39;, what=&amp;#39;character&amp;#39;)
vcf_header[grepl(&amp;#39;contig&amp;#39;,vcf_header)]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;##contig=&amp;lt;ID=1,length=249250621,assembly=b37&amp;gt;&amp;quot;      
##  [2] &amp;quot;##contig=&amp;lt;ID=2,length=243199373,assembly=b37&amp;gt;&amp;quot;      
##  [3] &amp;quot;##contig=&amp;lt;ID=3,length=198022430,assembly=b37&amp;gt;&amp;quot;      
##  [4] &amp;quot;##contig=&amp;lt;ID=4,length=191154276,assembly=b37&amp;gt;&amp;quot;      
##  [5] &amp;quot;##contig=&amp;lt;ID=5,length=180915260,assembly=b37&amp;gt;&amp;quot;      
##  [6] &amp;quot;##contig=&amp;lt;ID=6,length=171115067,assembly=b37&amp;gt;&amp;quot;      
##  [7] &amp;quot;##contig=&amp;lt;ID=7,length=159138663,assembly=b37&amp;gt;&amp;quot;      
##  [8] &amp;quot;##contig=&amp;lt;ID=8,length=146364022,assembly=b37&amp;gt;&amp;quot;      
##  [9] &amp;quot;##contig=&amp;lt;ID=9,length=141213431,assembly=b37&amp;gt;&amp;quot;      
## [10] &amp;quot;##contig=&amp;lt;ID=10,length=135534747,assembly=b37&amp;gt;&amp;quot;     
## [11] &amp;quot;##contig=&amp;lt;ID=11,length=135006516,assembly=b37&amp;gt;&amp;quot;     
## [12] &amp;quot;##contig=&amp;lt;ID=12,length=133851895,assembly=b37&amp;gt;&amp;quot;     
## [13] &amp;quot;##contig=&amp;lt;ID=13,length=115169878,assembly=b37&amp;gt;&amp;quot;     
## [14] &amp;quot;##contig=&amp;lt;ID=14,length=107349540,assembly=b37&amp;gt;&amp;quot;     
## [15] &amp;quot;##contig=&amp;lt;ID=15,length=102531392,assembly=b37&amp;gt;&amp;quot;     
## [16] &amp;quot;##contig=&amp;lt;ID=16,length=90354753,assembly=b37&amp;gt;&amp;quot;      
## [17] &amp;quot;##contig=&amp;lt;ID=17,length=81195210,assembly=b37&amp;gt;&amp;quot;      
## [18] &amp;quot;##contig=&amp;lt;ID=18,length=78077248,assembly=b37&amp;gt;&amp;quot;      
## [19] &amp;quot;##contig=&amp;lt;ID=19,length=59128983,assembly=b37&amp;gt;&amp;quot;      
## [20] &amp;quot;##contig=&amp;lt;ID=20,length=63025520,assembly=b37&amp;gt;&amp;quot;      
## [21] &amp;quot;##contig=&amp;lt;ID=21,length=48129895,assembly=b37&amp;gt;&amp;quot;      
## [22] &amp;quot;##contig=&amp;lt;ID=22,length=51304566,assembly=b37&amp;gt;&amp;quot;      
## [23] &amp;quot;##contig=&amp;lt;ID=X,length=155270560,assembly=b37&amp;gt;&amp;quot;      
## [24] &amp;quot;##contig=&amp;lt;ID=Y,length=59373566,assembly=b37&amp;gt;&amp;quot;       
## [25] &amp;quot;##contig=&amp;lt;ID=MT,length=16569,assembly=b37&amp;gt;&amp;quot;         
## [26] &amp;quot;##contig=&amp;lt;ID=GL000207.1,length=4262,assembly=b37&amp;gt;&amp;quot;  
## [27] &amp;quot;##contig=&amp;lt;ID=GL000226.1,length=15008,assembly=b37&amp;gt;&amp;quot; 
## [28] &amp;quot;##contig=&amp;lt;ID=GL000229.1,length=19913,assembly=b37&amp;gt;&amp;quot; 
## [29] &amp;quot;##contig=&amp;lt;ID=GL000231.1,length=27386,assembly=b37&amp;gt;&amp;quot; 
## [30] &amp;quot;##contig=&amp;lt;ID=GL000210.1,length=27682,assembly=b37&amp;gt;&amp;quot; 
## [31] &amp;quot;##contig=&amp;lt;ID=GL000239.1,length=33824,assembly=b37&amp;gt;&amp;quot; 
## [32] &amp;quot;##contig=&amp;lt;ID=GL000235.1,length=34474,assembly=b37&amp;gt;&amp;quot; 
## [33] &amp;quot;##contig=&amp;lt;ID=GL000201.1,length=36148,assembly=b37&amp;gt;&amp;quot; 
## [34] &amp;quot;##contig=&amp;lt;ID=GL000247.1,length=36422,assembly=b37&amp;gt;&amp;quot; 
## [35] &amp;quot;##contig=&amp;lt;ID=GL000245.1,length=36651,assembly=b37&amp;gt;&amp;quot; 
## [36] &amp;quot;##contig=&amp;lt;ID=GL000197.1,length=37175,assembly=b37&amp;gt;&amp;quot; 
## [37] &amp;quot;##contig=&amp;lt;ID=GL000203.1,length=37498,assembly=b37&amp;gt;&amp;quot; 
## [38] &amp;quot;##contig=&amp;lt;ID=GL000246.1,length=38154,assembly=b37&amp;gt;&amp;quot; 
## [39] &amp;quot;##contig=&amp;lt;ID=GL000249.1,length=38502,assembly=b37&amp;gt;&amp;quot; 
## [40] &amp;quot;##contig=&amp;lt;ID=GL000196.1,length=38914,assembly=b37&amp;gt;&amp;quot; 
## [41] &amp;quot;##contig=&amp;lt;ID=GL000248.1,length=39786,assembly=b37&amp;gt;&amp;quot; 
## [42] &amp;quot;##contig=&amp;lt;ID=GL000244.1,length=39929,assembly=b37&amp;gt;&amp;quot; 
## [43] &amp;quot;##contig=&amp;lt;ID=GL000238.1,length=39939,assembly=b37&amp;gt;&amp;quot; 
## [44] &amp;quot;##contig=&amp;lt;ID=GL000202.1,length=40103,assembly=b37&amp;gt;&amp;quot; 
## [45] &amp;quot;##contig=&amp;lt;ID=GL000234.1,length=40531,assembly=b37&amp;gt;&amp;quot; 
## [46] &amp;quot;##contig=&amp;lt;ID=GL000232.1,length=40652,assembly=b37&amp;gt;&amp;quot; 
## [47] &amp;quot;##contig=&amp;lt;ID=GL000206.1,length=41001,assembly=b37&amp;gt;&amp;quot; 
## [48] &amp;quot;##contig=&amp;lt;ID=GL000240.1,length=41933,assembly=b37&amp;gt;&amp;quot; 
## [49] &amp;quot;##contig=&amp;lt;ID=GL000236.1,length=41934,assembly=b37&amp;gt;&amp;quot; 
## [50] &amp;quot;##contig=&amp;lt;ID=GL000241.1,length=42152,assembly=b37&amp;gt;&amp;quot; 
## [51] &amp;quot;##contig=&amp;lt;ID=GL000243.1,length=43341,assembly=b37&amp;gt;&amp;quot; 
## [52] &amp;quot;##contig=&amp;lt;ID=GL000242.1,length=43523,assembly=b37&amp;gt;&amp;quot; 
## [53] &amp;quot;##contig=&amp;lt;ID=GL000230.1,length=43691,assembly=b37&amp;gt;&amp;quot; 
## [54] &amp;quot;##contig=&amp;lt;ID=GL000237.1,length=45867,assembly=b37&amp;gt;&amp;quot; 
## [55] &amp;quot;##contig=&amp;lt;ID=GL000233.1,length=45941,assembly=b37&amp;gt;&amp;quot; 
## [56] &amp;quot;##contig=&amp;lt;ID=GL000204.1,length=81310,assembly=b37&amp;gt;&amp;quot; 
## [57] &amp;quot;##contig=&amp;lt;ID=GL000198.1,length=90085,assembly=b37&amp;gt;&amp;quot; 
## [58] &amp;quot;##contig=&amp;lt;ID=GL000208.1,length=92689,assembly=b37&amp;gt;&amp;quot; 
## [59] &amp;quot;##contig=&amp;lt;ID=GL000191.1,length=106433,assembly=b37&amp;gt;&amp;quot;
## [60] &amp;quot;##contig=&amp;lt;ID=GL000227.1,length=128374,assembly=b37&amp;gt;&amp;quot;
## [61] &amp;quot;##contig=&amp;lt;ID=GL000228.1,length=129120,assembly=b37&amp;gt;&amp;quot;
## [62] &amp;quot;##contig=&amp;lt;ID=GL000214.1,length=137718,assembly=b37&amp;gt;&amp;quot;
## [63] &amp;quot;##contig=&amp;lt;ID=GL000221.1,length=155397,assembly=b37&amp;gt;&amp;quot;
## [64] &amp;quot;##contig=&amp;lt;ID=GL000209.1,length=159169,assembly=b37&amp;gt;&amp;quot;
## [65] &amp;quot;##contig=&amp;lt;ID=GL000218.1,length=161147,assembly=b37&amp;gt;&amp;quot;
## [66] &amp;quot;##contig=&amp;lt;ID=GL000220.1,length=161802,assembly=b37&amp;gt;&amp;quot;
## [67] &amp;quot;##contig=&amp;lt;ID=GL000213.1,length=164239,assembly=b37&amp;gt;&amp;quot;
## [68] &amp;quot;##contig=&amp;lt;ID=GL000211.1,length=166566,assembly=b37&amp;gt;&amp;quot;
## [69] &amp;quot;##contig=&amp;lt;ID=GL000199.1,length=169874,assembly=b37&amp;gt;&amp;quot;
## [70] &amp;quot;##contig=&amp;lt;ID=GL000217.1,length=172149,assembly=b37&amp;gt;&amp;quot;
## [71] &amp;quot;##contig=&amp;lt;ID=GL000216.1,length=172294,assembly=b37&amp;gt;&amp;quot;
## [72] &amp;quot;##contig=&amp;lt;ID=GL000215.1,length=172545,assembly=b37&amp;gt;&amp;quot;
## [73] &amp;quot;##contig=&amp;lt;ID=GL000205.1,length=174588,assembly=b37&amp;gt;&amp;quot;
## [74] &amp;quot;##contig=&amp;lt;ID=GL000219.1,length=179198,assembly=b37&amp;gt;&amp;quot;
## [75] &amp;quot;##contig=&amp;lt;ID=GL000224.1,length=179693,assembly=b37&amp;gt;&amp;quot;
## [76] &amp;quot;##contig=&amp;lt;ID=GL000223.1,length=180455,assembly=b37&amp;gt;&amp;quot;
## [77] &amp;quot;##contig=&amp;lt;ID=GL000195.1,length=182896,assembly=b37&amp;gt;&amp;quot;
## [78] &amp;quot;##contig=&amp;lt;ID=GL000212.1,length=186858,assembly=b37&amp;gt;&amp;quot;
## [79] &amp;quot;##contig=&amp;lt;ID=GL000222.1,length=186861,assembly=b37&amp;gt;&amp;quot;
## [80] &amp;quot;##contig=&amp;lt;ID=GL000200.1,length=187035,assembly=b37&amp;gt;&amp;quot;
## [81] &amp;quot;##contig=&amp;lt;ID=GL000193.1,length=189789,assembly=b37&amp;gt;&amp;quot;
## [82] &amp;quot;##contig=&amp;lt;ID=GL000194.1,length=191469,assembly=b37&amp;gt;&amp;quot;
## [83] &amp;quot;##contig=&amp;lt;ID=GL000225.1,length=211173,assembly=b37&amp;gt;&amp;quot;
## [84] &amp;quot;##contig=&amp;lt;ID=GL000192.1,length=547496,assembly=b37&amp;gt;&amp;quot;
## [85] &amp;quot;##contig=&amp;lt;ID=NC_007605,length=171823,assembly=b37&amp;gt;&amp;quot; 
## [86] &amp;quot;##contig=&amp;lt;ID=hs37d5,length=35477943,assembly=b37&amp;gt;&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;parse-out-chr-contig-sizes&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Parse out chr / contig sizes&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# turn into data frame (well, a tibble)
contig_size &amp;lt;- vcf_header[grepl(&amp;#39;contig&amp;#39;, vcf_header)] %&amp;gt;% 
  data.frame() %&amp;gt;% 
  select(1, &amp;#39;header&amp;#39; = 1) %&amp;gt;% 
  # separate by ,
  separate(header, c(&amp;#39;contig&amp;#39;,&amp;#39;length&amp;#39;,&amp;#39;assembly&amp;#39;),&amp;#39;,&amp;#39;) %&amp;gt;% 
  # extract values by splitting against = and taking the last element (first after reversing)
  rowwise() %&amp;gt;% 
  mutate(contig = str_split(contig,&amp;#39;=&amp;#39;)[[1]] %&amp;gt;% gsub(&amp;#39;&amp;gt;&amp;#39;,&amp;#39;&amp;#39;,.) %&amp;gt;% rev() %&amp;gt;% .[[1]],
         length = str_split(length,&amp;#39;=&amp;#39;)[[1]] %&amp;gt;% gsub(&amp;#39;&amp;gt;&amp;#39;,&amp;#39;&amp;#39;,.) %&amp;gt;% rev() %&amp;gt;% .[[1]] %&amp;gt;% as.numeric(),
         assembly = str_split(assembly,&amp;#39;=&amp;#39;)[[1]] %&amp;gt;% gsub(&amp;#39;&amp;gt;&amp;#39;,&amp;#39;&amp;#39;,.) %&amp;gt;% rev() %&amp;gt;% .[[1]])
contig_size&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Source: local data frame [86 x 3]
## Groups: &amp;lt;by row&amp;gt;
## 
## # A tibble: 86 x 3
##    contig    length assembly
##    &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;   
##  1 1      249250621 b37     
##  2 2      243199373 b37     
##  3 3      198022430 b37     
##  4 4      191154276 b37     
##  5 5      180915260 b37     
##  6 6      171115067 b37     
##  7 7      159138663 b37     
##  8 8      146364022 b37     
##  9 9      141213431 b37     
## 10 10     135534747 b37     
## # ... with 76 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;split-chr-above-3e7-base-pairs-into-equalish-size-pieces&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Split chr above 3e7 base pairs into equal(ish) size pieces&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;ceiling&lt;/code&gt; will allow intervals a bit less than 3e7 by rounding up the number of pieces per chromsome. Would rather have more splits with less than the target size.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n_split &amp;lt;- function(size){
  pieces &amp;lt;- ceiling(size / 3e7)
  seq(1, size, size/pieces)
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;print-coordinates-given-a-chromosome-contig&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;print coordinates given a chromosome / contig&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n_printer &amp;lt;- function(chr) {
  # grab the legnth of chr or contig
  size &amp;lt;- contig_size %&amp;gt;% filter(contig == chr) %&amp;gt;% pull(length)
  # split into ~30e7 sized pieces
  sequence &amp;lt;- n_split(size)
  # add the max size to end (plus another base pair since the loop below reduces size by 1 to eliminate overlaps)
  sequence &amp;lt;- c(sequence, size+1)
  df &amp;lt;- data.frame()
  for(i in 1:length(sequence)){
    row &amp;lt;- cbind(chr, as.integer(sequence[max(i-1,1)]), # for first row, makes sure you don&amp;#39;t pick the 0 position, which doesn&amp;#39;t exit
                 as.integer(sequence[i]-1)) # decrements by one so you don&amp;#39;t overlap
    df &amp;lt;- rbind(df, row)
  }
  colnames(df) &amp;lt;- c(&amp;#39;chr&amp;#39;,&amp;#39;start&amp;#39;,&amp;#39;end&amp;#39;)
  # skip first row which has dummy values
  df[-1,]
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;calculate-coordinates&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;calculate coordinates&lt;/h2&gt;
&lt;p&gt;Will skip contig &amp;lt; 3e7 (all but hs37d5, which I don’t process, so it will be eliminated). The contigs will be printed comma separated for &lt;code&gt;bcftools view -r&lt;/code&gt; purposes.&lt;/p&gt;
&lt;p&gt;How many regions do we have? Should have a bit more than 100.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;regions &amp;lt;- data.frame()
for (i in contig_size %&amp;gt;% filter(length &amp;gt; 3e7, contig != &amp;#39;hs37d5&amp;#39;) %&amp;gt;% pull(contig)){
  regions &amp;lt;- rbind(regions,(n_printer(i)))
}
regions %&amp;gt;% nrow()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 115&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;print-em&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;print ’em&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;regions %&amp;gt;% mutate(f = paste(paste(chr, start, sep =&amp;#39;:&amp;#39;), end, sep=&amp;#39;-&amp;#39;)) %&amp;gt;% select(f)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                          f
## 1             1:1-27694513
## 2      1:27694514-55389026
## 3      1:55389027-83083540
## 4     1:83083541-110778053
## 5    1:110778054-138472567
## 6    1:138472568-166167080
## 7    1:166167081-193861594
## 8    1:193861595-221556107
## 9    1:221556108-249250621
## 10            2:1-27022152
## 11     2:27022153-54044305
## 12     2:54044306-81066457
## 13    2:81066458-108088610
## 14   2:108088611-135110762
## 15   2:135110763-162132915
## 16   2:162132916-189155067
## 17   2:189155068-216177220
## 18   2:216177221-243199373
## 19            3:1-28288918
## 20     3:28288919-56577837
## 21     3:56577838-84866755
## 22    3:84866756-113155674
## 23   3:113155675-141444592
## 24   3:141444593-169733511
## 25   3:169733512-198022430
## 26            4:1-27307753
## 27     4:27307754-54615507
## 28     4:54615508-81923261
## 29    4:81923262-109231014
## 30   4:109231015-136538768
## 31   4:136538769-163846522
## 32   4:163846523-191154276
## 33            5:1-25845037
## 34     5:25845038-51690074
## 35     5:51690075-77535111
## 36    5:77535112-103380148
## 37   5:103380149-129225185
## 38   5:129225186-155070222
## 39   5:155070223-180915260
## 40            6:1-28519177
## 41     6:28519178-57038355
## 42     6:57038356-85557533
## 43    6:85557534-114076711
## 44   6:114076712-142595889
## 45   6:142595890-171115067
## 46            7:1-26523110
## 47     7:26523111-53046221
## 48     7:53046222-79569331
## 49    7:79569332-106092442
## 50   7:106092443-132615552
## 51   7:132615553-159138663
## 52            8:1-29272804
## 53     8:29272805-58545608
## 54     8:58545609-87818413
## 55    8:87818414-117091217
## 56   8:117091218-146364022
## 57            9:1-28242686
## 58     9:28242687-56485372
## 59     9:56485373-84728058
## 60    9:84728059-112970744
## 61   9:112970745-141213431
## 62           10:1-27106949
## 63    10:27106950-54213898
## 64    10:54213899-81320848
## 65   10:81320849-108427797
## 66  10:108427798-135534747
## 67           11:1-27001303
## 68    11:27001304-54002606
## 69    11:54002607-81003909
## 70   11:81003910-108005212
## 71  11:108005213-135006516
## 72           12:1-26770379
## 73    12:26770380-53540758
## 74    12:53540759-80311137
## 75   12:80311138-107081516
## 76  12:107081517-133851895
## 77           13:1-28792469
## 78    13:28792470-57584939
## 79    13:57584940-86377408
## 80   13:86377409-115169878
## 81           14:1-26837385
## 82    14:26837386-53674770
## 83    14:53674771-80512155
## 84   14:80512156-107349540
## 85           15:1-25632848
## 86    15:25632849-51265696
## 87    15:51265697-76898544
## 88   15:76898545-102531392
## 89           16:1-22588688
## 90    16:22588689-45177376
## 91    16:45177377-67766064
## 92    16:67766065-90354753
## 93           17:1-27065070
## 94    17:27065071-54130140
## 95    17:54130141-81195210
## 96           18:1-26025749
## 97    18:26025750-52051498
## 98    18:52051499-78077248
## 99           19:1-29564491
## 100   19:29564492-59128983
## 101          20:1-21008506
## 102   20:21008507-42017013
## 103   20:42017014-63025520
## 104          21:1-24064947
## 105   21:24064948-48129895
## 106          22:1-25652283
## 107   22:25652284-51304566
## 108           X:1-25878426
## 109    X:25878427-51756853
## 110    X:51756854-77635280
## 111   X:77635281-103513706
## 112  X:103513707-129392133
## 113  X:129392134-155270560
## 114           Y:1-29686783
## 115    Y:29686784-59373566&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;output-em-for-python-input-snakemake&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;output ’em for python input (Snakemake)&lt;/h2&gt;
&lt;p&gt;The second write command appends all of the chromosomes or contigs (in this case, just contigs) that are less than 3e7 in length to the output file. It comma separates them, which is how &lt;code&gt;bcftools view -r&lt;/code&gt; takes in multiple chromosomes or contigs. The &lt;code&gt;paste(., collapse=&#39;,&#39;)&lt;/code&gt; command at the end collapses the vector of contigs into a string with comma separation.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;write(regions %&amp;gt;% mutate(f = paste(paste(chr, start, sep =&amp;#39;:&amp;#39;), end, sep=&amp;#39;-&amp;#39;)) %&amp;gt;% pull(f), file=&amp;#39;vcf_region_split_coords.txt&amp;#39;)
write(contig_size %&amp;gt;% filter(length &amp;lt; 3e7, contig != &amp;#39;hs37d5&amp;#39;) %&amp;gt;% pull(contig) %&amp;gt;% paste(., collapse=&amp;#39;,&amp;#39;), file=&amp;#39;vcf_region_split_coords.txt&amp;#39;, append = T)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;rscript&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;rscript&lt;/h2&gt;
&lt;p&gt;I’ve wrapped up the functions and handling as a Rscript that takes the header of a vcf as input and outputs and writes to a user-given file the regions. The script also allows you to select desired number of regions (you will almost always get a few more), the output file name, and the genome size (defaults to human genome). The script is &lt;a href=&#34;/./files/scripts/split_vcf_into_n_pieces.R&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;using-the-script-output&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Using the script output&lt;/h2&gt;
&lt;p&gt;I’m using it in a Snakemake pipeline. &lt;code&gt;bcftools&lt;/code&gt; can use it with &lt;code&gt;-R&lt;/code&gt; (region) if you run the script like this (see source for comments): &lt;code&gt;Rscript split_vcf_into_n_pieces.R yourVCF.header 200 vcf_region_split_200_coords.txt 3e9 bed&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;sessioninfo&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;sessionInfo()&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::session_info()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Session info -------------------------------------------------------------&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  setting  value                       
##  version  R version 3.4.0 (2017-04-21)
##  system   x86_64, darwin15.6.0        
##  ui       X11                         
##  language (EN)                        
##  collate  en_US.UTF-8                 
##  tz       America/New_York            
##  date     2018-02-13&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Packages -----------------------------------------------------------------&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  package    * version    date       source                          
##  assertthat   0.2.0      2017-04-11 CRAN (R 3.4.0)                  
##  backports    1.1.1      2017-09-25 CRAN (R 3.4.2)                  
##  base       * 3.4.0      2017-04-21 local                           
##  bindr        0.1        2016-11-13 CRAN (R 3.4.0)                  
##  bindrcpp   * 0.2        2017-06-17 CRAN (R 3.4.0)                  
##  blogdown     0.5        2018-01-24 CRAN (R 3.4.3)                  
##  bookdown     0.6        2018-01-25 CRAN (R 3.4.3)                  
##  broom        0.4.3      2017-11-20 CRAN (R 3.4.0)                  
##  cellranger   1.1.0      2016-07-27 CRAN (R 3.4.0)                  
##  cli          1.0.0      2017-11-05 CRAN (R 3.4.2)                  
##  colorspace   1.3-2      2016-12-14 CRAN (R 3.4.0)                  
##  compiler     3.4.0      2017-04-21 local                           
##  crayon       1.3.4      2017-09-16 CRAN (R 3.4.1)                  
##  datasets   * 3.4.0      2017-04-21 local                           
##  devtools     1.13.4     2017-11-09 CRAN (R 3.4.2)                  
##  digest       0.6.12     2017-01-27 CRAN (R 3.4.0)                  
##  dplyr      * 0.7.4      2017-09-28 CRAN (R 3.4.2)                  
##  evaluate     0.10.1     2017-06-24 CRAN (R 3.4.1)                  
##  forcats    * 0.2.0      2017-01-23 CRAN (R 3.4.0)                  
##  foreign      0.8-69     2017-06-22 CRAN (R 3.4.1)                  
##  ggplot2    * 2.2.1      2016-12-30 CRAN (R 3.4.0)                  
##  glue         1.2.0      2017-10-29 CRAN (R 3.4.2)                  
##  graphics   * 3.4.0      2017-04-21 local                           
##  grDevices  * 3.4.0      2017-04-21 local                           
##  grid         3.4.0      2017-04-21 local                           
##  gtable       0.2.0      2016-02-26 CRAN (R 3.4.0)                  
##  haven        1.1.0      2017-07-09 CRAN (R 3.4.0)                  
##  hms          0.3        2016-11-22 CRAN (R 3.4.0)                  
##  htmltools    0.3.6      2017-04-28 CRAN (R 3.4.0)                  
##  httr         1.3.1      2017-08-20 CRAN (R 3.4.1)                  
##  jsonlite     1.5        2017-06-01 CRAN (R 3.4.0)                  
##  knitr        1.17       2017-08-10 CRAN (R 3.4.1)                  
##  lattice      0.20-35    2017-03-25 CRAN (R 3.4.0)                  
##  lazyeval     0.2.1      2017-10-29 CRAN (R 3.4.2)                  
##  lubridate    1.7.1      2017-11-03 CRAN (R 3.4.2)                  
##  magrittr     1.5        2014-11-22 CRAN (R 3.4.0)                  
##  memoise      1.1.0      2017-04-21 CRAN (R 3.4.0)                  
##  methods    * 3.4.0      2017-04-21 local                           
##  mnormt       1.5-5      2016-10-15 CRAN (R 3.4.0)                  
##  modelr       0.1.1      2017-07-24 CRAN (R 3.4.1)                  
##  munsell      0.4.3      2016-02-13 CRAN (R 3.4.0)                  
##  nlme         3.1-131    2017-02-06 CRAN (R 3.4.0)                  
##  parallel     3.4.0      2017-04-21 local                           
##  pillar       1.1.0      2018-01-14 cran (@1.1.0)                   
##  pkgconfig    2.0.1      2017-03-21 CRAN (R 3.4.0)                  
##  plyr         1.8.4      2016-06-08 CRAN (R 3.4.0)                  
##  psych        1.7.8      2017-09-09 CRAN (R 3.4.0)                  
##  purrr      * 0.2.4      2017-10-18 CRAN (R 3.4.2)                  
##  R6           2.2.2      2017-06-17 CRAN (R 3.4.0)                  
##  Rcpp         0.12.13    2017-09-28 CRAN (R 3.4.2)                  
##  readr      * 1.1.1      2017-05-16 CRAN (R 3.4.0)                  
##  readxl       1.0.0      2017-04-18 CRAN (R 3.4.0)                  
##  reshape2     1.4.2      2016-10-22 CRAN (R 3.4.0)                  
##  rlang        0.1.6      2017-12-21 cran (@0.1.6)                   
##  rmarkdown    1.8        2017-11-17 CRAN (R 3.4.2)                  
##  rprojroot    1.2        2017-01-16 CRAN (R 3.4.0)                  
##  rstudioapi   0.7        2017-09-07 CRAN (R 3.4.1)                  
##  rvest        0.3.2      2016-06-17 CRAN (R 3.4.0)                  
##  scales       0.5.0.9000 2017-09-20 Github (hadley/scales@d767915)  
##  stats      * 3.4.0      2017-04-21 local                           
##  stringi      1.1.6      2017-11-17 CRAN (R 3.4.2)                  
##  stringr    * 1.2.0      2017-02-18 CRAN (R 3.4.0)                  
##  tibble     * 1.4.2      2018-01-22 cran (@1.4.2)                   
##  tidyr      * 0.7.2      2017-10-16 CRAN (R 3.4.2)                  
##  tidyselect   0.2.3      2017-11-06 CRAN (R 3.4.2)                  
##  tidyverse  * 1.2.1      2017-11-14 CRAN (R 3.4.2)                  
##  tools        3.4.0      2017-04-21 local                           
##  utf8         1.1.3      2018-01-03 cran (@1.1.3)                   
##  utils      * 3.4.0      2017-04-21 local                           
##  withr        2.1.0.9000 2017-11-22 Github (jimhester/withr@fe81c00)
##  xfun         0.1        2018-01-22 CRAN (R 3.4.3)                  
##  xml2         1.1.1      2017-01-24 CRAN (R 3.4.0)                  
##  yaml         2.1.14     2016-11-12 CRAN (R 3.4.0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;```&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Let’s Plot 2: Smoothed Lines</title>
      <link>/./post/let-s-plot-2-smoothed-lines/</link>
      <pubDate>Sun, 04 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/./post/let-s-plot-2-smoothed-lines/</guid>
      <description>&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#get-data-two-xls-files-from-here&#34;&gt;Get data (two xls files) from here:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#load-data-and-look-at-structure-str&#34;&gt;Load data and look at structure (str)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#head-first-few-lines&#34;&gt;Head (first few lines)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#auc-n1p1-latency&#34;&gt;AUC, N1P1, Latency&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#summary-of-eel-and-cobra-auc&#34;&gt;Summary of eel and cobra AUC&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#what-kind-of-time-points-or-conditions-or-whatever-do-we-have-again&#34;&gt;What kind of time points or conditions or whatever do we have again?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#summary-by-pig-and-region&#34;&gt;Summary by pig and region&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#plot-auc-by-time-and-region-and-pig&#34;&gt;Plot AUC by time and region and pig&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#prettier-plot-with-lines-and-more-formatting&#34;&gt;Prettier plot with lines and more formatting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#n1p1-plot&#34;&gt;N1P1 Plot&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#latency-plot&#34;&gt;Latency plot&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#bonus&#34;&gt;Bonus&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;Data from Aaron Rising.&lt;/p&gt;
&lt;div id=&#34;get-data-two-xls-files-from-here&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Get data (two xls files) from here:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/davemcg/Let_us_plot/tree/master/002_smoothed_lines&#34; class=&#34;uri&#34;&gt;https://github.com/davemcg/Let_us_plot/tree/master/002_smoothed_lines&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;The rmd is also here if you want the source code&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Two different excel files (Cobra and Eel). Pig names?&lt;/p&gt;
&lt;p&gt;They have metrics for eye function across time.&lt;/p&gt;
&lt;p&gt;Aaron told me to take the ‘first tab’ in each excel file. Which is not the case, as at least to me, ‘Sheet 1’ is empty in both. So I’m using the next tab in both, which is ‘Normalized 2 Base For Comb’&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;load-data-and-look-at-structure-str&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Load data and look at structure (str)&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Attaching packages ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.2.1 ──&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✔ ggplot2 2.2.1     ✔ purrr   0.2.4
## ✔ tibble  1.4.2     ✔ dplyr   0.7.4
## ✔ tidyr   0.7.2     ✔ stringr 1.2.0
## ✔ readr   1.1.1     ✔ forcats 0.2.0&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Conflicts ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
## ✖ dplyr::filter() masks stats::filter()
## ✖ dplyr::lag()    masks stats::lag()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggsci)

cobra &amp;lt;- readxl::read_xls(&amp;#39;~/git/Let_us_plot/002_smoothed_lines/Cobra 749--_Normalized_Data_.xls&amp;#39;, sheet = &amp;#39;Normalized 2 Base For Comb&amp;#39;)
cobra %&amp;gt;% str()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Classes &amp;#39;tbl_df&amp;#39;, &amp;#39;tbl&amp;#39; and &amp;#39;data.frame&amp;#39;:    187 obs. of  8 variables:
##  $ Pig_Name  : chr  &amp;quot;Cobra 749&amp;quot; &amp;quot;Cobra 749&amp;quot; &amp;quot;Cobra 749&amp;quot; &amp;quot;Cobra 749&amp;quot; ...
##  $ Week      : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ Region    : chr  &amp;quot;Healthy_Implant&amp;quot; &amp;quot;Healthy_Implant&amp;quot; &amp;quot;Healthy_Implant&amp;quot; &amp;quot;Healthy_Implant&amp;quot; ...
##  $ Cells     : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...
##  $ Output    : chr  &amp;quot;Area-Under-Curve&amp;quot; &amp;quot;HFC-Scalar&amp;quot; &amp;quot;LFC-Scalar&amp;quot; &amp;quot;N1&amp;quot; ...
##  $ GroupCount: num  3 3 3 3 3 3 3 3 3 3 ...
##  $ Data      : num  1 1 1 1 15.7 ...
##  $ STD       : num  0.0994 0.3493 0.2259 0.1063 0.5774 ...&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;eel &amp;lt;- readxl::read_xls(&amp;#39;~/git/Let_us_plot/002_smoothed_lines/Eel 668--_Normalized_Data_.xls&amp;#39;, sheet = &amp;#39;Normalized 2 Base For Comb&amp;#39;)
eel %&amp;gt;% str()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Classes &amp;#39;tbl_df&amp;#39;, &amp;#39;tbl&amp;#39; and &amp;#39;data.frame&amp;#39;:    192 obs. of  8 variables:
##  $ Pig_Name  : chr  &amp;quot;Eel 668&amp;quot; &amp;quot;Eel 668&amp;quot; &amp;quot;Eel 668&amp;quot; &amp;quot;Eel 668&amp;quot; ...
##  $ Week      : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ Region    : chr  &amp;quot;Healthy_Sham&amp;quot; &amp;quot;Healthy_Sham&amp;quot; &amp;quot;Healthy_Sham&amp;quot; &amp;quot;Healthy_Sham&amp;quot; ...
##  $ Cells     : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...
##  $ Output    : chr  &amp;quot;Area-Under-Curve&amp;quot; &amp;quot;HFC-Scalar&amp;quot; &amp;quot;LFC-Scalar&amp;quot; &amp;quot;N1&amp;quot; ...
##  $ GroupCount: num  3 3 3 3 3 3 3 3 3 3 ...
##  $ Data      : num  1 1 1 1 20.7 ...
##  $ STD       : num  0.0537 0.5141 0.1355 0.0631 0.5774 ...&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;head-first-few-lines&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Head (first few lines)&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cobra %&amp;gt;% head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 8
##   Pig_Name   Week Region          Cells Output     GroupCount  Data    STD
##   &amp;lt;chr&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;           &amp;lt;lgl&amp;gt; &amp;lt;chr&amp;gt;           &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1 Cobra 749     0 Healthy_Implant F     Area-Unde…       3.00  1.00 0.0994
## 2 Cobra 749     0 Healthy_Implant F     HFC-Scalar       3.00  1.00 0.349 
## 3 Cobra 749     0 Healthy_Implant F     LFC-Scalar       3.00  1.00 0.226 
## 4 Cobra 749     0 Healthy_Implant F     N1               3.00  1.00 0.106 
## 5 Cobra 749     0 Healthy_Implant F     N1-Latency       3.00 15.7  0.577 
## 6 Cobra 749     0 Healthy_Implant F     N1-Prom          3.00  1.00 0.177&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;eel %&amp;gt;% head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 8
##   Pig_Name  Week Region       Cells Output         GroupCount  Data    STD
##   &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;        &amp;lt;lgl&amp;gt; &amp;lt;chr&amp;gt;               &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1 Eel 668      0 Healthy_Sham F     Area-Under-Cu…       3.00  1.00 0.0537
## 2 Eel 668      0 Healthy_Sham F     HFC-Scalar           3.00  1.00 0.514 
## 3 Eel 668      0 Healthy_Sham F     LFC-Scalar           3.00  1.00 0.135 
## 4 Eel 668      0 Healthy_Sham F     N1                   3.00  1.00 0.0631
## 5 Eel 668      0 Healthy_Sham F     N1-Latency           3.00 20.7  0.577 
## 6 Eel 668      0 Healthy_Sham F     N1-Prom              3.00  1.00 0.0781&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Looks like we have implant (cobra) vs sham (eel)?&lt;/p&gt;
&lt;p&gt;We have several types of &lt;code&gt;Output&lt;/code&gt; (Area-Under-Curve, HFC-Scalar, LFC-Scalar, N1, N1-Latency, N1-Prom, N1-Width, N1P1, N2, N2-Latency, N2-Prom, N2-Width, N2P2, P1, P1-Latency, P1-Prom, P1-Width, P1N2, P2, P2-Latency, P2-Prom, P2-Width, Pos.-Area-Under-Curve, RMS-HFC) which are different variables that have been measured. I asked Aaron what he cared most about and he suggested AUC, N1P1, and Latency&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;auc-n1p1-latency&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;AUC, N1P1, Latency&lt;/h2&gt;
&lt;p&gt;We need to get the exact names for those variables&lt;/p&gt;
&lt;p&gt;We can extract all of the &lt;code&gt;Output&lt;/code&gt; values and only print the unique ones&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;eel$Output %&amp;gt;% unique()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;Area-Under-Curve&amp;quot;      &amp;quot;HFC-Scalar&amp;quot;           
##  [3] &amp;quot;LFC-Scalar&amp;quot;            &amp;quot;N1&amp;quot;                   
##  [5] &amp;quot;N1-Latency&amp;quot;            &amp;quot;N1-Prom&amp;quot;              
##  [7] &amp;quot;N1-Width&amp;quot;              &amp;quot;N1P1&amp;quot;                 
##  [9] &amp;quot;N2&amp;quot;                    &amp;quot;N2-Latency&amp;quot;           
## [11] &amp;quot;N2-Prom&amp;quot;               &amp;quot;N2-Width&amp;quot;             
## [13] &amp;quot;N2P2&amp;quot;                  &amp;quot;P1&amp;quot;                   
## [15] &amp;quot;P1-Latency&amp;quot;            &amp;quot;P1-Prom&amp;quot;              
## [17] &amp;quot;P1-Width&amp;quot;              &amp;quot;P1N2&amp;quot;                 
## [19] &amp;quot;P2&amp;quot;                    &amp;quot;P2-Latency&amp;quot;           
## [21] &amp;quot;P2-Prom&amp;quot;               &amp;quot;P2-Width&amp;quot;             
## [23] &amp;quot;Pos.-Area-Under-Curve&amp;quot; &amp;quot;RMS-HFC&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;OK, so &lt;code&gt;Area-Under-Curve&lt;/code&gt;, &lt;code&gt;N1P1&lt;/code&gt;, and &lt;code&gt;N1-Latency&lt;/code&gt; are the three variables we’ll take a look at. Or fewer if I get confused.&lt;/p&gt;
&lt;p&gt;Let’s start by just looking at AUC. Generically it is a machine learning measure of how often an algorithm will distinguish the right answer over the wrong one. 1 is perfect. 0 is perfect wrong. 0.5 is a monkey flipping coins. Not sure what it means here.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;summary-of-eel-and-cobra-auc&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Summary of eel and cobra AUC&lt;/h2&gt;
&lt;p&gt;Get the summary data from just the AUC values for each pig&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cobra %&amp;gt;% filter(Output == &amp;#39;Area-Under-Curve&amp;#39;) %&amp;gt;% pull(Data) %&amp;gt;% summary()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  0.3653  0.4629  0.6895  0.6989  0.9675  1.0000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;eel %&amp;gt;% filter(Output == &amp;#39;Area-Under-Curve&amp;#39;) %&amp;gt;% pull(Data) %&amp;gt;% summary()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  0.6022  0.7717  0.9596  0.8698  0.9959  1.0000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So the sham (eel) has a better AUC?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;what-kind-of-time-points-or-conditions-or-whatever-do-we-have-again&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What kind of time points or conditions or whatever do we have again?&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cobra %&amp;gt;% filter(Output == &amp;#39;Area-Under-Curve&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 8 x 8
##   Pig_Name   Week Region          Cells Output     GroupCount  Data    STD
##   &amp;lt;chr&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;           &amp;lt;lgl&amp;gt; &amp;lt;chr&amp;gt;           &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1 Cobra 749   0   Healthy_Implant F     Area-Unde…       3.00 1.00  0.0994
## 2 Cobra 749  14.0 Healthy_Implant F     Area-Unde…       3.00 0.690 0.0877
## 3 Cobra 749  35.0 Healthy_Implant F     Area-Unde…       3.00 0.689 0.119 
## 4 Cobra 749  58.0 Healthy_Implant F     Area-Unde…       3.00 0.957 0.208 
## 5 Cobra 749   0   Implant_NoLx    F     Area-Unde…       3.00 1.00  0.0868
## 6 Cobra 749  14.0 Implant_NoLx    F     Area-Unde…       3.00 0.365 0.0964
## 7 Cobra 749  35.0 Implant_NoLx    F     Area-Unde…       3.00 0.409 0.102 
## 8 Cobra 749  58.0 Implant_NoLx    F     Area-Unde…       3.00 0.481 0.212&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Oh, we have &lt;em&gt;two kinds or regions&lt;/em&gt;. Didn’t see that before. So the above summary doesn’t take that into account.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;summary-by-pig-and-region&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Summary by pig and region&lt;/h2&gt;
&lt;p&gt;This summary is &lt;code&gt;group_by(Region)&lt;/code&gt; so we’ll get summary data (&lt;code&gt;mean&lt;/code&gt; and &lt;code&gt;median&lt;/code&gt;) by Region now&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cobra %&amp;gt;% filter(Output == &amp;#39;Area-Under-Curve&amp;#39;) %&amp;gt;% group_by(Region) %&amp;gt;% summarise(mean = mean(Data), median= median(Data))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 3
##   Region           mean median
##   &amp;lt;chr&amp;gt;           &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1 Healthy_Implant 0.834  0.823
## 2 Implant_NoLx    0.564  0.445&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;eel %&amp;gt;% filter(Output == &amp;#39;Area-Under-Curve&amp;#39;) %&amp;gt;% group_by(Region) %&amp;gt;% summarise(mean = mean(Data), median= median(Data))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 3
##   Region        mean median
##   &amp;lt;chr&amp;gt;        &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1 Healthy_Sham 0.978  0.992
## 2 Implant-Sham 0.761  0.721&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We also have time (Week). This will be our x axis when we plot, as this data is sampled across time&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;plot-auc-by-time-and-region-and-pig&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Plot AUC by time and region and pig&lt;/h2&gt;
&lt;p&gt;x axis is time, y axis is AUC, and split by region/pig&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cobra_eel_AUC &amp;lt;- rbind(cobra %&amp;gt;% filter(Output == &amp;#39;Area-Under-Curve&amp;#39;), 
                       eel %&amp;gt;% filter(Output == &amp;#39;Area-Under-Curve&amp;#39;))
cobra_eel_AUC %&amp;gt;% 
  ggplot(aes(x=Week, y=Data, shape=Region, colour=Region)) + 
   geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-02-04-let-s-plot-2-smoothed-lines_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;prettier-plot-with-lines-and-more-formatting&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Prettier plot with lines and more formatting&lt;/h2&gt;
&lt;p&gt;Using the ggsci library with the Nature Publishing Group color scheme (&lt;code&gt;scale_colour_npg()&lt;/code&gt;)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cobra_eel_AUC %&amp;gt;% 
  ggplot(aes(x=Week, y=Data, colour=Region, shape = Pig_Name)) + 
  geom_point(size=4) + 
  geom_smooth(method = &amp;#39;loess&amp;#39;) + ## this draws the smoothed lines through the four points. It auto picks an algorithm that works. loess was used here
  theme_bw() + scale_colour_npg() +
  ylab(&amp;#39;AUC&amp;#39;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-02-04-let-s-plot-2-smoothed-lines_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;n1p1-plot&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;N1P1 Plot&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rbind(cobra %&amp;gt;% filter(Output == &amp;#39;N1P1&amp;#39;), eel %&amp;gt;% filter(Output == &amp;#39;N1P1&amp;#39;)) %&amp;gt;% 
  ggplot(aes(x=Week, y=Data, colour=Region, shape = Pig_Name)) + 
  geom_point(size=4) + 
  geom_smooth() + ## this draws the smoothed lines through the four points. It auto picks an algorithm that works. loess was used here
  theme_bw() + scale_colour_npg() +
  ylab(&amp;#39;N1P1&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &amp;#39;loess&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-02-04-let-s-plot-2-smoothed-lines_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;latency-plot&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Latency plot&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rbind(cobra %&amp;gt;% filter(Output == &amp;#39;N1-Latency&amp;#39;), eel %&amp;gt;% filter(Output == &amp;#39;N1-Latency&amp;#39;)) %&amp;gt;% 
  ggplot(aes(x=Week, y=Data, colour=Region, shape = Pig_Name)) + 
  geom_point(size=4) + 
  geom_smooth() + ## this draws the smoothed lines through the four points. It auto picks an algorithm that works. loess was used here
  theme_bw() + scale_colour_npg() +
  ylab(&amp;#39;N1-Latency&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &amp;#39;loess&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-02-04-let-s-plot-2-smoothed-lines_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;bonus&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Bonus&lt;/h2&gt;
&lt;p&gt;We have many variables. We can get a quick sense of how all of the variables separate out the major data categories with a PCA&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all_pigs &amp;lt;- rbind(cobra, eel) %&amp;gt;% 
  select(Region, Pig_Name, Week, Output, Data) %&amp;gt;% 
  spread(Output, Data)
## toss P-Prime-Latency column
all_pigs &amp;lt;- all_pigs %&amp;gt;% select(-`P-Prime-Latency`)
## remove columns with NA
all_pigs &amp;lt;- all_pigs[complete.cases(all_pigs), complete.cases(t(all_pigs))]
pca &amp;lt;- prcomp(all_pigs[,4:ncol(all_pigs)], scale. = T)

## pull out PCA coordinates (pca$x) and add to all_pigs with the cbind
all_pigs &amp;lt;- cbind(all_pigs, pca$x)

ggplot(all_pigs, aes(x=PC1, y=PC4, color=as.factor(Week), shape=Region)) + 
  geom_point(size=5, alpha=0.7) + 
  theme_bw() + 
  scale_colour_npg() &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-02-04-let-s-plot-2-smoothed-lines_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>John Bryan</title>
      <link>/./people/john_bryan/</link>
      <pubDate>Thu, 01 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/./people/john_bryan/</guid>
      <description>

&lt;h2 id=&#34;november-2016-may-2018&#34;&gt;November 2016 - May 2018&lt;/h2&gt;

&lt;h2 id=&#34;education&#34;&gt;Education&lt;/h2&gt;

&lt;p&gt;BA, Mathematics Major, from Clarement 2016&lt;/p&gt;

&lt;h2 id=&#34;next-position&#34;&gt;Next position&lt;/h2&gt;

&lt;p&gt;[BLANK] Medical School&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Let’s Plot 1: Going in circles </title>
      <link>/./post/let-s-plot-1/</link>
      <pubDate>Thu, 01 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/./post/let-s-plot-1/</guid>
      <description>&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#what-is-going-on&#34;&gt;What is going on?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#where-to-get-the-code-and-data&#34;&gt;Where to get the code and data?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#import-data-with-readxl&#34;&gt;Import data with readxl&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#ok-first-lets-remove-the-notes.&#34;&gt;OK, first let’s remove the notes.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#however-we-arent-done.-the-data-is-wide-instead-of-long-and-we-have-mixed-session-ids-amp-1-3-and-angle-1-3-with-the-value-type.&#34;&gt;However, we aren’t done. The data is “wide” instead of “long” and we have mixed session IDs (Amp 1-3 and Angle 1-3) with the value type.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#now-we-need-to-extract-the-session-123-and-the-test-type-amp-or-angle&#34;&gt;Now we need to extract the session (1,2,3) and the test type (Amp or Angle)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#now-we-have-two-value-types-angle-and-amplitude-in-one-column.-so-we-need-to-go-from-long-to-wide-to-split-them-apart.&#34;&gt;Now we have two value types (Angle and Amplitude) in one column. So we need to go from long to wide to split them apart.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#putting-it-all-together-and-saving-so-we-dont-have-to-see-this-big-code-block-later.&#34;&gt;Putting it all together and saving so we don’t have to see this big code block later.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#first-plot.-does-this-work&#34;&gt;First plot. Does this work?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#but-wait-this-is-a-polar-plot.&#34;&gt;But wait, this is a polar plot….&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#not-bad-but-we-have-a-lot-of-little-things-to-do.&#34;&gt;Not bad, but we have a lot of little things to do.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#yeah-so-we-need-to-tell-ggplot-what-the-range-of-values-is.&#34;&gt;Yeah, so we need to tell ggplot what the range of values is.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#cool-the-range-goes-to-360-as-expected.-still-a-few-more-things-to-do&#34;&gt;Cool, the range goes to 360 as expected. Still a few more things to do:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#hmm-wrong-way.-want-180-on-the-left-lets-make-it-negative.&#34;&gt;Hmm, wrong way. (want 180 on the left) Let’s make it negative.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#ok-final-plot-with-some-color-and-geom_point-tweaking&#34;&gt;OK, Final plot with some color and geom_point tweaking!&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sessioninfo&#34;&gt;sessionInfo&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;what-is-going-on&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What is going on?&lt;/h2&gt;
&lt;p&gt;See &lt;a href=&#34;https://davemcg.github.io/post/what-is-let-s-plot/&#34; class=&#34;uri&#34;&gt;https://davemcg.github.io/post/what-is-let-s-plot/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;where-to-get-the-code-and-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Where to get the code and data?&lt;/h2&gt;
&lt;p&gt;Rmarkdown document: &lt;a href=&#34;https://github.com/davemcg/Let_us_plot/blob/master/001_polar_figure/polar_plot.Rmd&#34; class=&#34;uri&#34;&gt;https://github.com/davemcg/Let_us_plot/blob/master/001_polar_figure/polar_plot.Rmd&lt;/a&gt; Data: &lt;a href=&#34;https://github.com/davemcg/Let_us_plot/blob/master/001_polar_figure/polar_values.xlsx&#34; class=&#34;uri&#34;&gt;https://github.com/davemcg/Let_us_plot/blob/master/001_polar_figure/polar_values.xlsx&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;First time making a polar plot….let’s see if ggplot2 can do it.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;import-data-with-readxl&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Import data with readxl&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Attaching packages ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.2.1 ──&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✔ ggplot2 2.2.1     ✔ purrr   0.2.4
## ✔ tibble  1.4.2     ✔ dplyr   0.7.4
## ✔ tidyr   0.7.2     ✔ stringr 1.2.0
## ✔ readr   1.1.1     ✔ forcats 0.2.0&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Conflicts ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
## ✖ dplyr::filter() masks stats::filter()
## ✖ dplyr::lag()    masks stats::lag()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(stringr)
polar_values &amp;lt;- readxl::read_xlsx(&amp;#39;~/git/Let_us_plot/001_polar_figure/polar_values.xlsx&amp;#39;)
polar_values&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 8 x 8
##   X__1         `Od Amp1` `Od Amp2` `Od Amp3` X__2  `Od Angle1` `Od Angle2`
##   &amp;lt;chr&amp;gt;            &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;lgl&amp;gt;       &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt;
## 1 3                2.10      3.01      2.96  NA           66.0        67.7
## 2 5                1.56      1.36      1.54  NA           19.6        14.7
## 3 14               4.79      4.73      4.72  NA          360         353  
## 4 15               0.350     0.320     0.300 NA          257         234  
## 5 18               0.910     0.830     1.12  NA          350         344  
## 6 &amp;lt;NA&amp;gt;            NA        NA        NA     NA           NA          NA  
## 7 1,2,3 are t…    NA        NA        NA     NA           NA          NA  
## 8 Amp and Ang…    NA        NA        NA     NA           NA          NA  
## # ... with 1 more variable: `Od Angle3` &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;ok-first-lets-remove-the-notes.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;OK, first let’s remove the notes.&lt;/h2&gt;
&lt;p&gt;We first slice the first 5 rows, then fix the encoding for &lt;code&gt;Od Amp1&lt;/code&gt;, then remove the empty column in between&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;polar_values &amp;lt;- polar_values %&amp;gt;% 
  slice(1:5) %&amp;gt;% 
  mutate(Patient=as.factor(X__1)) %&amp;gt;% 
  select(Patient,`Od Amp1`:`Od Amp3`, `Od Angle1`:`Od Angle3`)
polar_values&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 5 x 7
##   Patient `Od Amp1` `Od Amp2` `Od Amp3` `Od Angle1` `Od Angle2`
##   &amp;lt;fct&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt;
## 1 3           2.10      3.01      2.96         66.0        67.7
## 2 5           1.56      1.36      1.54         19.6        14.7
## 3 14          4.79      4.73      4.72        360         353  
## 4 15          0.350     0.320     0.300       257         234  
## 5 18          0.910     0.830     1.12        350         344  
## # ... with 1 more variable: `Od Angle3` &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;however-we-arent-done.-the-data-is-wide-instead-of-long-and-we-have-mixed-session-ids-amp-1-3-and-angle-1-3-with-the-value-type.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;However, we aren’t done. The data is “wide” instead of “long” and we have mixed session IDs (Amp 1-3 and Angle 1-3) with the value type.&lt;/h2&gt;
&lt;p&gt;Let’s first deal with the wide issue. If we google “R wide to long” we find this page near the top &lt;a href=&#34;http://www.cookbook-r.com/Manipulating_data/Converting_data_between_wide_and_long_format/&#34; class=&#34;uri&#34;&gt;http://www.cookbook-r.com/Manipulating_data/Converting_data_between_wide_and_long_format/&lt;/a&gt; which tells us that &lt;code&gt;gather&lt;/code&gt; is the function we want.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Test_Session&lt;/code&gt; is the name for the column containing &lt;code&gt;Od Amp1 to Od Angle&lt;/code&gt; &lt;code&gt;Value&lt;/code&gt; is the name for the column holding the test measurements.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;polar_values %&amp;gt;% 
  gather(Test_Session, Value, `Od Amp1`:`Od Angle3`) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 30 x 3
##    Patient Test_Session Value
##    &amp;lt;fct&amp;gt;   &amp;lt;chr&amp;gt;        &amp;lt;dbl&amp;gt;
##  1 3       Od Amp1      2.10 
##  2 5       Od Amp1      1.56 
##  3 14      Od Amp1      4.79 
##  4 15      Od Amp1      0.350
##  5 18      Od Amp1      0.910
##  6 3       Od Amp2      3.01 
##  7 5       Od Amp2      1.36 
##  8 14      Od Amp2      4.73 
##  9 15      Od Amp2      0.320
## 10 18      Od Amp2      0.830
## # ... with 20 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;now-we-need-to-extract-the-session-123-and-the-test-type-amp-or-angle&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Now we need to extract the session (1,2,3) and the test type (Amp or Angle)&lt;/h2&gt;
&lt;p&gt;We will use the fact that the session is &lt;em&gt;always&lt;/em&gt; at the end to our advantage.&lt;/p&gt;
&lt;p&gt;The str_sub function from the stringr package allows you to pick ‘negative’ positions in the string. So we pick last value and the first to the second last position to get what we need.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;polar_values %&amp;gt;% 
  gather(Test_Session, Value, `Od Amp1`:`Od Angle3`) %&amp;gt;% 
  mutate(Session = str_sub(Test_Session, -1), Test = str_sub(Test_Session,1,-2))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 30 x 5
##    Patient Test_Session Value Session Test  
##    &amp;lt;fct&amp;gt;   &amp;lt;chr&amp;gt;        &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt; 
##  1 3       Od Amp1      2.10  1       Od Amp
##  2 5       Od Amp1      1.56  1       Od Amp
##  3 14      Od Amp1      4.79  1       Od Amp
##  4 15      Od Amp1      0.350 1       Od Amp
##  5 18      Od Amp1      0.910 1       Od Amp
##  6 3       Od Amp2      3.01  2       Od Amp
##  7 5       Od Amp2      1.36  2       Od Amp
##  8 14      Od Amp2      4.73  2       Od Amp
##  9 15      Od Amp2      0.320 2       Od Amp
## 10 18      Od Amp2      0.830 2       Od Amp
## # ... with 20 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;now-we-have-two-value-types-angle-and-amplitude-in-one-column.-so-we-need-to-go-from-long-to-wide-to-split-them-apart.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Now we have two value types (Angle and Amplitude) in one column. So we need to go from long to wide to split them apart.&lt;/h2&gt;
&lt;p&gt;We drop the now useless Test_Session column, grab the session number from the end with &lt;code&gt;str_sub&lt;/code&gt;, then us the &lt;code&gt;spread&lt;/code&gt; function to use the Test and Value columns to get it wide.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;polar_values %&amp;gt;% 
  gather(Test_Session, Value, `Od Amp1`:`Od Angle3`) %&amp;gt;% 
  mutate(Session = str_sub(Test_Session, -1), Test = str_sub(Test_Session,1,-2)) %&amp;gt;% 
  select(-Test_Session) %&amp;gt;% 
  spread(Test, Value)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 15 x 4
##    Patient Session `Od Amp` `Od Angle`
##  * &amp;lt;fct&amp;gt;   &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;
##  1 14      1          4.79       360  
##  2 14      2          4.73       353  
##  3 14      3          4.72       353  
##  4 15      1          0.350      257  
##  5 15      2          0.320      234  
##  6 15      3          0.300      276  
##  7 18      1          0.910      350  
##  8 18      2          0.830      344  
##  9 18      3          1.12       349  
## 10 3       1          2.10        66.0
## 11 3       2          3.01        67.7
## 12 3       3          2.96        65.7
## 13 5       1          1.56        19.6
## 14 5       2          1.36        14.7
## 15 5       3          1.54       360&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Boom. Mic drop.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;putting-it-all-together-and-saving-so-we-dont-have-to-see-this-big-code-block-later.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Putting it all together and saving so we don’t have to see this big code block later.&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;reformatted_values &amp;lt;- 
  polar_values %&amp;gt;% 
  gather(Test_Session, Value, `Od Amp1`:`Od Angle3`) %&amp;gt;% 
  mutate(Session = str_sub(Test_Session, -1), Test = str_sub(Test_Session,1,-2)) %&amp;gt;% 
  select(-Test_Session) %&amp;gt;% 
  spread(Test, Value)

reformatted_values&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 15 x 4
##    Patient Session `Od Amp` `Od Angle`
##  * &amp;lt;fct&amp;gt;   &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;
##  1 14      1          4.79       360  
##  2 14      2          4.73       353  
##  3 14      3          4.72       353  
##  4 15      1          0.350      257  
##  5 15      2          0.320      234  
##  6 15      3          0.300      276  
##  7 18      1          0.910      350  
##  8 18      2          0.830      344  
##  9 18      3          1.12       349  
## 10 3       1          2.10        66.0
## 11 3       2          3.01        67.7
## 12 3       3          2.96        65.7
## 13 5       1          1.56        19.6
## 14 5       2          1.36        14.7
## 15 5       3          1.54       360&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;first-plot.-does-this-work&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;First plot. Does this work?&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;reformatted_values %&amp;gt;% ggplot(aes(y=`Od Amp`, x=`Od Angle`)) + geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-02-01-let-s-plot-1_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;but-wait-this-is-a-polar-plot.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;But wait, this is a polar plot….&lt;/h2&gt;
&lt;p&gt;Fortunately ggplot has a function to transform cartesian values into polar values: &lt;code&gt;coord_polar&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;reformatted_values %&amp;gt;% ggplot(aes(y=`Od Amp`, x=`Od Angle`)) + coord_polar() + geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-02-01-let-s-plot-1_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;not-bad-but-we-have-a-lot-of-little-things-to-do.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Not bad, but we have a lot of little things to do.&lt;/h2&gt;
&lt;p&gt;First, I’m suspicious that the ranges of values is from the smallest to the largest. Or maybe 0 to the largest. We can test this by filtering out the bigger values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;reformatted_values %&amp;gt;% 
  filter(`Od Angle` &amp;lt; 300) %&amp;gt;% 
  ggplot(aes(y=`Od Amp`, x=`Od Angle`)) + coord_polar() + geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-02-01-let-s-plot-1_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;yeah-so-we-need-to-tell-ggplot-what-the-range-of-values-is.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Yeah, so we need to tell ggplot what the range of values is.&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;reformatted_values %&amp;gt;% filter(`Od Angle` &amp;lt; 300) %&amp;gt;% 
  ggplot(aes(y=`Od Amp`, x=`Od Angle`)) + 
  coord_polar() + 
  geom_point() +
  scale_x_continuous(limits=c(0,360), breaks = c(0,30,60,90,120,150,180,210,240,270,300,330)) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-02-01-let-s-plot-1_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;cool-the-range-goes-to-360-as-expected.-still-a-few-more-things-to-do&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Cool, the range goes to 360 as expected. Still a few more things to do:&lt;/h2&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Rotate the start point so 90 is the top&lt;/li&gt;
&lt;li&gt;Change directions of values from CW to CCW&lt;/li&gt;
&lt;li&gt;Add color and prettify&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We examine the coord_polar options (type &lt;code&gt;?coord_polar&lt;/code&gt; in the R console) and see that &lt;code&gt;start&lt;/code&gt; and &lt;code&gt;direction&lt;/code&gt; are options. We want to shift 90 degrees…but the &lt;code&gt;start&lt;/code&gt; parameter is in radians. Some quick googling let’s us know that 90 degree ~ 1.57 radians. Let’s use that. And -1 for direction to make it counter clockwise.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;reformatted_values %&amp;gt;% 
  ggplot(aes(y=`Od Amp`, x=`Od Angle`)) + 
  coord_polar(start = 1.57, direction = -1) + 
  geom_point() +
  scale_x_continuous(limits=c(0,360), breaks = c(0,30,60,90,120,150,180,210,240,270,300,330)) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-02-01-let-s-plot-1_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;hmm-wrong-way.-want-180-on-the-left-lets-make-it-negative.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Hmm, wrong way. (want 180 on the left) Let’s make it negative.&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;reformatted_values %&amp;gt;% 
  ggplot(aes(y=`Od Amp`, x=`Od Angle`)) + 
  coord_polar(start = -1.57, direction = -1) + 
  geom_point() +
  scale_x_continuous(limits=c(0,360), breaks = c(0,30,60,90,120,150,180,210,240,270,300,330)) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-02-01-let-s-plot-1_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ok-final-plot-with-some-color-and-geom_point-tweaking&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;OK, Final plot with some color and geom_point tweaking!&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;theme_bw&lt;/code&gt; makes the background white instead of gray, which I prefer&lt;/p&gt;
&lt;p&gt;&lt;code&gt;alpha&lt;/code&gt; in &lt;code&gt;geom_point&lt;/code&gt; makes the points semi-transparent&lt;/p&gt;
&lt;p&gt;&lt;code&gt;scale_colour_brewer&lt;/code&gt; is a nicer color palette, in my opinion&lt;/p&gt;
&lt;p&gt;&lt;code&gt;colour&lt;/code&gt; and &lt;code&gt;shape&lt;/code&gt; in ggplot() gives us color and shape for the patients and three sessions&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;reformatted_values %&amp;gt;% ggplot(aes(y=`Od Amp`, x=`Od Angle`, colour=Patient, shape=Session)) + 
  coord_polar(start = -1.57, direction = -1) + 
  geom_point(size=3, alpha=0.7) + 
  theme_bw() + 
  scale_x_continuous(limits=c(0,360), breaks = c(0,30,60,90,120,150,180,210,240,270,300,330)) + 
  scale_color_brewer(palette =&amp;#39;Set1&amp;#39;) + xlab(&amp;#39;Angle&amp;#39;) + ylab(&amp;#39;Amplitude&amp;#39;) + ggtitle(&amp;#39;OD&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-02-01-let-s-plot-1_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;sessioninfo&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;sessionInfo&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sessionInfo()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 3.4.0 (2017-04-21)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: OS X El Capitan 10.11.6
## 
## Matrix products: default
## BLAS: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] methods   stats     graphics  grDevices utils     datasets  base     
## 
## other attached packages:
##  [1] bindrcpp_0.2    forcats_0.2.0   stringr_1.2.0   dplyr_0.7.4    
##  [5] purrr_0.2.4     readr_1.1.1     tidyr_0.7.2     tibble_1.4.2   
##  [9] ggplot2_2.2.1   tidyverse_1.2.1
## 
## loaded via a namespace (and not attached):
##  [1] tidyselect_0.2.3   xfun_0.1           reshape2_1.4.2    
##  [4] haven_1.1.0        lattice_0.20-35    colorspace_1.3-2  
##  [7] htmltools_0.3.6    yaml_2.1.14        utf8_1.1.3        
## [10] rlang_0.1.6        pillar_1.1.0       foreign_0.8-69    
## [13] glue_1.2.0         RColorBrewer_1.1-2 modelr_0.1.1      
## [16] readxl_1.0.0       bindr_0.1          plyr_1.8.4        
## [19] munsell_0.4.3      blogdown_0.5       gtable_0.2.0      
## [22] cellranger_1.1.0   rvest_0.3.2        psych_1.7.8       
## [25] evaluate_0.10.1    labeling_0.3       knitr_1.17        
## [28] parallel_3.4.0     broom_0.4.3        Rcpp_0.12.13      
## [31] backports_1.1.1    scales_0.5.0.9000  jsonlite_1.5      
## [34] mnormt_1.5-5       hms_0.3            digest_0.6.12     
## [37] stringi_1.1.6      bookdown_0.6       grid_3.4.0        
## [40] rprojroot_1.2      cli_1.0.0          tools_3.4.0       
## [43] magrittr_1.5       lazyeval_0.2.1     crayon_1.3.4      
## [46] pkgconfig_2.0.1    xml2_1.1.1         lubridate_1.7.1   
## [49] assertthat_0.2.0   rmarkdown_1.8      httr_1.3.1        
## [52] rstudioapi_0.7     R6_2.2.2           nlme_3.1-131      
## [55] compiler_3.4.0&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>eyeIntegration</title>
      <link>/./project/eyeintegration/</link>
      <pubDate>Thu, 01 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/./project/eyeintegration/</guid>
      <description></description>
    </item>
    
    <item>
      <title>What is Let’s Plot?</title>
      <link>/./post/what-is-let-s-plot/</link>
      <pubDate>Wed, 31 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/./post/what-is-let-s-plot/</guid>
      <description>&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#tooling&#34;&gt;Tooling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#how-can-i-follow-along&#34;&gt;How can I follow along?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;The concept is simple - I get data from one of the scientists in my group. Or I get my own. Then I demonstrate, step-by-step, how I generate the plot(s). I’ll also toss in some &lt;em&gt;data science&lt;/em&gt; concepts occasionally.&lt;/p&gt;
&lt;p&gt;They are a bit sparse on the words because I’m presenting these in person. But I believe they are clear enough for someone to follow along. Let me know if I’m wrong.&lt;/p&gt;
&lt;div id=&#34;tooling&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Tooling&lt;/h1&gt;
&lt;p&gt;I like R. I like ggplot. I like the tidyverse. That’s what I’ll be using.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;how-can-i-follow-along&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;How can I follow along?&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Download and install R: &lt;a href=&#34;https://cran.r-project.org/&#34; class=&#34;uri&#34;&gt;https://cran.r-project.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Download and install Rstudio: &lt;a href=&#34;https://www.rstudio.com/products/rstudio/download/#download&#34; class=&#34;uri&#34;&gt;https://www.rstudio.com/products/rstudio/download/#download&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;In Rstudio install any libraries that throw an error when you run &lt;code&gt;library (LIBRARYNAME)&lt;/code&gt; with &lt;code&gt;install.packages(LIBRARYNAME)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Then you can (largely) go line by line through the blog post&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Identifying Core Biological Processes Distinguishing Human Eye Tissues With Systems-Level Gene Expression Analyses And Weighted Correlation Networks</title>
      <link>/./publication/eyeintegration/</link>
      <pubDate>Thu, 11 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/./publication/eyeintegration/</guid>
      <description>&lt;p&gt;More detail can easily be written here using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Example Talk</title>
      <link>/./talk/example-talk/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 -0500</pubDate>
      
      <guid>/./talk/example-talk/</guid>
      <description>&lt;p&gt;Embed your slides or video here using &lt;a href=&#34;https://sourcethemes.com/academic/post/writing-markdown-latex/&#34; target=&#34;_blank&#34;&gt;shortcodes&lt;/a&gt;. Further details can easily be added using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/./post/2018-02-07-let-s-plot-3-base-pair-resolution-ngs-exome-coverage-plots-part-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/./post/2018-02-07-let-s-plot-3-base-pair-resolution-ngs-exome-coverage-plots-part-1/</guid>
      <description>&lt;table&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;title: Let’s Plot 3: Base pair resolution NGS (exome) coverage plots - Part 1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;author: David McGaughey&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;date: ‘2018-02-07’&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;slug: let-s-plot-3-base-pair-resolution-ngs-exome-coverage-plots-part-1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;categories:&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;- bioinformatics&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;- Let’s Plot&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;- R&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;tags:&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;- bioinformatics&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;- ggplot2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;- Let’s Plot&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;- quinlanverse&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;- R&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;output:&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;blogdown::html_page:&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;toc: true&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div id=&#34;load-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Load data&lt;/h2&gt;
&lt;p&gt;This is a departure from the previous installments, as we are loading in a very processed dataset. The reasons why are numerous:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;The original data is 330mb, compressed&lt;/li&gt;
&lt;li&gt;After loading (2 minutes on my quite fast computer) and uncompressing, it takes over 10GB of RAM on my computer&lt;/li&gt;
&lt;li&gt;The original data needed a severe amount of massaging to make it quickly useable:&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Annotating with gene name&lt;/li&gt;
&lt;li&gt;Identifying primary transcript for gene&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Expanding range data into row-form*&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;mosdepth&lt;/code&gt; provides read depth as ranges. So instead of writing a row for each of the three billion+ base pairs, &lt;code&gt;mosdepth&lt;/code&gt; collapses adjacent rows with identical read depth together. This is crucial for saving space, especially for exomes, which have huge stretches of zero coverage since only ~3% of the genome is targeted.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;curious&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Curious?&lt;/h2&gt;
&lt;p&gt;If you want to see how I did the above, see &lt;a href=&#34;/./post/let-s-plot-3-base-pair-resolution-ngs-exome-coverage-plots&#34;&gt;Part 2&lt;/a&gt;. This post also has some cooler plots.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;dd_class.csv&lt;/code&gt; can be found &lt;a href=&#34;https://github.com/davemcg/Let_us_plot/raw/master/003_coverage/dd_class.csv&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Attaching packages ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.2.1 ──&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✔ ggplot2 2.2.1     ✔ purrr   0.2.4
## ✔ tibble  1.4.2     ✔ dplyr   0.7.4
## ✔ tidyr   0.8.0     ✔ stringr 1.3.0
## ✔ readr   1.1.1     ✔ forcats 0.3.0&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Conflicts ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
## ✖ dplyr::filter() masks stats::filter()
## ✖ dplyr::lag()    masks stats::lag()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(cowplot) # you may need to install this with install.packages(&amp;#39;cowplot&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;cowplot&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following object is masked from &amp;#39;package:ggplot2&amp;#39;:
## 
##     ggsave&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dd_class &amp;lt;- read_csv(&amp;#39;~/git/Let_us_plot/003_coverage/dd_class.csv&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Parsed with column specification:
## cols(
##   Transcript = col_character(),
##   `Exon Number` = col_integer(),
##   Start = col_double(),
##   Chr = col_integer(),
##   End = col_integer(),
##   Read_Depth = col_integer(),
##   Strand = col_character(),
##   ExonStart = col_integer(),
##   ExonEnd = col_integer(),
##   Name = col_character()
## )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(dd_class)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 10
##   Transcript `Exon Number`  Start   Chr    End Read_Depth Strand ExonStart
##   &amp;lt;chr&amp;gt;              &amp;lt;int&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;  &amp;lt;int&amp;gt;      &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;      &amp;lt;int&amp;gt;
## 1 ENST00000…             0 4.98e7     8 4.98e7        108 -       49831365
## 2 ENST00000…             0 4.98e7     8 4.98e7        108 -       49831365
## 3 ENST00000…             0 4.98e7     8 4.98e7        108 -       49831365
## 4 ENST00000…             0 4.98e7     8 4.98e7        108 -       49831365
## 5 ENST00000…             0 4.98e7     8 4.98e7        108 -       49831365
## 6 ENST00000…             0 4.98e7     8 4.98e7        108 -       49831365
## # ... with 2 more variables: ExonEnd &amp;lt;int&amp;gt;, Name &amp;lt;chr&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;how-many-genes-are-in-this-dataset&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;How many genes are in this dataset?&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dd_class$Name %&amp;gt;% unique() %&amp;gt;% length()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 118&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;what-genes-are-in-here&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What genes are in here?&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dd_class$Name %&amp;gt;% unique() %&amp;gt;% sort()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   [1] &amp;quot;ABCA4&amp;quot;    &amp;quot;ABCB6&amp;quot;    &amp;quot;AIPL1&amp;quot;    &amp;quot;ALDH1A3&amp;quot;  &amp;quot;ARL6&amp;quot;     &amp;quot;ATF6&amp;quot;    
##   [7] &amp;quot;ATOH7&amp;quot;    &amp;quot;BBIP1&amp;quot;    &amp;quot;BBS1&amp;quot;     &amp;quot;BBS10&amp;quot;    &amp;quot;BBS12&amp;quot;    &amp;quot;BBS5&amp;quot;    
##  [13] &amp;quot;BBS7&amp;quot;     &amp;quot;BBS9&amp;quot;     &amp;quot;BCOR&amp;quot;     &amp;quot;BMP4&amp;quot;     &amp;quot;CACNA1F&amp;quot;  &amp;quot;CACNA2D4&amp;quot;
##  [19] &amp;quot;CASK&amp;quot;     &amp;quot;CDHR1&amp;quot;    &amp;quot;CEP290&amp;quot;   &amp;quot;CHD7&amp;quot;     &amp;quot;CNGB3&amp;quot;    &amp;quot;CNNM4&amp;quot;   
##  [25] &amp;quot;COL4A1&amp;quot;   &amp;quot;COX7B&amp;quot;    &amp;quot;CRX&amp;quot;      &amp;quot;CYP1B1&amp;quot;   &amp;quot;DCDC1&amp;quot;    &amp;quot;EDN3&amp;quot;    
##  [31] &amp;quot;EDNRB&amp;quot;    &amp;quot;ELP4&amp;quot;     &amp;quot;FKRP&amp;quot;     &amp;quot;FKTN&amp;quot;     &amp;quot;FOXC1&amp;quot;    &amp;quot;FOXC2&amp;quot;   
##  [37] &amp;quot;FOXE3&amp;quot;    &amp;quot;GDF3&amp;quot;     &amp;quot;GDF6&amp;quot;     &amp;quot;GNAT2&amp;quot;    &amp;quot;HESX1&amp;quot;    &amp;quot;HMGB3&amp;quot;   
##  [43] &amp;quot;HPS1&amp;quot;     &amp;quot;HPS3&amp;quot;     &amp;quot;HPS4&amp;quot;     &amp;quot;HPS5&amp;quot;     &amp;quot;HPS6&amp;quot;     &amp;quot;INPP5E&amp;quot;  
##  [49] &amp;quot;ISPD&amp;quot;     &amp;quot;KCNJ13&amp;quot;   &amp;quot;KCNV2&amp;quot;    &amp;quot;KIT&amp;quot;      &amp;quot;LAMB2&amp;quot;    &amp;quot;LHX2&amp;quot;    
##  [55] &amp;quot;LYST&amp;quot;     &amp;quot;LZTFL1&amp;quot;   &amp;quot;MAB21L2&amp;quot;  &amp;quot;MFRP&amp;quot;     &amp;quot;MITF&amp;quot;     &amp;quot;MKKS&amp;quot;    
##  [61] &amp;quot;MKS1&amp;quot;     &amp;quot;MLPH&amp;quot;     &amp;quot;MYO5A&amp;quot;    &amp;quot;NAA10&amp;quot;    &amp;quot;NDP&amp;quot;      &amp;quot;NPHP1&amp;quot;   
##  [67] &amp;quot;NRL&amp;quot;      &amp;quot;OCA2&amp;quot;     &amp;quot;OTX2&amp;quot;     &amp;quot;PAX2&amp;quot;     &amp;quot;PAX3&amp;quot;     &amp;quot;PAX6&amp;quot;    
##  [73] &amp;quot;PDE6C&amp;quot;    &amp;quot;PDE6H&amp;quot;    &amp;quot;PITPNM3&amp;quot;  &amp;quot;PITX2&amp;quot;    &amp;quot;PITX3&amp;quot;    &amp;quot;POMT1&amp;quot;   
##  [79] &amp;quot;POMT2&amp;quot;    &amp;quot;PROM1&amp;quot;    &amp;quot;PRPH2&amp;quot;    &amp;quot;PRSS56&amp;quot;   &amp;quot;RAB18&amp;quot;    &amp;quot;RAB27A&amp;quot;  
##  [85] &amp;quot;RAB3GAP1&amp;quot; &amp;quot;RAB3GAP2&amp;quot; &amp;quot;RARB&amp;quot;     &amp;quot;RAX&amp;quot;      &amp;quot;RAX2&amp;quot;     &amp;quot;RDH5&amp;quot;    
##  [91] &amp;quot;RET&amp;quot;      &amp;quot;RIMS1&amp;quot;    &amp;quot;RPGR&amp;quot;     &amp;quot;RPGRIP1&amp;quot;  &amp;quot;SDCCAG8&amp;quot;  &amp;quot;SEMA4A&amp;quot;  
##  [97] &amp;quot;SHH&amp;quot;      &amp;quot;SIX3&amp;quot;     &amp;quot;SIX6&amp;quot;     &amp;quot;SLC24A5&amp;quot;  &amp;quot;SLC25A1&amp;quot;  &amp;quot;SLC38A8&amp;quot; 
## [103] &amp;quot;SLC45A2&amp;quot;  &amp;quot;SNAI2&amp;quot;    &amp;quot;SNX3&amp;quot;     &amp;quot;SOX10&amp;quot;    &amp;quot;SOX2&amp;quot;     &amp;quot;SOX3&amp;quot;    
## [109] &amp;quot;STRA6&amp;quot;    &amp;quot;TENM3&amp;quot;    &amp;quot;TMEM98&amp;quot;   &amp;quot;TRIM32&amp;quot;   &amp;quot;TTC8&amp;quot;     &amp;quot;TTLL5&amp;quot;   
## [115] &amp;quot;UNC119&amp;quot;   &amp;quot;VAX1&amp;quot;     &amp;quot;VSX2&amp;quot;     &amp;quot;ZEB2&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;how-many-data-points-bases-per-gene&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;How many data points (bases) per gene?&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dd_class %&amp;gt;% 
  group_by(Name) %&amp;gt;% 
  summarise(Count=n())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 118 x 2
##    Name    Count
##    &amp;lt;chr&amp;gt;   &amp;lt;int&amp;gt;
##  1 ABCA4    6804
##  2 ABCB6    2527
##  3 AIPL1    1159
##  4 ALDH1A3  1550
##  5 ARL6      569
##  6 ATF6     2008
##  7 ATOH7     457
##  8 BBIP1     220
##  9 BBS1     1773
## 10 BBS10    2172
## # ... with 108 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;how-many-exons-per-gene&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;How many exons per gene?&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dd_class %&amp;gt;% 
  select(Name, `Exon Number`) %&amp;gt;% 
  unique() %&amp;gt;% 
  group_by(Name) %&amp;gt;% 
  summarise(Count = n())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 118 x 2
##    Name    Count
##    &amp;lt;chr&amp;gt;   &amp;lt;int&amp;gt;
##  1 ABCA4      50
##  2 ABCB6      19
##  3 AIPL1       6
##  4 ALDH1A3    13
##  5 ARL6        7
##  6 ATF6       16
##  7 ATOH7       1
##  8 BBIP1       2
##  9 BBS1       17
## 10 BBS10       2
## # ... with 108 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;how-many-base-pairs-of-abca4-well-abca4-exons-is-covered-by-more-than-10-reads&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;How many base pairs of ABCA4 (well, ABCA4 exons) is covered by more than 10 reads?&lt;/h2&gt;
&lt;p&gt;Base R style&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Grab the Read_Depth vector from the data frame filtered by ABCA4 values
depth_abca4 &amp;lt;- dd_class %&amp;gt;% 
  filter(Name==&amp;#39;ABCA4&amp;#39;) %&amp;gt;% 
  pull(Read_Depth)
sum(depth_abca4 &amp;gt; 10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 6803&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;reads&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;5 reads?&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum(depth_abca4 &amp;gt; 5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 6804&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;lets-check-all-of-the-genes-to-see-which-are-the-worst-covered&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Let’s check all of the genes to see which are the worst covered&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dd_class %&amp;gt;% 
  group_by(Name) %&amp;gt;% 
  summarise(Total_Bases = n(),
            LT5 = sum(Read_Depth &amp;lt; 5),
            LT10 = sum(Read_Depth &amp;lt; 10),
            Good = sum(Read_Depth &amp;gt;= 10),
            P5 = LT5 / Total_Bases,
            P10 = LT10 / Total_Bases) %&amp;gt;% 
  arrange(-P10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 118 x 7
##    Name    Total_Bases   LT5  LT10  Good      P5     P10
##    &amp;lt;chr&amp;gt;         &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
##  1 BBIP1           220     0    61   159 0.      0.277  
##  2 ISPD           1339     0    57  1282 0.      0.0426 
##  3 CASK           2778     0    79  2699 0.      0.0284 
##  4 NAA10           725     0    10   715 0.      0.0138 
##  5 CNGB3          2436     0    18  2418 0.      0.00739
##  6 LYST          11400    13    66 11334 0.00114 0.00579
##  7 PROM1          2601     0     8  2593 0.      0.00308
##  8 RET            3348     0     9  3339 0.      0.00269
##  9 CEP290         7456     0    18  7438 0.      0.00241
## 10 SLC25A1         933     0     2   931 0.      0.00214
## # ... with 108 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;we-can-visually-display-the-data-also&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;We can visually display the data, also&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dd_class %&amp;gt;% 
  ggplot(aes(x=Read_Depth, group=Name)) +
  geom_density()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-02-07-let-s-plot-3-base-pair-resolution-ngs-exome-coverage-plots-part-1_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;hard-to-see-what-is-going-on-lets-make-little-plots-for-each-gene&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Hard to see what is going on, let’s make little plots for each gene&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dd_class %&amp;gt;% 
  ggplot(aes(x=Read_Depth, group=Name)) +
  facet_wrap(~Name) + 
  geom_density()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-02-07-let-s-plot-3-base-pair-resolution-ngs-exome-coverage-plots-part-1_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;960&#34; /&gt;
&lt;a href=&#34;/./img/lets_plot3_density.png&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;where-are-genes-poorly-covered&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Where are genes poorly covered?&lt;/h2&gt;
&lt;div id=&#34;bbip1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;BBIP1&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dd_class %&amp;gt;% filter(Name==&amp;#39;BBIP1&amp;#39;) %&amp;gt;% 
  ggplot(aes(x=Start, y=Read_Depth)) + 
  facet_wrap(~`Exon Number`, scales = &amp;#39;free_x&amp;#39;, nrow=1, strip.position = &amp;#39;bottom&amp;#39;) + 
  geom_point(size=0.1) + theme_minimal() +
  theme(axis.text.x=element_blank(), 
        axis.ticks.x = element_blank(), 
        panel.grid.minor = element_blank(), 
        panel.grid.major.x = element_blank(),
        legend.position = &amp;#39;none&amp;#39;) + 
  ylab(&amp;#39;Depth&amp;#39;) + 
  xlab(&amp;#39;Exon Number&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/././post/2018-02-07-let-s-plot-3-base-pair-resolution-ngs-exome-coverage-plots-part-1_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;make-a-coverage-plot-for-many-genes-this-is-advanced-stuff&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Make a coverage plot for many genes (This is advanced stuff!!!)&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gene_list &amp;lt;- c(&amp;#39;ABCA4&amp;#39;, &amp;#39;PITX2&amp;#39;,&amp;#39;VSX2&amp;#39;,&amp;#39;RPGR&amp;#39;,&amp;#39;SOX10&amp;#39;)

# set a custom color that will work even if a category is missing
scale_colour_custom &amp;lt;- function(...){
  ggplot2:::manual_scale(&amp;#39;colour&amp;#39;, 
                         values = setNames(c(&amp;#39;darkred&amp;#39;, &amp;#39;red&amp;#39;, &amp;#39;black&amp;#39;),
                                           c(&amp;#39;&amp;lt; 10 Reads&amp;#39;,&amp;#39;&amp;lt; 20 Reads&amp;#39;,&amp;#39;&amp;gt;= 20 Reads&amp;#39;)), 
                         ...)
}

plot_maker &amp;lt;- function(gene){
  num_of_exons &amp;lt;- dd_class%&amp;gt;% filter(Name==gene) %&amp;gt;% pull(`Exon Number`) %&amp;gt;% as.numeric() %&amp;gt;% max()
   # expand to create a row for each sequence and fill in previous values
  dd_class %&amp;gt;% filter(Name==gene) %&amp;gt;%
    mutate(`Exon Number`= factor(`Exon Number`,levels=0:num_of_exons)) %&amp;gt;%  
    ggplot(aes(x=Start, y=Read_Depth)) + 
    facet_wrap(~`Exon Number`, scales = &amp;#39;free_x&amp;#39;, nrow=1, strip.position = &amp;#39;bottom&amp;#39;) + 
    geom_point(size=0.1) + theme_minimal() + scale_colour_custom() +
    theme(axis.text.x=element_blank(), 
          axis.ticks.x = element_blank(), 
          panel.grid.minor = element_blank(), 
          panel.grid.major.x = element_blank(),
          legend.position = &amp;#39;none&amp;#39;) + 
    ylab(&amp;#39;Depth&amp;#39;) + 
    xlab(gene)
}

plots &amp;lt;- list()
for (i in gene_list){
  plots[[i]] &amp;lt;- plot_maker(i)
}

plot_grid(plotlist = plots, ncol=1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/./img/lets_plot3_cow.png&#34; width=&#34;100%&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::session_info()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Session info -------------------------------------------------------------&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  setting  value                       
##  version  R version 3.4.0 (2017-04-21)
##  system   x86_64, darwin15.6.0        
##  ui       X11                         
##  language (EN)                        
##  collate  en_US.UTF-8                 
##  tz       America/New_York            
##  date     2018-05-04&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Packages -----------------------------------------------------------------&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  package    * version    date       source                        
##  assertthat   0.2.0      2017-04-11 CRAN (R 3.4.0)                
##  backports    1.1.2      2017-12-13 CRAN (R 3.4.3)                
##  base       * 3.4.0      2017-04-21 local                         
##  bindr        0.1.1      2018-03-13 CRAN (R 3.4.4)                
##  bindrcpp   * 0.2        2017-06-17 CRAN (R 3.4.0)                
##  blogdown     0.5        2018-01-24 CRAN (R 3.4.3)                
##  bookdown     0.7        2018-02-18 CRAN (R 3.4.3)                
##  broom        0.4.3      2017-11-20 CRAN (R 3.4.0)                
##  cellranger   1.1.0      2016-07-27 CRAN (R 3.4.0)                
##  cli          1.0.0      2017-11-05 CRAN (R 3.4.2)                
##  colorspace   1.3-2      2016-12-14 CRAN (R 3.4.0)                
##  compiler     3.4.0      2017-04-21 local                         
##  cowplot    * 0.9.2      2017-12-17 CRAN (R 3.4.3)                
##  crayon       1.3.4      2017-09-16 CRAN (R 3.4.1)                
##  datasets   * 3.4.0      2017-04-21 local                         
##  devtools     1.13.5     2018-02-18 CRAN (R 3.4.3)                
##  digest       0.6.15     2018-01-28 CRAN (R 3.4.3)                
##  dplyr      * 0.7.4      2017-09-28 CRAN (R 3.4.2)                
##  evaluate     0.10.1     2017-06-24 CRAN (R 3.4.1)                
##  forcats    * 0.3.0      2018-02-19 CRAN (R 3.4.3)                
##  foreign      0.8-69     2017-06-22 CRAN (R 3.4.1)                
##  ggplot2    * 2.2.1      2016-12-30 CRAN (R 3.4.0)                
##  glue         1.2.0      2017-10-29 CRAN (R 3.4.2)                
##  graphics   * 3.4.0      2017-04-21 local                         
##  grDevices  * 3.4.0      2017-04-21 local                         
##  grid         3.4.0      2017-04-21 local                         
##  gtable       0.2.0      2016-02-26 CRAN (R 3.4.0)                
##  haven        1.1.1      2018-01-18 CRAN (R 3.4.3)                
##  hms          0.4.2      2018-03-10 CRAN (R 3.4.4)                
##  htmltools    0.3.6      2017-04-28 CRAN (R 3.4.0)                
##  httr         1.3.1      2017-08-20 CRAN (R 3.4.1)                
##  jsonlite     1.5        2017-06-01 CRAN (R 3.4.0)                
##  knitr        1.20       2018-02-20 CRAN (R 3.4.3)                
##  labeling     0.3        2014-08-23 CRAN (R 3.4.0)                
##  lattice      0.20-35    2017-03-25 CRAN (R 3.4.0)                
##  lazyeval     0.2.1      2017-10-29 CRAN (R 3.4.2)                
##  lubridate    1.7.3      2018-02-27 CRAN (R 3.4.3)                
##  magrittr     1.5        2014-11-22 CRAN (R 3.4.0)                
##  memoise      1.1.0      2017-04-21 CRAN (R 3.4.0)                
##  methods    * 3.4.0      2017-04-21 local                         
##  mnormt       1.5-5      2016-10-15 CRAN (R 3.4.0)                
##  modelr       0.1.1      2017-07-24 CRAN (R 3.4.1)                
##  munsell      0.4.3      2016-02-13 CRAN (R 3.4.0)                
##  nlme         3.1-131.1  2018-02-16 CRAN (R 3.4.3)                
##  parallel     3.4.0      2017-04-21 local                         
##  pillar       1.2.1      2018-02-27 CRAN (R 3.4.3)                
##  pkgconfig    2.0.1      2017-03-21 CRAN (R 3.4.0)                
##  plyr         1.8.4      2016-06-08 CRAN (R 3.4.0)                
##  psych        1.7.8      2017-09-09 CRAN (R 3.4.0)                
##  purrr      * 0.2.4      2017-10-18 CRAN (R 3.4.2)                
##  R6           2.2.2      2017-06-17 CRAN (R 3.4.0)                
##  Rcpp         0.12.16    2018-03-13 CRAN (R 3.4.4)                
##  readr      * 1.1.1      2017-05-16 CRAN (R 3.4.0)                
##  readxl       1.0.0      2017-04-18 CRAN (R 3.4.0)                
##  reshape2     1.4.3      2017-12-11 CRAN (R 3.4.3)                
##  rlang        0.2.0      2018-02-20 CRAN (R 3.4.3)                
##  rmarkdown    1.9        2018-03-01 CRAN (R 3.4.3)                
##  rprojroot    1.3-2      2018-01-03 CRAN (R 3.4.3)                
##  rstudioapi   0.7        2017-09-07 CRAN (R 3.4.1)                
##  rvest        0.3.2      2016-06-17 CRAN (R 3.4.0)                
##  scales       0.5.0.9000 2017-09-20 Github (hadley/scales@d767915)
##  stats      * 3.4.0      2017-04-21 local                         
##  stringi      1.1.7      2018-03-12 CRAN (R 3.4.4)                
##  stringr    * 1.3.0      2018-02-19 CRAN (R 3.4.3)                
##  tibble     * 1.4.2      2018-01-22 cran (@1.4.2)                 
##  tidyr      * 0.8.0      2018-01-29 CRAN (R 3.4.3)                
##  tidyverse  * 1.2.1      2017-11-14 CRAN (R 3.4.2)                
##  tools        3.4.0      2017-04-21 local                         
##  utf8         1.1.3      2018-01-03 cran (@1.1.3)                 
##  utils      * 3.4.0      2017-04-21 local                         
##  withr        2.1.2      2018-03-15 CRAN (R 3.4.4)                
##  xfun         0.1        2018-01-22 CRAN (R 3.4.3)                
##  xml2         1.2.0      2018-01-24 CRAN (R 3.4.3)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
